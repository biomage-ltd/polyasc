{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysam in /d0/home/adamk/pysccnv/venv/lib/python3.7/site-packages (0.15.2)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/d0/home/adamk/pysccnv/venv/bin/pip install pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package pysam:\n",
      "\n",
      "NAME\n",
      "    pysam\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    Pileup\n",
      "    bcftools\n",
      "    config\n",
      "    include (package)\n",
      "    libcalignedsegment\n",
      "    libcalignmentfile\n",
      "    libcbcf\n",
      "    libcbcftools\n",
      "    libcbgzf\n",
      "    libcfaidx\n",
      "    libchtslib\n",
      "    libcsamfile\n",
      "    libcsamtools\n",
      "    libctabix\n",
      "    libctabixproxies\n",
      "    libcutils\n",
      "    libcvcf\n",
      "    samtools\n",
      "    utils\n",
      "    version\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        pysam.utils.SamtoolsError\n",
      "    builtins.object\n",
      "        pysam.libcalignedsegment.AlignedSegment\n",
      "            pysam.libcsamfile.AlignedRead\n",
      "        pysam.libcalignedsegment.PileupColumn\n",
      "        pysam.libcalignedsegment.PileupRead\n",
      "        pysam.libcalignmentfile.AlignmentHeader\n",
      "        pysam.libcalignmentfile.IndexedReads\n",
      "        pysam.libcalignmentfile.IteratorColumn\n",
      "        pysam.libcalignmentfile.IteratorRow\n",
      "        pysam.libcbcf.VariantHeader\n",
      "        pysam.libcbcf.VariantHeaderRecord\n",
      "        pysam.libcbcf.VariantRecord\n",
      "        pysam.libcbgzf.BGZFile\n",
      "        pysam.libcfaidx.FastaFile\n",
      "            pysam.libcfaidx.Fastafile\n",
      "        pysam.libcfaidx.FastqProxy\n",
      "        pysam.libcfaidx.FastxFile\n",
      "            pysam.libcfaidx.FastqFile\n",
      "        pysam.libcfaidx.FastxRecord\n",
      "        pysam.libchtslib.HFile\n",
      "        pysam.libchtslib.HTSFile\n",
      "            pysam.libcalignmentfile.AlignmentFile\n",
      "                pysam.libcsamfile.Samfile\n",
      "            pysam.libcbcf.VariantFile\n",
      "            pysam.libctabix.TabixFile\n",
      "                pysam.libctabix.Tabixfile\n",
      "        pysam.libctabix.GZIterator\n",
      "            pysam.libctabix.GZIteratorHead\n",
      "        pysam.libctabix.tabix_file_iterator\n",
      "        pysam.libctabix.tabix_generic_iterator\n",
      "        pysam.libcvcf.VCF\n",
      "    pysam.libctabix.Parser(builtins.object)\n",
      "        pysam.libctabix.asBed\n",
      "        pysam.libctabix.asGFF3\n",
      "        pysam.libctabix.asGTF\n",
      "        pysam.libctabix.asTuple\n",
      "        pysam.libctabix.asVCF\n",
      "    pysam.libctabixproxies.TupleProxy(builtins.object)\n",
      "        pysam.libcvcf.VCFRecord\n",
      "    \n",
      "    class AlignedRead(pysam.libcalignedsegment.AlignedSegment)\n",
      "     |  Deprecated alternative for :class:`~pysam.AlignedSegment`\n",
      "     |  \n",
      "     |  Added for backwards compatibility with pysam <= 0.8.0\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AlignedRead\n",
      "     |      pysam.libcalignedsegment.AlignedSegment\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      AlignedRead.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      AlignedRead.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysam.libcalignedsegment.AlignedSegment:\n",
      "     |  \n",
      "     |  __copy__(...)\n",
      "     |      AlignedSegment.__copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      AlignedSegment.__deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      return string representation of alignment.\n",
      "     |      \n",
      "     |      The representation is an approximate :term:`SAM` format, because\n",
      "     |      an aligned read might not be associated with a :term:`AlignmentFile`.\n",
      "     |      As a result :term:`tid` is shown instead of the reference name.\n",
      "     |      Similarly, the tags field is returned in its parsed state.\n",
      "     |      \n",
      "     |      To get a valid SAM record, use :meth:`to_string`.\n",
      "     |  \n",
      "     |  compare(...)\n",
      "     |      AlignedSegment.compare(self, AlignedSegment other)\n",
      "     |      return -1,0,1, if contents in this are binary\n",
      "     |              <,=,> to *other*\n",
      "     |  \n",
      "     |  get_aligned_pairs(...)\n",
      "     |      AlignedSegment.get_aligned_pairs(self, matches_only=False, with_seq=False)\n",
      "     |      a list of aligned read (query) and reference positions.\n",
      "     |      \n",
      "     |              For inserts, deletions, skipping either query or reference\n",
      "     |              position may be None.\n",
      "     |      \n",
      "     |              Padding is currently not supported and leads to an exception.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              matches_only : bool\n",
      "     |                If True, only matched bases are returned - no None on either\n",
      "     |                side.\n",
      "     |              with_seq : bool\n",
      "     |                If True, return a third element in the tuple containing the\n",
      "     |                reference sequence. Substitutions are lower-case. This option\n",
      "     |                requires an MD tag to be present.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              aligned_pairs : list of tuples\n",
      "     |  \n",
      "     |  get_blocks(...)\n",
      "     |      AlignedSegment.get_blocks(self)\n",
      "     |      a list of start and end positions of\n",
      "     |             aligned gapless blocks.\n",
      "     |      \n",
      "     |             The start and end positions are in genomic\n",
      "     |             coordinates.\n",
      "     |      \n",
      "     |             Blocks are not normalized, i.e. two blocks\n",
      "     |             might be directly adjacent. This happens if\n",
      "     |             the two blocks are separated by an insertion\n",
      "     |             in the read.\n",
      "     |  \n",
      "     |  get_cigar_stats(...)\n",
      "     |      AlignedSegment.get_cigar_stats(self)\n",
      "     |      summary of operations in cigar string.\n",
      "     |      \n",
      "     |              The output order in the array is \"MIDNSHP=X\" followed by a\n",
      "     |              field for the NM tag. If the NM tag is not present, this\n",
      "     |              field will always be 0.\n",
      "     |      \n",
      "     |              +-----+--------------+-----+\n",
      "     |              |M    |BAM_CMATCH    |0    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |I    |BAM_CINS      |1    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |D    |BAM_CDEL      |2    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |N    |BAM_CREF_SKIP |3    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |S    |BAM_CSOFT_CLIP|4    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |H    |BAM_CHARD_CLIP|5    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |P    |BAM_CPAD      |6    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |=    |BAM_CEQUAL    |7    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |X    |BAM_CDIFF     |8    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |B    |BAM_CBACK     |9    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |NM   |NM tag        |10   |\n",
      "     |              +-----+--------------+-----+\n",
      "     |      \n",
      "     |              If no cigar string is present, empty arrays will be returned.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              arrays : two arrays. The first contains the nucleotide counts within\n",
      "     |                 each cigar operation, the second contains the number of blocks for\n",
      "     |                 each cigar operation.\n",
      "     |  \n",
      "     |  get_forward_qualities(...)\n",
      "     |      AlignedSegment.get_forward_qualities(self)\n",
      "     |      return the original read sequence.\n",
      "     |              \n",
      "     |              Reads mapping to the reverse strand will be reverse\n",
      "     |              complemented.\n",
      "     |  \n",
      "     |  get_forward_sequence(...)\n",
      "     |      AlignedSegment.get_forward_sequence(self)\n",
      "     |      return the original read sequence.\n",
      "     |              \n",
      "     |              Reads mapping to the reverse strand will be reverse\n",
      "     |              complemented.\n",
      "     |      \n",
      "     |              Returns None if the record has no query sequence.\n",
      "     |  \n",
      "     |  get_overlap(...)\n",
      "     |      AlignedSegment.get_overlap(self, uint32_t start, uint32_t end)\n",
      "     |      return number of aligned bases of read overlapping the interval\n",
      "     |              *start* and *end* on the reference sequence.\n",
      "     |      \n",
      "     |              Return None if cigar alignment is not available.\n",
      "     |  \n",
      "     |  get_reference_positions(...)\n",
      "     |      AlignedSegment.get_reference_positions(self, full_length=False)\n",
      "     |      a list of reference positions that this read aligns to.\n",
      "     |      \n",
      "     |              By default, this method only returns positions in the\n",
      "     |              reference that are within the alignment. If *full_length* is\n",
      "     |              set, None values will be included for any soft-clipped or\n",
      "     |              unaligned positions within the read. The returned list will\n",
      "     |              thus be of the same length as the read.\n",
      "     |  \n",
      "     |  get_reference_sequence(...)\n",
      "     |      AlignedSegment.get_reference_sequence(self)\n",
      "     |      return the reference sequence in the region that is covered by the\n",
      "     |              alignment of the read to the reference.\n",
      "     |      \n",
      "     |              This method requires the MD tag to be set.\n",
      "     |  \n",
      "     |  get_tag(...)\n",
      "     |      AlignedSegment.get_tag(self, tag, with_value_type=False)\n",
      "     |      \n",
      "     |      retrieves data from the optional alignment section\n",
      "     |      given a two-letter *tag* denoting the field.\n",
      "     |      \n",
      "     |      The returned value is cast into an appropriate python type.\n",
      "     |      \n",
      "     |      This method is the fastest way to access the optional\n",
      "     |      alignment section if only few tags need to be retrieved.\n",
      "     |      \n",
      "     |      Possible value types are \"AcCsSiIfZHB\" (see BAM format\n",
      "     |      specification) as well as additional value type 'd' as\n",
      "     |      implemented in htslib.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      tag :\n",
      "     |          data tag.\n",
      "     |      \n",
      "     |      with_value_type : Optional[bool]\n",
      "     |          if set to True, the return value is a tuple of (tag value, type code).\n",
      "     |          (default False)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      \n",
      "     |      A python object with the value of the `tag`. The type of the\n",
      "     |      object depends on the data type in the data record.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      \n",
      "     |      KeyError\n",
      "     |          If `tag` is not present, a KeyError is raised.\n",
      "     |  \n",
      "     |  get_tags(...)\n",
      "     |      AlignedSegment.get_tags(self, with_value_type=False)\n",
      "     |      the fields in the optional aligment section.\n",
      "     |      \n",
      "     |              Returns a list of all fields in the optional\n",
      "     |              alignment section. Values are converted to appropriate python\n",
      "     |              values. For example:\n",
      "     |      \n",
      "     |              [(NM, 2), (RG, \"GJP00TM04\")]\n",
      "     |      \n",
      "     |              If *with_value_type* is set, the value type as encode in\n",
      "     |              the AlignedSegment record will be returned as well:\n",
      "     |      \n",
      "     |              [(NM, 2, \"i\"), (RG, \"GJP00TM04\", \"Z\")]\n",
      "     |      \n",
      "     |              This method will convert all values in the optional alignment\n",
      "     |              section. When getting only one or few tags, please see\n",
      "     |              :meth:`get_tag` for a quicker way to achieve this.\n",
      "     |  \n",
      "     |  has_tag(...)\n",
      "     |      AlignedSegment.has_tag(self, tag)\n",
      "     |      returns true if the optional alignment section\n",
      "     |              contains a given *tag*.\n",
      "     |  \n",
      "     |  infer_query_length(...)\n",
      "     |      AlignedSegment.infer_query_length(self, always=False)\n",
      "     |      infer query length from CIGAR alignment.\n",
      "     |      \n",
      "     |              This method deduces the query length from the CIGAR alignment\n",
      "     |              but does not include hard-clipped bases.\n",
      "     |      \n",
      "     |              Returns None if CIGAR alignment is not present.\n",
      "     |      \n",
      "     |              If *always* is set to True, `infer_read_length` is used instead.\n",
      "     |              This is deprecated and only present for backward compatibility.\n",
      "     |  \n",
      "     |  infer_read_length(...)\n",
      "     |      AlignedSegment.infer_read_length(self)\n",
      "     |      infer read length from CIGAR alignment.\n",
      "     |      \n",
      "     |              This method deduces the read length from the CIGAR alignment\n",
      "     |              including hard-clipped bases.\n",
      "     |      \n",
      "     |              Returns None if CIGAR alignment is not present.\n",
      "     |  \n",
      "     |  opt(...)\n",
      "     |      AlignedSegment.opt(self, tag)\n",
      "     |      deprecated, use get_tag() instead\n",
      "     |  \n",
      "     |  overlap(...)\n",
      "     |      AlignedSegment.overlap(self)\n",
      "     |      deprecated, use get_overlap() instead\n",
      "     |  \n",
      "     |  setTag(...)\n",
      "     |      AlignedSegment.setTag(self, tag, value, value_type=None, replace=True)\n",
      "     |      deprecated, use set_tag() instead\n",
      "     |  \n",
      "     |  set_tag(...)\n",
      "     |      AlignedSegment.set_tag(self, tag, value, value_type=None, replace=True)\n",
      "     |      sets a particular field *tag* to *value* in the optional alignment\n",
      "     |              section.\n",
      "     |      \n",
      "     |              *value_type* describes the type of *value* that is to entered\n",
      "     |              into the alignment record. It can be set explicitly to one of\n",
      "     |              the valid one-letter type codes. If unset, an appropriate type\n",
      "     |              will be chosen automatically based on the python type of\n",
      "     |              *value*.\n",
      "     |      \n",
      "     |              An existing value of the same *tag* will be overwritten unless\n",
      "     |              *replace* is set to False. This is usually not recommened as a\n",
      "     |              tag may only appear once in the optional alignment section.\n",
      "     |      \n",
      "     |              If *value* is None, the tag will be deleted.\n",
      "     |      \n",
      "     |              This method accepts valid SAM specification value types, which\n",
      "     |              are::\n",
      "     |              \n",
      "     |                 A: printable char\n",
      "     |                 i: signed int\n",
      "     |                 f: float\n",
      "     |                 Z: printable string\n",
      "     |                 H: Byte array in hex format\n",
      "     |                 B: Integer or numeric array\n",
      "     |      \n",
      "     |              Additionally, it will accept the integer BAM types ('cCsSI')\n",
      "     |      \n",
      "     |              For htslib compatibility, 'a' is synonymous with 'A' and the\n",
      "     |              method accepts a 'd' type code for a double precision float.\n",
      "     |      \n",
      "     |              When deducing the type code by the python type of *value*, the\n",
      "     |              following mapping is applied::\n",
      "     |              \n",
      "     |                  i: python int\n",
      "     |                  f: python float\n",
      "     |                  Z: python str or bytes\n",
      "     |                  B: python array.array, list or tuple\n",
      "     |                  \n",
      "     |              Note that a single character string will be output as 'Z' and\n",
      "     |              not 'A' as the former is the more general type.\n",
      "     |  \n",
      "     |  set_tags(...)\n",
      "     |      AlignedSegment.set_tags(self, tags)\n",
      "     |      sets the fields in the optional alignment section with\n",
      "     |              a list of (tag, value) tuples.\n",
      "     |      \n",
      "     |              The :term:`value type` of the values is determined from the\n",
      "     |              python type. Optionally, a type may be given explicitly as\n",
      "     |              a third value in the tuple, For example:\n",
      "     |      \n",
      "     |              x.set_tags([(NM, 2, \"i\"), (RG, \"GJP00TM04\", \"Z\")]\n",
      "     |      \n",
      "     |              This method will not enforce the rule that the same tag may appear\n",
      "     |              only once in the optional alignment section.\n",
      "     |  \n",
      "     |  to_dict(...)\n",
      "     |      AlignedSegment.to_dict(self)\n",
      "     |      returns a json representation of the aligned segment.\n",
      "     |      \n",
      "     |              Field names are abbreviated versions of the class attributes.\n",
      "     |  \n",
      "     |  to_string(...)\n",
      "     |      AlignedSegment.to_string(self)\n",
      "     |      returns a string representation of the aligned segment.\n",
      "     |      \n",
      "     |              The output format is valid SAM format if a header is associated\n",
      "     |              with the AlignedSegment.\n",
      "     |  \n",
      "     |  tostring(...)\n",
      "     |      AlignedSegment.tostring(self, htsfile=None)\n",
      "     |      deprecated, use :meth:`to_string()` instead.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              htsfile -- (deprecated) AlignmentFile object to map numerical\n",
      "     |                         identifiers to chromosome names. This parameter is present\n",
      "     |                         for backwards compatibility and ignored.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pysam.libcalignedsegment.AlignedSegment:\n",
      "     |  \n",
      "     |  from_dict(...) from builtins.type\n",
      "     |      AlignedSegment.from_dict(type cls, sam_dict, AlignmentHeader header)\n",
      "     |      parses a dictionary representation of the aligned segment.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |              sam_dict -- dictionary of alignment values, keys corresponding to output from\n",
      "     |                          :meth:`todict()`.\n",
      "     |  \n",
      "     |  fromstring(...) from builtins.type\n",
      "     |      AlignedSegment.fromstring(type cls, sam, AlignmentHeader header)\n",
      "     |      parses a string representation of the aligned segment.\n",
      "     |      \n",
      "     |              The input format should be valid SAM format.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |              sam -- :term:`SAM` formatted string\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysam.libcalignedsegment.AlignedSegment:\n",
      "     |  \n",
      "     |  aend\n",
      "     |      deprecated, reference_end instead\n",
      "     |  \n",
      "     |  alen\n",
      "     |      deprecated, reference_length instead\n",
      "     |  \n",
      "     |  aligned_pairs\n",
      "     |      deprecated, use get_aligned_pairs() instead\n",
      "     |  \n",
      "     |  bin\n",
      "     |      properties bin\n",
      "     |  \n",
      "     |  blocks\n",
      "     |      deprecated, use get_blocks() instead\n",
      "     |  \n",
      "     |  cigar\n",
      "     |      deprecated, use cigartuples instead\n",
      "     |  \n",
      "     |  cigarstring\n",
      "     |      the :term:`cigar` alignment as a string.\n",
      "     |      \n",
      "     |      The cigar string is a string of alternating integers\n",
      "     |      and characters denoting the length and the type of\n",
      "     |      an operation.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          The order length,operation is specified in the\n",
      "     |          SAM format. It is different from the order of\n",
      "     |          the :attr:`cigar` property.\n",
      "     |      \n",
      "     |      Returns None if not present.\n",
      "     |      \n",
      "     |      To unset the cigarstring, assign None or the\n",
      "     |      empty string.\n",
      "     |  \n",
      "     |  cigartuples\n",
      "     |      the :term:`cigar` alignment. The alignment\n",
      "     |      is returned as a list of tuples of (operation, length).\n",
      "     |      \n",
      "     |      If the alignment is not present, None is returned.\n",
      "     |      \n",
      "     |      The operations are:\n",
      "     |      \n",
      "     |      +-----+--------------+-----+\n",
      "     |      |M    |BAM_CMATCH    |0    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |I    |BAM_CINS      |1    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |D    |BAM_CDEL      |2    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |N    |BAM_CREF_SKIP |3    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |S    |BAM_CSOFT_CLIP|4    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |H    |BAM_CHARD_CLIP|5    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |P    |BAM_CPAD      |6    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |=    |BAM_CEQUAL    |7    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |X    |BAM_CDIFF     |8    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |B    |BAM_CBACK     |9    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          The output is a list of (operation, length) tuples, such as\n",
      "     |          ``[(0, 30)]``.\n",
      "     |          This is different from the SAM specification and\n",
      "     |          the :attr:`cigarstring` property, which uses a\n",
      "     |          (length, operation) order, for example: ``30M``.\n",
      "     |      \n",
      "     |      To unset the cigar property, assign an empty list\n",
      "     |      or None.\n",
      "     |  \n",
      "     |  flag\n",
      "     |      properties flag\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  inferred_length\n",
      "     |      deprecated, use infer_query_length() instead\n",
      "     |  \n",
      "     |  is_duplicate\n",
      "     |      true if optical or PCR duplicate\n",
      "     |  \n",
      "     |  is_paired\n",
      "     |      true if read is paired in sequencing\n",
      "     |  \n",
      "     |  is_proper_pair\n",
      "     |      true if read is mapped in a proper pair\n",
      "     |  \n",
      "     |  is_qcfail\n",
      "     |      true if QC failure\n",
      "     |  \n",
      "     |  is_read1\n",
      "     |      true if this is read1\n",
      "     |  \n",
      "     |  is_read2\n",
      "     |      true if this is read2\n",
      "     |  \n",
      "     |  is_reverse\n",
      "     |      true if read is mapped to reverse strand\n",
      "     |  \n",
      "     |  is_secondary\n",
      "     |      true if not primary alignment\n",
      "     |  \n",
      "     |  is_supplementary\n",
      "     |      true if this is a supplementary alignment\n",
      "     |  \n",
      "     |  is_unmapped\n",
      "     |      true if read itself is unmapped\n",
      "     |  \n",
      "     |  isize\n",
      "     |      deprecated, use template_length instead\n",
      "     |  \n",
      "     |  mapping_quality\n",
      "     |      mapping quality\n",
      "     |  \n",
      "     |  mapq\n",
      "     |      deprecated, use mapping_quality instead\n",
      "     |  \n",
      "     |  mate_is_reverse\n",
      "     |      true is read is mapped to reverse strand\n",
      "     |  \n",
      "     |  mate_is_unmapped\n",
      "     |      true if the mate is unmapped\n",
      "     |  \n",
      "     |  mpos\n",
      "     |      deprecated, use next_reference_start instead\n",
      "     |  \n",
      "     |  mrnm\n",
      "     |      deprecated, use next_reference_id instead\n",
      "     |  \n",
      "     |  next_reference_id\n",
      "     |      the :term:`reference` id of the mate/next read.\n",
      "     |  \n",
      "     |  next_reference_name\n",
      "     |      :term:`reference` name of the mate/next read (None if no\n",
      "     |      AlignmentFile is associated)\n",
      "     |  \n",
      "     |  next_reference_start\n",
      "     |      the position of the mate/next read.\n",
      "     |  \n",
      "     |  pnext\n",
      "     |      deprecated, use next_reference_start instead\n",
      "     |  \n",
      "     |  pos\n",
      "     |      deprecated, use reference_start instead\n",
      "     |  \n",
      "     |  positions\n",
      "     |      deprecated, use get_reference_positions() instead\n",
      "     |  \n",
      "     |  qend\n",
      "     |      deprecated, use query_alignment_end instead\n",
      "     |  \n",
      "     |  qlen\n",
      "     |      deprecated, use query_alignment_length instead\n",
      "     |  \n",
      "     |  qname\n",
      "     |      deprecated, use query_name instead\n",
      "     |  \n",
      "     |  qqual\n",
      "     |      deprecated, query_alignment_qualities instead\n",
      "     |  \n",
      "     |  qstart\n",
      "     |      deprecated, use query_alignment_start instead\n",
      "     |  \n",
      "     |  qual\n",
      "     |      deprecated, query_qualities instead\n",
      "     |  \n",
      "     |  query\n",
      "     |      deprecated, query_alignment_sequence instead\n",
      "     |  \n",
      "     |  query_alignment_end\n",
      "     |      end index of the aligned query portion of the sequence (0-based,\n",
      "     |      exclusive)\n",
      "     |      \n",
      "     |      This the index just past the last base in :attr:`seq` that is not\n",
      "     |      soft-clipped.\n",
      "     |  \n",
      "     |  query_alignment_length\n",
      "     |      length of the aligned query sequence.\n",
      "     |      \n",
      "     |      This is equal to :attr:`qend` - :attr:`qstart`\n",
      "     |  \n",
      "     |  query_alignment_qualities\n",
      "     |      aligned query sequence quality values (None if not present). These\n",
      "     |      are the quality values that correspond to :attr:`query`, that\n",
      "     |      is, they exclude qualities of :term:`soft clipped` bases. This\n",
      "     |      is equal to ``qual[qstart:qend]``.\n",
      "     |      \n",
      "     |      Quality scores are returned as a python array of unsigned\n",
      "     |      chars. Note that this is not the ASCII-encoded value typically\n",
      "     |      seen in FASTQ or SAM formatted files. Thus, no offset of 33\n",
      "     |      needs to be subtracted.\n",
      "     |      \n",
      "     |      This property is read-only.\n",
      "     |  \n",
      "     |  query_alignment_sequence\n",
      "     |      aligned portion of the read.\n",
      "     |      \n",
      "     |      This is a substring of :attr:`seq` that excludes flanking\n",
      "     |      bases that were :term:`soft clipped` (None if not present). It\n",
      "     |      is equal to ``seq[qstart:qend]``.\n",
      "     |      \n",
      "     |      SAM/BAM files may include extra flanking bases that are not\n",
      "     |      part of the alignment.  These bases may be the result of the\n",
      "     |      Smith-Waterman or other algorithms, which may not require\n",
      "     |      alignments that begin at the first residue or end at the last.\n",
      "     |      In addition, extra sequencing adapters, multiplex identifiers,\n",
      "     |      and low-quality bases that were not considered for alignment\n",
      "     |      may have been retained.\n",
      "     |  \n",
      "     |  query_alignment_start\n",
      "     |      start index of the aligned query portion of the sequence (0-based,\n",
      "     |      inclusive).\n",
      "     |      \n",
      "     |      This the index of the first base in :attr:`seq` that is not\n",
      "     |      soft-clipped.\n",
      "     |  \n",
      "     |  query_length\n",
      "     |      the length of the query/read.\n",
      "     |      \n",
      "     |      This value corresponds to the length of the sequence supplied\n",
      "     |      in the BAM/SAM file. The length of a query is 0 if there is no\n",
      "     |      sequence in the BAM/SAM file. In those cases, the read length\n",
      "     |      can be inferred from the CIGAR alignment, see\n",
      "     |      :meth:`pysam.AlignedSegment.infer_query_length`.\n",
      "     |      \n",
      "     |      The length includes soft-clipped bases and is equal to\n",
      "     |      ``len(query_sequence)``.\n",
      "     |      \n",
      "     |      This property is read-only but can be set by providing a\n",
      "     |      sequence.\n",
      "     |      \n",
      "     |      Returns 0 if not available.\n",
      "     |  \n",
      "     |  query_name\n",
      "     |      the query template name (None if not present)\n",
      "     |  \n",
      "     |  query_qualities\n",
      "     |      read sequence base qualities, including :term:`soft\n",
      "     |      clipped` bases (None if not present).\n",
      "     |      \n",
      "     |      Quality scores are returned as a python array of unsigned\n",
      "     |      chars. Note that this is not the ASCII-encoded value typically\n",
      "     |      seen in FASTQ or SAM formatted files. Thus, no offset of 33\n",
      "     |      needs to be subtracted.\n",
      "     |      \n",
      "     |      Note that to set quality scores the sequence has to be set\n",
      "     |      beforehand as this will determine the expected length of the\n",
      "     |      quality score array.\n",
      "     |      \n",
      "     |      This method raises a ValueError if the length of the\n",
      "     |      quality scores and the sequence are not the same.\n",
      "     |  \n",
      "     |  query_sequence\n",
      "     |      read sequence bases, including :term:`soft clipped` bases\n",
      "     |      (None if not present).\n",
      "     |      \n",
      "     |      Note that assigning to seq will invalidate any quality scores.\n",
      "     |      Thus, to in-place edit the sequence and quality scores, copies of\n",
      "     |      the quality scores need to be taken. Consider trimming for example::\n",
      "     |      \n",
      "     |         q = read.query_qualities\n",
      "     |         read.query_squence = read.query_sequence[5:10]\n",
      "     |         read.query_qualities = q[5:10]\n",
      "     |      \n",
      "     |      The sequence is returned as it is stored in the BAM file. Some mappers\n",
      "     |      might have stored a reverse complement of the original read\n",
      "     |      sequence.\n",
      "     |  \n",
      "     |  reference_end\n",
      "     |      aligned reference position of the read on the reference genome.\n",
      "     |      \n",
      "     |      reference_end points to one past the last aligned residue.\n",
      "     |      Returns None if not available (read is unmapped or no cigar\n",
      "     |      alignment present).\n",
      "     |  \n",
      "     |  reference_id\n",
      "     |      :term:`reference` ID\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This field contains the index of the reference sequence in\n",
      "     |          the sequence dictionary. To obtain the name of the\n",
      "     |          reference sequence, use :meth:`get_reference_name()`\n",
      "     |  \n",
      "     |  reference_length\n",
      "     |      aligned length of the read on the reference genome.\n",
      "     |      \n",
      "     |      This is equal to `aend - pos`. Returns None if not available.\n",
      "     |  \n",
      "     |  reference_name\n",
      "     |      :term:`reference` name\n",
      "     |  \n",
      "     |  reference_start\n",
      "     |      0-based leftmost coordinate\n",
      "     |  \n",
      "     |  rlen\n",
      "     |      deprecated, query_length instead\n",
      "     |  \n",
      "     |  rname\n",
      "     |      deprecated, use reference_id instead\n",
      "     |  \n",
      "     |  rnext\n",
      "     |      deprecated, use next_reference_id instead\n",
      "     |  \n",
      "     |  seq\n",
      "     |      deprecated, use query_sequence instead\n",
      "     |  \n",
      "     |  tags\n",
      "     |      deprecated, use get_tags() instead\n",
      "     |  \n",
      "     |  template_length\n",
      "     |      the observed query template length\n",
      "     |  \n",
      "     |  tid\n",
      "     |      deprecated, use reference_id instead\n",
      "     |  \n",
      "     |  tlen\n",
      "     |      deprecated, use template_length instead\n",
      "    \n",
      "    class AlignedSegment(builtins.object)\n",
      "     |  AlignedSegment(AlignmentHeader header=None)\n",
      "     |  Class representing an aligned segment.\n",
      "     |  \n",
      "     |      This class stores a handle to the samtools C-structure representing\n",
      "     |      an aligned read. Member read access is forwarded to the C-structure\n",
      "     |      and converted into python objects. This implementation should be fast,\n",
      "     |      as only the data needed is converted.\n",
      "     |  \n",
      "     |      For write access, the C-structure is updated in-place. This is\n",
      "     |      not the most efficient way to build BAM entries, as the variable\n",
      "     |      length data is concatenated and thus needs to be resized if\n",
      "     |      a field is updated. Furthermore, the BAM entry might be\n",
      "     |      in an inconsistent state.\n",
      "     |  \n",
      "     |      One issue to look out for is that the sequence should always\n",
      "     |      be set *before* the quality scores. Setting the sequence will\n",
      "     |      also erase any quality scores that were set previously.\n",
      "     |  \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |  \n",
      "     |      header -- :class:`~pysam.AlignmentHeader` object to map numerical\n",
      "     |                identifiers to chromosome names. If not given, an empty\n",
      "     |                header is created.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __copy__(...)\n",
      "     |      AlignedSegment.__copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      AlignedSegment.__deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      AlignedSegment.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      AlignedSegment.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      return string representation of alignment.\n",
      "     |      \n",
      "     |      The representation is an approximate :term:`SAM` format, because\n",
      "     |      an aligned read might not be associated with a :term:`AlignmentFile`.\n",
      "     |      As a result :term:`tid` is shown instead of the reference name.\n",
      "     |      Similarly, the tags field is returned in its parsed state.\n",
      "     |      \n",
      "     |      To get a valid SAM record, use :meth:`to_string`.\n",
      "     |  \n",
      "     |  compare(...)\n",
      "     |      AlignedSegment.compare(self, AlignedSegment other)\n",
      "     |      return -1,0,1, if contents in this are binary\n",
      "     |              <,=,> to *other*\n",
      "     |  \n",
      "     |  get_aligned_pairs(...)\n",
      "     |      AlignedSegment.get_aligned_pairs(self, matches_only=False, with_seq=False)\n",
      "     |      a list of aligned read (query) and reference positions.\n",
      "     |      \n",
      "     |              For inserts, deletions, skipping either query or reference\n",
      "     |              position may be None.\n",
      "     |      \n",
      "     |              Padding is currently not supported and leads to an exception.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              matches_only : bool\n",
      "     |                If True, only matched bases are returned - no None on either\n",
      "     |                side.\n",
      "     |              with_seq : bool\n",
      "     |                If True, return a third element in the tuple containing the\n",
      "     |                reference sequence. Substitutions are lower-case. This option\n",
      "     |                requires an MD tag to be present.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              aligned_pairs : list of tuples\n",
      "     |  \n",
      "     |  get_blocks(...)\n",
      "     |      AlignedSegment.get_blocks(self)\n",
      "     |      a list of start and end positions of\n",
      "     |             aligned gapless blocks.\n",
      "     |      \n",
      "     |             The start and end positions are in genomic\n",
      "     |             coordinates.\n",
      "     |      \n",
      "     |             Blocks are not normalized, i.e. two blocks\n",
      "     |             might be directly adjacent. This happens if\n",
      "     |             the two blocks are separated by an insertion\n",
      "     |             in the read.\n",
      "     |  \n",
      "     |  get_cigar_stats(...)\n",
      "     |      AlignedSegment.get_cigar_stats(self)\n",
      "     |      summary of operations in cigar string.\n",
      "     |      \n",
      "     |              The output order in the array is \"MIDNSHP=X\" followed by a\n",
      "     |              field for the NM tag. If the NM tag is not present, this\n",
      "     |              field will always be 0.\n",
      "     |      \n",
      "     |              +-----+--------------+-----+\n",
      "     |              |M    |BAM_CMATCH    |0    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |I    |BAM_CINS      |1    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |D    |BAM_CDEL      |2    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |N    |BAM_CREF_SKIP |3    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |S    |BAM_CSOFT_CLIP|4    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |H    |BAM_CHARD_CLIP|5    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |P    |BAM_CPAD      |6    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |=    |BAM_CEQUAL    |7    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |X    |BAM_CDIFF     |8    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |B    |BAM_CBACK     |9    |\n",
      "     |              +-----+--------------+-----+\n",
      "     |              |NM   |NM tag        |10   |\n",
      "     |              +-----+--------------+-----+\n",
      "     |      \n",
      "     |              If no cigar string is present, empty arrays will be returned.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              arrays : two arrays. The first contains the nucleotide counts within\n",
      "     |                 each cigar operation, the second contains the number of blocks for\n",
      "     |                 each cigar operation.\n",
      "     |  \n",
      "     |  get_forward_qualities(...)\n",
      "     |      AlignedSegment.get_forward_qualities(self)\n",
      "     |      return the original read sequence.\n",
      "     |              \n",
      "     |              Reads mapping to the reverse strand will be reverse\n",
      "     |              complemented.\n",
      "     |  \n",
      "     |  get_forward_sequence(...)\n",
      "     |      AlignedSegment.get_forward_sequence(self)\n",
      "     |      return the original read sequence.\n",
      "     |              \n",
      "     |              Reads mapping to the reverse strand will be reverse\n",
      "     |              complemented.\n",
      "     |      \n",
      "     |              Returns None if the record has no query sequence.\n",
      "     |  \n",
      "     |  get_overlap(...)\n",
      "     |      AlignedSegment.get_overlap(self, uint32_t start, uint32_t end)\n",
      "     |      return number of aligned bases of read overlapping the interval\n",
      "     |              *start* and *end* on the reference sequence.\n",
      "     |      \n",
      "     |              Return None if cigar alignment is not available.\n",
      "     |  \n",
      "     |  get_reference_positions(...)\n",
      "     |      AlignedSegment.get_reference_positions(self, full_length=False)\n",
      "     |      a list of reference positions that this read aligns to.\n",
      "     |      \n",
      "     |              By default, this method only returns positions in the\n",
      "     |              reference that are within the alignment. If *full_length* is\n",
      "     |              set, None values will be included for any soft-clipped or\n",
      "     |              unaligned positions within the read. The returned list will\n",
      "     |              thus be of the same length as the read.\n",
      "     |  \n",
      "     |  get_reference_sequence(...)\n",
      "     |      AlignedSegment.get_reference_sequence(self)\n",
      "     |      return the reference sequence in the region that is covered by the\n",
      "     |              alignment of the read to the reference.\n",
      "     |      \n",
      "     |              This method requires the MD tag to be set.\n",
      "     |  \n",
      "     |  get_tag(...)\n",
      "     |      AlignedSegment.get_tag(self, tag, with_value_type=False)\n",
      "     |      \n",
      "     |      retrieves data from the optional alignment section\n",
      "     |      given a two-letter *tag* denoting the field.\n",
      "     |      \n",
      "     |      The returned value is cast into an appropriate python type.\n",
      "     |      \n",
      "     |      This method is the fastest way to access the optional\n",
      "     |      alignment section if only few tags need to be retrieved.\n",
      "     |      \n",
      "     |      Possible value types are \"AcCsSiIfZHB\" (see BAM format\n",
      "     |      specification) as well as additional value type 'd' as\n",
      "     |      implemented in htslib.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      tag :\n",
      "     |          data tag.\n",
      "     |      \n",
      "     |      with_value_type : Optional[bool]\n",
      "     |          if set to True, the return value is a tuple of (tag value, type code).\n",
      "     |          (default False)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      \n",
      "     |      A python object with the value of the `tag`. The type of the\n",
      "     |      object depends on the data type in the data record.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      \n",
      "     |      KeyError\n",
      "     |          If `tag` is not present, a KeyError is raised.\n",
      "     |  \n",
      "     |  get_tags(...)\n",
      "     |      AlignedSegment.get_tags(self, with_value_type=False)\n",
      "     |      the fields in the optional aligment section.\n",
      "     |      \n",
      "     |              Returns a list of all fields in the optional\n",
      "     |              alignment section. Values are converted to appropriate python\n",
      "     |              values. For example:\n",
      "     |      \n",
      "     |              [(NM, 2), (RG, \"GJP00TM04\")]\n",
      "     |      \n",
      "     |              If *with_value_type* is set, the value type as encode in\n",
      "     |              the AlignedSegment record will be returned as well:\n",
      "     |      \n",
      "     |              [(NM, 2, \"i\"), (RG, \"GJP00TM04\", \"Z\")]\n",
      "     |      \n",
      "     |              This method will convert all values in the optional alignment\n",
      "     |              section. When getting only one or few tags, please see\n",
      "     |              :meth:`get_tag` for a quicker way to achieve this.\n",
      "     |  \n",
      "     |  has_tag(...)\n",
      "     |      AlignedSegment.has_tag(self, tag)\n",
      "     |      returns true if the optional alignment section\n",
      "     |              contains a given *tag*.\n",
      "     |  \n",
      "     |  infer_query_length(...)\n",
      "     |      AlignedSegment.infer_query_length(self, always=False)\n",
      "     |      infer query length from CIGAR alignment.\n",
      "     |      \n",
      "     |              This method deduces the query length from the CIGAR alignment\n",
      "     |              but does not include hard-clipped bases.\n",
      "     |      \n",
      "     |              Returns None if CIGAR alignment is not present.\n",
      "     |      \n",
      "     |              If *always* is set to True, `infer_read_length` is used instead.\n",
      "     |              This is deprecated and only present for backward compatibility.\n",
      "     |  \n",
      "     |  infer_read_length(...)\n",
      "     |      AlignedSegment.infer_read_length(self)\n",
      "     |      infer read length from CIGAR alignment.\n",
      "     |      \n",
      "     |              This method deduces the read length from the CIGAR alignment\n",
      "     |              including hard-clipped bases.\n",
      "     |      \n",
      "     |              Returns None if CIGAR alignment is not present.\n",
      "     |  \n",
      "     |  opt(...)\n",
      "     |      AlignedSegment.opt(self, tag)\n",
      "     |      deprecated, use get_tag() instead\n",
      "     |  \n",
      "     |  overlap(...)\n",
      "     |      AlignedSegment.overlap(self)\n",
      "     |      deprecated, use get_overlap() instead\n",
      "     |  \n",
      "     |  setTag(...)\n",
      "     |      AlignedSegment.setTag(self, tag, value, value_type=None, replace=True)\n",
      "     |      deprecated, use set_tag() instead\n",
      "     |  \n",
      "     |  set_tag(...)\n",
      "     |      AlignedSegment.set_tag(self, tag, value, value_type=None, replace=True)\n",
      "     |      sets a particular field *tag* to *value* in the optional alignment\n",
      "     |              section.\n",
      "     |      \n",
      "     |              *value_type* describes the type of *value* that is to entered\n",
      "     |              into the alignment record. It can be set explicitly to one of\n",
      "     |              the valid one-letter type codes. If unset, an appropriate type\n",
      "     |              will be chosen automatically based on the python type of\n",
      "     |              *value*.\n",
      "     |      \n",
      "     |              An existing value of the same *tag* will be overwritten unless\n",
      "     |              *replace* is set to False. This is usually not recommened as a\n",
      "     |              tag may only appear once in the optional alignment section.\n",
      "     |      \n",
      "     |              If *value* is None, the tag will be deleted.\n",
      "     |      \n",
      "     |              This method accepts valid SAM specification value types, which\n",
      "     |              are::\n",
      "     |              \n",
      "     |                 A: printable char\n",
      "     |                 i: signed int\n",
      "     |                 f: float\n",
      "     |                 Z: printable string\n",
      "     |                 H: Byte array in hex format\n",
      "     |                 B: Integer or numeric array\n",
      "     |      \n",
      "     |              Additionally, it will accept the integer BAM types ('cCsSI')\n",
      "     |      \n",
      "     |              For htslib compatibility, 'a' is synonymous with 'A' and the\n",
      "     |              method accepts a 'd' type code for a double precision float.\n",
      "     |      \n",
      "     |              When deducing the type code by the python type of *value*, the\n",
      "     |              following mapping is applied::\n",
      "     |              \n",
      "     |                  i: python int\n",
      "     |                  f: python float\n",
      "     |                  Z: python str or bytes\n",
      "     |                  B: python array.array, list or tuple\n",
      "     |                  \n",
      "     |              Note that a single character string will be output as 'Z' and\n",
      "     |              not 'A' as the former is the more general type.\n",
      "     |  \n",
      "     |  set_tags(...)\n",
      "     |      AlignedSegment.set_tags(self, tags)\n",
      "     |      sets the fields in the optional alignment section with\n",
      "     |              a list of (tag, value) tuples.\n",
      "     |      \n",
      "     |              The :term:`value type` of the values is determined from the\n",
      "     |              python type. Optionally, a type may be given explicitly as\n",
      "     |              a third value in the tuple, For example:\n",
      "     |      \n",
      "     |              x.set_tags([(NM, 2, \"i\"), (RG, \"GJP00TM04\", \"Z\")]\n",
      "     |      \n",
      "     |              This method will not enforce the rule that the same tag may appear\n",
      "     |              only once in the optional alignment section.\n",
      "     |  \n",
      "     |  to_dict(...)\n",
      "     |      AlignedSegment.to_dict(self)\n",
      "     |      returns a json representation of the aligned segment.\n",
      "     |      \n",
      "     |              Field names are abbreviated versions of the class attributes.\n",
      "     |  \n",
      "     |  to_string(...)\n",
      "     |      AlignedSegment.to_string(self)\n",
      "     |      returns a string representation of the aligned segment.\n",
      "     |      \n",
      "     |              The output format is valid SAM format if a header is associated\n",
      "     |              with the AlignedSegment.\n",
      "     |  \n",
      "     |  tostring(...)\n",
      "     |      AlignedSegment.tostring(self, htsfile=None)\n",
      "     |      deprecated, use :meth:`to_string()` instead.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              htsfile -- (deprecated) AlignmentFile object to map numerical\n",
      "     |                         identifiers to chromosome names. This parameter is present\n",
      "     |                         for backwards compatibility and ignored.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_dict(...) from builtins.type\n",
      "     |      AlignedSegment.from_dict(type cls, sam_dict, AlignmentHeader header)\n",
      "     |      parses a dictionary representation of the aligned segment.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |              sam_dict -- dictionary of alignment values, keys corresponding to output from\n",
      "     |                          :meth:`todict()`.\n",
      "     |  \n",
      "     |  fromstring(...) from builtins.type\n",
      "     |      AlignedSegment.fromstring(type cls, sam, AlignmentHeader header)\n",
      "     |      parses a string representation of the aligned segment.\n",
      "     |      \n",
      "     |              The input format should be valid SAM format.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |              sam -- :term:`SAM` formatted string\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  aend\n",
      "     |      deprecated, reference_end instead\n",
      "     |  \n",
      "     |  alen\n",
      "     |      deprecated, reference_length instead\n",
      "     |  \n",
      "     |  aligned_pairs\n",
      "     |      deprecated, use get_aligned_pairs() instead\n",
      "     |  \n",
      "     |  bin\n",
      "     |      properties bin\n",
      "     |  \n",
      "     |  blocks\n",
      "     |      deprecated, use get_blocks() instead\n",
      "     |  \n",
      "     |  cigar\n",
      "     |      deprecated, use cigartuples instead\n",
      "     |  \n",
      "     |  cigarstring\n",
      "     |      the :term:`cigar` alignment as a string.\n",
      "     |      \n",
      "     |      The cigar string is a string of alternating integers\n",
      "     |      and characters denoting the length and the type of\n",
      "     |      an operation.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          The order length,operation is specified in the\n",
      "     |          SAM format. It is different from the order of\n",
      "     |          the :attr:`cigar` property.\n",
      "     |      \n",
      "     |      Returns None if not present.\n",
      "     |      \n",
      "     |      To unset the cigarstring, assign None or the\n",
      "     |      empty string.\n",
      "     |  \n",
      "     |  cigartuples\n",
      "     |      the :term:`cigar` alignment. The alignment\n",
      "     |      is returned as a list of tuples of (operation, length).\n",
      "     |      \n",
      "     |      If the alignment is not present, None is returned.\n",
      "     |      \n",
      "     |      The operations are:\n",
      "     |      \n",
      "     |      +-----+--------------+-----+\n",
      "     |      |M    |BAM_CMATCH    |0    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |I    |BAM_CINS      |1    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |D    |BAM_CDEL      |2    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |N    |BAM_CREF_SKIP |3    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |S    |BAM_CSOFT_CLIP|4    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |H    |BAM_CHARD_CLIP|5    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |P    |BAM_CPAD      |6    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |=    |BAM_CEQUAL    |7    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |X    |BAM_CDIFF     |8    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      |B    |BAM_CBACK     |9    |\n",
      "     |      +-----+--------------+-----+\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          The output is a list of (operation, length) tuples, such as\n",
      "     |          ``[(0, 30)]``.\n",
      "     |          This is different from the SAM specification and\n",
      "     |          the :attr:`cigarstring` property, which uses a\n",
      "     |          (length, operation) order, for example: ``30M``.\n",
      "     |      \n",
      "     |      To unset the cigar property, assign an empty list\n",
      "     |      or None.\n",
      "     |  \n",
      "     |  flag\n",
      "     |      properties flag\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  inferred_length\n",
      "     |      deprecated, use infer_query_length() instead\n",
      "     |  \n",
      "     |  is_duplicate\n",
      "     |      true if optical or PCR duplicate\n",
      "     |  \n",
      "     |  is_paired\n",
      "     |      true if read is paired in sequencing\n",
      "     |  \n",
      "     |  is_proper_pair\n",
      "     |      true if read is mapped in a proper pair\n",
      "     |  \n",
      "     |  is_qcfail\n",
      "     |      true if QC failure\n",
      "     |  \n",
      "     |  is_read1\n",
      "     |      true if this is read1\n",
      "     |  \n",
      "     |  is_read2\n",
      "     |      true if this is read2\n",
      "     |  \n",
      "     |  is_reverse\n",
      "     |      true if read is mapped to reverse strand\n",
      "     |  \n",
      "     |  is_secondary\n",
      "     |      true if not primary alignment\n",
      "     |  \n",
      "     |  is_supplementary\n",
      "     |      true if this is a supplementary alignment\n",
      "     |  \n",
      "     |  is_unmapped\n",
      "     |      true if read itself is unmapped\n",
      "     |  \n",
      "     |  isize\n",
      "     |      deprecated, use template_length instead\n",
      "     |  \n",
      "     |  mapping_quality\n",
      "     |      mapping quality\n",
      "     |  \n",
      "     |  mapq\n",
      "     |      deprecated, use mapping_quality instead\n",
      "     |  \n",
      "     |  mate_is_reverse\n",
      "     |      true is read is mapped to reverse strand\n",
      "     |  \n",
      "     |  mate_is_unmapped\n",
      "     |      true if the mate is unmapped\n",
      "     |  \n",
      "     |  mpos\n",
      "     |      deprecated, use next_reference_start instead\n",
      "     |  \n",
      "     |  mrnm\n",
      "     |      deprecated, use next_reference_id instead\n",
      "     |  \n",
      "     |  next_reference_id\n",
      "     |      the :term:`reference` id of the mate/next read.\n",
      "     |  \n",
      "     |  next_reference_name\n",
      "     |      :term:`reference` name of the mate/next read (None if no\n",
      "     |      AlignmentFile is associated)\n",
      "     |  \n",
      "     |  next_reference_start\n",
      "     |      the position of the mate/next read.\n",
      "     |  \n",
      "     |  pnext\n",
      "     |      deprecated, use next_reference_start instead\n",
      "     |  \n",
      "     |  pos\n",
      "     |      deprecated, use reference_start instead\n",
      "     |  \n",
      "     |  positions\n",
      "     |      deprecated, use get_reference_positions() instead\n",
      "     |  \n",
      "     |  qend\n",
      "     |      deprecated, use query_alignment_end instead\n",
      "     |  \n",
      "     |  qlen\n",
      "     |      deprecated, use query_alignment_length instead\n",
      "     |  \n",
      "     |  qname\n",
      "     |      deprecated, use query_name instead\n",
      "     |  \n",
      "     |  qqual\n",
      "     |      deprecated, query_alignment_qualities instead\n",
      "     |  \n",
      "     |  qstart\n",
      "     |      deprecated, use query_alignment_start instead\n",
      "     |  \n",
      "     |  qual\n",
      "     |      deprecated, query_qualities instead\n",
      "     |  \n",
      "     |  query\n",
      "     |      deprecated, query_alignment_sequence instead\n",
      "     |  \n",
      "     |  query_alignment_end\n",
      "     |      end index of the aligned query portion of the sequence (0-based,\n",
      "     |      exclusive)\n",
      "     |      \n",
      "     |      This the index just past the last base in :attr:`seq` that is not\n",
      "     |      soft-clipped.\n",
      "     |  \n",
      "     |  query_alignment_length\n",
      "     |      length of the aligned query sequence.\n",
      "     |      \n",
      "     |      This is equal to :attr:`qend` - :attr:`qstart`\n",
      "     |  \n",
      "     |  query_alignment_qualities\n",
      "     |      aligned query sequence quality values (None if not present). These\n",
      "     |      are the quality values that correspond to :attr:`query`, that\n",
      "     |      is, they exclude qualities of :term:`soft clipped` bases. This\n",
      "     |      is equal to ``qual[qstart:qend]``.\n",
      "     |      \n",
      "     |      Quality scores are returned as a python array of unsigned\n",
      "     |      chars. Note that this is not the ASCII-encoded value typically\n",
      "     |      seen in FASTQ or SAM formatted files. Thus, no offset of 33\n",
      "     |      needs to be subtracted.\n",
      "     |      \n",
      "     |      This property is read-only.\n",
      "     |  \n",
      "     |  query_alignment_sequence\n",
      "     |      aligned portion of the read.\n",
      "     |      \n",
      "     |      This is a substring of :attr:`seq` that excludes flanking\n",
      "     |      bases that were :term:`soft clipped` (None if not present). It\n",
      "     |      is equal to ``seq[qstart:qend]``.\n",
      "     |      \n",
      "     |      SAM/BAM files may include extra flanking bases that are not\n",
      "     |      part of the alignment.  These bases may be the result of the\n",
      "     |      Smith-Waterman or other algorithms, which may not require\n",
      "     |      alignments that begin at the first residue or end at the last.\n",
      "     |      In addition, extra sequencing adapters, multiplex identifiers,\n",
      "     |      and low-quality bases that were not considered for alignment\n",
      "     |      may have been retained.\n",
      "     |  \n",
      "     |  query_alignment_start\n",
      "     |      start index of the aligned query portion of the sequence (0-based,\n",
      "     |      inclusive).\n",
      "     |      \n",
      "     |      This the index of the first base in :attr:`seq` that is not\n",
      "     |      soft-clipped.\n",
      "     |  \n",
      "     |  query_length\n",
      "     |      the length of the query/read.\n",
      "     |      \n",
      "     |      This value corresponds to the length of the sequence supplied\n",
      "     |      in the BAM/SAM file. The length of a query is 0 if there is no\n",
      "     |      sequence in the BAM/SAM file. In those cases, the read length\n",
      "     |      can be inferred from the CIGAR alignment, see\n",
      "     |      :meth:`pysam.AlignedSegment.infer_query_length`.\n",
      "     |      \n",
      "     |      The length includes soft-clipped bases and is equal to\n",
      "     |      ``len(query_sequence)``.\n",
      "     |      \n",
      "     |      This property is read-only but can be set by providing a\n",
      "     |      sequence.\n",
      "     |      \n",
      "     |      Returns 0 if not available.\n",
      "     |  \n",
      "     |  query_name\n",
      "     |      the query template name (None if not present)\n",
      "     |  \n",
      "     |  query_qualities\n",
      "     |      read sequence base qualities, including :term:`soft\n",
      "     |      clipped` bases (None if not present).\n",
      "     |      \n",
      "     |      Quality scores are returned as a python array of unsigned\n",
      "     |      chars. Note that this is not the ASCII-encoded value typically\n",
      "     |      seen in FASTQ or SAM formatted files. Thus, no offset of 33\n",
      "     |      needs to be subtracted.\n",
      "     |      \n",
      "     |      Note that to set quality scores the sequence has to be set\n",
      "     |      beforehand as this will determine the expected length of the\n",
      "     |      quality score array.\n",
      "     |      \n",
      "     |      This method raises a ValueError if the length of the\n",
      "     |      quality scores and the sequence are not the same.\n",
      "     |  \n",
      "     |  query_sequence\n",
      "     |      read sequence bases, including :term:`soft clipped` bases\n",
      "     |      (None if not present).\n",
      "     |      \n",
      "     |      Note that assigning to seq will invalidate any quality scores.\n",
      "     |      Thus, to in-place edit the sequence and quality scores, copies of\n",
      "     |      the quality scores need to be taken. Consider trimming for example::\n",
      "     |      \n",
      "     |         q = read.query_qualities\n",
      "     |         read.query_squence = read.query_sequence[5:10]\n",
      "     |         read.query_qualities = q[5:10]\n",
      "     |      \n",
      "     |      The sequence is returned as it is stored in the BAM file. Some mappers\n",
      "     |      might have stored a reverse complement of the original read\n",
      "     |      sequence.\n",
      "     |  \n",
      "     |  reference_end\n",
      "     |      aligned reference position of the read on the reference genome.\n",
      "     |      \n",
      "     |      reference_end points to one past the last aligned residue.\n",
      "     |      Returns None if not available (read is unmapped or no cigar\n",
      "     |      alignment present).\n",
      "     |  \n",
      "     |  reference_id\n",
      "     |      :term:`reference` ID\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This field contains the index of the reference sequence in\n",
      "     |          the sequence dictionary. To obtain the name of the\n",
      "     |          reference sequence, use :meth:`get_reference_name()`\n",
      "     |  \n",
      "     |  reference_length\n",
      "     |      aligned length of the read on the reference genome.\n",
      "     |      \n",
      "     |      This is equal to `aend - pos`. Returns None if not available.\n",
      "     |  \n",
      "     |  reference_name\n",
      "     |      :term:`reference` name\n",
      "     |  \n",
      "     |  reference_start\n",
      "     |      0-based leftmost coordinate\n",
      "     |  \n",
      "     |  rlen\n",
      "     |      deprecated, query_length instead\n",
      "     |  \n",
      "     |  rname\n",
      "     |      deprecated, use reference_id instead\n",
      "     |  \n",
      "     |  rnext\n",
      "     |      deprecated, use next_reference_id instead\n",
      "     |  \n",
      "     |  seq\n",
      "     |      deprecated, use query_sequence instead\n",
      "     |  \n",
      "     |  tags\n",
      "     |      deprecated, use get_tags() instead\n",
      "     |  \n",
      "     |  template_length\n",
      "     |      the observed query template length\n",
      "     |  \n",
      "     |  tid\n",
      "     |      deprecated, use reference_id instead\n",
      "     |  \n",
      "     |  tlen\n",
      "     |      deprecated, use template_length instead\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "    \n",
      "    class AlignmentFile(pysam.libchtslib.HTSFile)\n",
      "     |  AlignmentFile(filepath_or_object, mode=None, template=None,\n",
      "     |  reference_names=None, reference_lengths=None, text=NULL,\n",
      "     |  header=None, add_sq_text=False, check_header=True, check_sq=True,\n",
      "     |  reference_filename=None, filename=None, index_filename=None,\n",
      "     |  filepath_index=None, require_index=False, duplicate_filehandle=True,\n",
      "     |  ignore_truncation=False, threads=1)\n",
      "     |  \n",
      "     |  A :term:`SAM`/:term:`BAM`/:term:`CRAM` formatted file.\n",
      "     |  \n",
      "     |  If `filepath_or_object` is a string, the file is automatically\n",
      "     |  opened. If `filepath_or_object` is a python File object, the\n",
      "     |  already opened file will be used.\n",
      "     |  \n",
      "     |  If the file is opened for reading and an index exists (if file is BAM, a\n",
      "     |  .bai file or if CRAM a .crai file), it will be opened automatically.\n",
      "     |  `index_filename` may be specified explicitly. If the index is not named\n",
      "     |  in the standard manner, not located in the same directory as the\n",
      "     |  BAM/CRAM file, or is remote.  Without an index, random access via\n",
      "     |  :meth:`~pysam.AlignmentFile.fetch` and :meth:`~pysam.AlignmentFile.pileup`\n",
      "     |  is disabled.\n",
      "     |  \n",
      "     |  For writing, the header of a :term:`SAM` file/:term:`BAM` file can\n",
      "     |  be constituted from several sources (see also the samtools format\n",
      "     |  specification):\n",
      "     |  \n",
      "     |      1. If `template` is given, the header is copied from a another\n",
      "     |         `AlignmentFile` (`template` must be a\n",
      "     |         :class:`~pysam.AlignmentFile`).\n",
      "     |  \n",
      "     |      2. If `header` is given, the header is built from a\n",
      "     |         multi-level dictionary.\n",
      "     |  \n",
      "     |      3. If `text` is given, new header text is copied from raw\n",
      "     |         text.\n",
      "     |  \n",
      "     |      4. The names (`reference_names`) and lengths\n",
      "     |         (`reference_lengths`) are supplied directly as lists.\n",
      "     |  \n",
      "     |  When reading or writing a CRAM file, the filename of a FASTA-formatted\n",
      "     |  reference can be specified with `reference_filename`.\n",
      "     |  \n",
      "     |  By default, if a file is opened in mode 'r', it is checked\n",
      "     |  for a valid header (`check_header` = True) and a definition of\n",
      "     |  chromosome names (`check_sq` = True).\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  mode : string\n",
      "     |      `mode` should be ``r`` for reading or ``w`` for writing. The\n",
      "     |      default is text mode (:term:`SAM`). For binary (:term:`BAM`)\n",
      "     |      I/O you should append ``b`` for compressed or ``u`` for\n",
      "     |      uncompressed :term:`BAM` output.  Use ``h`` to output header\n",
      "     |      information in text (:term:`TAM`) mode. Use ``c`` for\n",
      "     |      :term:`CRAM` formatted files.\n",
      "     |  \n",
      "     |      If ``b`` is present, it must immediately follow ``r`` or\n",
      "     |      ``w``.  Valid modes are ``r``, ``w``, ``wh``, ``rb``, ``wb``,\n",
      "     |      ``wbu``, ``wb0``, ``rc`` and ``wc``. For instance, to open a\n",
      "     |      :term:`BAM` formatted file for reading, type::\n",
      "     |  \n",
      "     |         f = pysam.AlignmentFile('ex1.bam','rb')\n",
      "     |  \n",
      "     |      If mode is not specified, the method will try to auto-detect\n",
      "     |      in the order 'rb', 'r', thus both the following should work::\n",
      "     |  \n",
      "     |          f1 = pysam.AlignmentFile('ex1.bam')\n",
      "     |          f2 = pysam.AlignmentFile('ex1.sam')\n",
      "     |  \n",
      "     |  template : AlignmentFile\n",
      "     |      when writing, copy header from file `template`.\n",
      "     |  \n",
      "     |  header :  dict or AlignmentHeader\n",
      "     |      when writing, build header from a multi-level dictionary. The\n",
      "     |      first level are the four types ('HD', 'SQ', ...). The second\n",
      "     |      level are a list of lines, with each line being a list of\n",
      "     |      tag-value pairs. The header is constructed first from all the\n",
      "     |      defined fields, followed by user tags in alphabetical\n",
      "     |      order. Alternatively, an :class:`~pysam.AlignmentHeader`\n",
      "     |      object can be passed directly.\n",
      "     |  \n",
      "     |  text : string\n",
      "     |      when writing, use the string provided as the header\n",
      "     |  \n",
      "     |  reference_names : list\n",
      "     |      see reference_lengths\n",
      "     |  \n",
      "     |  reference_lengths : list\n",
      "     |      when writing or opening a SAM file without header build header\n",
      "     |      from list of chromosome names and lengths.  By default, 'SQ'\n",
      "     |      and 'LN' tags will be added to the header text. This option\n",
      "     |      can be changed by unsetting the flag `add_sq_text`.\n",
      "     |  \n",
      "     |  add_sq_text : bool\n",
      "     |      do not add 'SQ' and 'LN' tags to header. This option permits\n",
      "     |      construction :term:`SAM` formatted files without a header.\n",
      "     |  \n",
      "     |  add_sam_header : bool\n",
      "     |      when outputting SAM the default is to output a header. This is\n",
      "     |      equivalent to opening the file in 'wh' mode. If this option is\n",
      "     |      set to False, no header will be output. To read such a file,\n",
      "     |      set `check_header=False`.\n",
      "     |  \n",
      "     |  check_header : bool\n",
      "     |      obsolete: when reading a SAM file, check if header is present\n",
      "     |      (default=True)\n",
      "     |  \n",
      "     |  check_sq : bool\n",
      "     |      when reading, check if SQ entries are present in header\n",
      "     |      (default=True)\n",
      "     |  \n",
      "     |  reference_filename : string\n",
      "     |      Path to a FASTA-formatted reference file. Valid only for CRAM files.\n",
      "     |      When reading a CRAM file, this overrides both ``$REF_PATH`` and the URL\n",
      "     |      specified in the header (``UR`` tag), which are normally used to find\n",
      "     |      the reference.\n",
      "     |  \n",
      "     |  index_filename : string\n",
      "     |      Explicit path to the index file.  Only needed if the index is not\n",
      "     |      named in the standard manner, not located in the same directory as\n",
      "     |      the BAM/CRAM file, or is remote.  An IOError is raised if the index\n",
      "     |      cannot be found or is invalid.\n",
      "     |  \n",
      "     |  filepath_index : string\n",
      "     |      Alias for `index_filename`.\n",
      "     |  \n",
      "     |  require_index : bool\n",
      "     |      When reading, require that an index file is present and is valid or\n",
      "     |      raise an IOError.  (default=False)\n",
      "     |  \n",
      "     |  filename : string\n",
      "     |      Alternative to filepath_or_object. Filename of the file\n",
      "     |      to be opened.\n",
      "     |  \n",
      "     |  duplicate_filehandle: bool\n",
      "     |      By default, file handles passed either directly or through\n",
      "     |      File-like objects will be duplicated before passing them to\n",
      "     |      htslib. The duplication prevents issues where the same stream\n",
      "     |      will be closed by htslib and through destruction of the\n",
      "     |      high-level python object. Set to False to turn off\n",
      "     |      duplication.\n",
      "     |  \n",
      "     |  ignore_truncation: bool\n",
      "     |      Issue a warning, instead of raising an error if the current file\n",
      "     |      appears to be truncated due to a missing EOF marker.  Only applies\n",
      "     |      to bgzipped formats. (Default=False)\n",
      "     |  \n",
      "     |  format_options: list\n",
      "     |      A list of key=value strings, as accepted by --input-fmt-option and\n",
      "     |      --output-fmt-option in samtools.\n",
      "     |  threads: integer\n",
      "     |      Number of threads to use for compressing/decompressing BAM/CRAM files.\n",
      "     |      Setting threads to > 1 cannot be combined with `ignore_truncation`.\n",
      "     |      (Default=1)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AlignmentFile\n",
      "     |      pysam.libchtslib.HTSFile\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(...)\n",
      "     |      AlignmentFile.__enter__(self)\n",
      "     |  \n",
      "     |  __exit__(...)\n",
      "     |      AlignmentFile.__exit__(self, exc_type, exc_value, traceback)\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __next__(...)\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      AlignmentFile.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      AlignmentFile.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  check_index(...)\n",
      "     |      AlignmentFile.check_index(self)\n",
      "     |      return True if index is present.\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              AttributeError\n",
      "     |                  if htsfile is :term:`SAM` formatted and thus has no index.\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                  if htsfile is closed or index could not be opened.\n",
      "     |  \n",
      "     |  close(...)\n",
      "     |      AlignmentFile.close(self)\n",
      "     |      closes the :class:`pysam.AlignmentFile`.\n",
      "     |  \n",
      "     |  count(...)\n",
      "     |      AlignmentFile.count(self, contig=None, start=None, stop=None, region=None, until_eof=False, read_callback='nofilter', reference=None, end=None)\n",
      "     |      count the number of reads in :term:`region`\n",
      "     |      \n",
      "     |              The region is specified by :term:`contig`, `start` and `stop`.\n",
      "     |              :term:`reference` and `end` are also accepted for backward\n",
      "     |              compatiblity as synonyms for :term:`contig` and `stop`,\n",
      "     |              respectively.  Alternatively, a :term:`samtools` :term:`region`\n",
      "     |              string can be supplied.\n",
      "     |      \n",
      "     |              A :term:`SAM` file does not allow random access and if\n",
      "     |              `region` or `contig` are given, an exception is raised.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              contig : string\n",
      "     |                  reference_name of the genomic region (chromosome)\n",
      "     |      \n",
      "     |              start : int\n",
      "     |                  start of the genomic region (0-based inclusive)\n",
      "     |      \n",
      "     |              stop : int\n",
      "     |                  end of the genomic region (0-based exclusive)\n",
      "     |      \n",
      "     |              region : string\n",
      "     |                  a region string in samtools format.\n",
      "     |      \n",
      "     |              until_eof : bool\n",
      "     |                  count until the end of the file, possibly including\n",
      "     |                  unmapped reads as well.\n",
      "     |      \n",
      "     |              read_callback: string or function\n",
      "     |      \n",
      "     |                  select a call-back to ignore reads when counting. It can\n",
      "     |                  be either a string with the following values:\n",
      "     |      \n",
      "     |                  ``all``\n",
      "     |                      skip reads in which any of the following\n",
      "     |                      flags are set: BAM_FUNMAP, BAM_FSECONDARY, BAM_FQCFAIL,\n",
      "     |                      BAM_FDUP\n",
      "     |      \n",
      "     |                  ``nofilter``\n",
      "     |                      uses every single read\n",
      "     |      \n",
      "     |                  Alternatively, `read_callback` can be a function\n",
      "     |                  ``check_read(read)`` that should return True only for\n",
      "     |                  those reads that shall be included in the counting.\n",
      "     |      \n",
      "     |              reference : string\n",
      "     |                  backward compatible synonym for `contig`\n",
      "     |      \n",
      "     |              end : int\n",
      "     |                  backward compatible synonym for `stop`\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                  if the genomic coordinates are out of range or invalid.\n",
      "     |  \n",
      "     |  count_coverage(...)\n",
      "     |      AlignmentFile.count_coverage(self, contig, start=None, stop=None, region=None, quality_threshold=15, read_callback='all', reference=None, end=None)\n",
      "     |      count the coverage of genomic positions by reads in :term:`region`.\n",
      "     |      \n",
      "     |              The region is specified by :term:`contig`, `start` and `stop`.\n",
      "     |              :term:`reference` and `end` are also accepted for backward\n",
      "     |              compatiblity as synonyms for :term:`contig` and `stop`,\n",
      "     |              respectively.  Alternatively, a :term:`samtools` :term:`region`\n",
      "     |              string can be supplied.  The coverage is computed per-base [ACGT].\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              contig : string\n",
      "     |                  reference_name of the genomic region (chromosome)\n",
      "     |      \n",
      "     |              start : int\n",
      "     |                  start of the genomic region (0-based inclusive). If not\n",
      "     |                  given, count from the start of the chromosome.\n",
      "     |      \n",
      "     |              stop : int\n",
      "     |                  end of the genomic region (0-based exclusive). If not given,\n",
      "     |                  count to the end of the chromosome.\n",
      "     |      \n",
      "     |              region : int\n",
      "     |                  a region string.\n",
      "     |      \n",
      "     |              quality_threshold : int\n",
      "     |                  quality_threshold is the minimum quality score (in phred) a\n",
      "     |                  base has to reach to be counted.\n",
      "     |      \n",
      "     |              read_callback: string or function\n",
      "     |      \n",
      "     |                  select a call-back to ignore reads when counting. It can\n",
      "     |                  be either a string with the following values:\n",
      "     |      \n",
      "     |                  ``all``\n",
      "     |                      skip reads in which any of the following\n",
      "     |                      flags are set: BAM_FUNMAP, BAM_FSECONDARY, BAM_FQCFAIL,\n",
      "     |                      BAM_FDUP\n",
      "     |      \n",
      "     |                  ``nofilter``\n",
      "     |                      uses every single read\n",
      "     |      \n",
      "     |                  Alternatively, `read_callback` can be a function\n",
      "     |                  ``check_read(read)`` that should return True only for\n",
      "     |                  those reads that shall be included in the counting.\n",
      "     |      \n",
      "     |              reference : string\n",
      "     |                  backward compatible synonym for `contig`\n",
      "     |      \n",
      "     |              end : int\n",
      "     |                  backward compatible synonym for `stop`\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                  if the genomic coordinates are out of range or invalid.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              four array.arrays of the same length in order A C G T : tuple\n",
      "     |  \n",
      "     |  fetch(...)\n",
      "     |      AlignmentFile.fetch(self, contig=None, start=None, stop=None, region=None, tid=None, until_eof=False, multiple_iterators=False, reference=None, end=None)\n",
      "     |      fetch reads aligned in a :term:`region`.\n",
      "     |      \n",
      "     |              See :meth:`~pysam.HTSFile.parse_region` for more information\n",
      "     |              on how genomic regions can be specified. :term:`reference` and\n",
      "     |              `end` are also accepted for backward compatiblity as synonyms\n",
      "     |              for :term:`contig` and `stop`, respectively.\n",
      "     |      \n",
      "     |              Without a `contig` or `region` all mapped reads in the file\n",
      "     |              will be fetched. The reads will be returned ordered by reference\n",
      "     |              sequence, which will not necessarily be the order within the\n",
      "     |              file. This mode of iteration still requires an index. If there is\n",
      "     |              no index, use `until_eof=True`.\n",
      "     |      \n",
      "     |              If only `contig` is set, all reads aligned to `contig`\n",
      "     |              will be fetched.\n",
      "     |      \n",
      "     |              A :term:`SAM` file does not allow random access. If `region`\n",
      "     |              or `contig` are given, an exception is raised.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              until_eof : bool\n",
      "     |      \n",
      "     |                 If `until_eof` is True, all reads from the current file\n",
      "     |                 position will be returned in order as they are within the\n",
      "     |                 file. Using this option will also fetch unmapped reads.\n",
      "     |      \n",
      "     |              multiple_iterators : bool\n",
      "     |      \n",
      "     |                 If `multiple_iterators` is True, multiple\n",
      "     |                 iterators on the same file can be used at the same time. The\n",
      "     |                 iterator returned will receive its own copy of a filehandle to\n",
      "     |                 the file effectively re-opening the file. Re-opening a file\n",
      "     |                 creates some overhead, so beware.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              An iterator over a collection of reads.\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                  if the genomic coordinates are out of range or invalid or the\n",
      "     |                  file does not permit random access to genomic coordinates.\n",
      "     |  \n",
      "     |  find_introns(...)\n",
      "     |      AlignmentFile.find_introns(self, read_iterator)\n",
      "     |      Return a dictionary {(start, stop): count}\n",
      "     |              Listing the intronic sites in the reads (identified by 'N' in the cigar strings),\n",
      "     |              and their support ( = number of reads ).\n",
      "     |      \n",
      "     |              read_iterator can be the result of a .fetch(...) call.\n",
      "     |              Or it can be a generator filtering such reads. Example\n",
      "     |              samfile.find_introns((read for read in samfile.fetch(...) if read.is_reverse)\n",
      "     |  \n",
      "     |  find_introns_slow(...)\n",
      "     |      AlignmentFile.find_introns_slow(self, read_iterator)\n",
      "     |      Return a dictionary {(start, stop): count}\n",
      "     |              Listing the intronic sites in the reads (identified by 'N' in the cigar strings),\n",
      "     |              and their support ( = number of reads ).\n",
      "     |      \n",
      "     |              read_iterator can be the result of a .fetch(...) call.\n",
      "     |              Or it can be a generator filtering such reads. Example\n",
      "     |              samfile.find_introns((read for read in samfile.fetch(...) if read.is_reverse)\n",
      "     |  \n",
      "     |  get_index_statistics(...)\n",
      "     |      AlignmentFile.get_index_statistics(self)\n",
      "     |      return statistics about mapped/unmapped reads per chromosome as\n",
      "     |              they are stored in the index.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |              list : a list of records for each chromosome. Each record has the attributes 'contig',\n",
      "     |                     'mapped', 'unmapped' and 'total'.\n",
      "     |  \n",
      "     |  get_reference_length(...)\n",
      "     |      AlignmentFile.get_reference_length(self, reference)\n",
      "     |      \n",
      "     |      return :term:`reference` name corresponding to numerical :term:`tid`\n",
      "     |  \n",
      "     |  get_reference_name(...)\n",
      "     |      AlignmentFile.get_reference_name(self, tid)\n",
      "     |      \n",
      "     |      return :term:`reference` name corresponding to numerical :term:`tid`\n",
      "     |  \n",
      "     |  get_tid(...)\n",
      "     |      AlignmentFile.get_tid(self, reference)\n",
      "     |      \n",
      "     |      return the numerical :term:`tid` corresponding to\n",
      "     |      :term:`reference`\n",
      "     |      \n",
      "     |      returns -1 if reference is not known.\n",
      "     |  \n",
      "     |  getrname(...)\n",
      "     |      AlignmentFile.getrname(self, tid)\n",
      "     |      deprecated, use get_reference_name() instead\n",
      "     |  \n",
      "     |  gettid(...)\n",
      "     |      AlignmentFile.gettid(self, reference)\n",
      "     |      deprecated, use get_tid() instead\n",
      "     |  \n",
      "     |  has_index(...)\n",
      "     |      AlignmentFile.has_index(self)\n",
      "     |      return true if htsfile has an existing (and opened) index.\n",
      "     |  \n",
      "     |  head(...)\n",
      "     |      AlignmentFile.head(self, n, multiple_iterators=True)\n",
      "     |      return an iterator over the first n alignments.\n",
      "     |      \n",
      "     |              This iterator is is useful for inspecting the bam-file.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              multiple_iterators : bool\n",
      "     |      \n",
      "     |                  is set to True by default in order to\n",
      "     |                  avoid changing the current file position.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              an iterator over a collection of reads\n",
      "     |  \n",
      "     |  is_valid_tid(...)\n",
      "     |      AlignmentFile.is_valid_tid(self, int tid)\n",
      "     |      \n",
      "     |      return True if the numerical :term:`tid` is valid; False otherwise.\n",
      "     |      \n",
      "     |      Note that the unmapped tid code (-1) counts as an invalid.\n",
      "     |  \n",
      "     |  mate(...)\n",
      "     |      AlignmentFile.mate(self, AlignedSegment read)\n",
      "     |      return the mate of :class:`~pysam.AlignedSegment` `read`.\n",
      "     |      \n",
      "     |              .. note::\n",
      "     |      \n",
      "     |                  Calling this method will change the file position.\n",
      "     |                  This might interfere with any iterators that have\n",
      "     |                  not re-opened the file.\n",
      "     |      \n",
      "     |              .. note::\n",
      "     |      \n",
      "     |                 This method is too slow for high-throughput processing.\n",
      "     |                 If a read needs to be processed with its mate, work\n",
      "     |                 from a read name sorted file or, better, cache reads.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              :class:`~pysam.AlignedSegment` : the mate\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                  if the read is unpaired or the mate is unmapped\n",
      "     |  \n",
      "     |  pileup(...)\n",
      "     |      AlignmentFile.pileup(self, contig=None, start=None, stop=None, region=None, reference=None, end=None, **kwargs)\n",
      "     |      perform a :term:`pileup` within a :term:`region`. The region is\n",
      "     |              specified by :term:`contig`, `start` and `stop` (using\n",
      "     |              0-based indexing).  :term:`reference` and `end` are also accepted for\n",
      "     |              backward compatiblity as synonyms for :term:`contig` and `stop`,\n",
      "     |              respectively.  Alternatively, a samtools 'region' string\n",
      "     |              can be supplied.\n",
      "     |      \n",
      "     |              Without 'contig' or 'region' all reads will be used for the\n",
      "     |              pileup. The reads will be returned ordered by\n",
      "     |              :term:`contig` sequence, which will not necessarily be the\n",
      "     |              order within the file.\n",
      "     |      \n",
      "     |              Note that :term:`SAM` formatted files do not allow random\n",
      "     |              access.  In these files, if a 'region' or 'contig' are\n",
      "     |              given an exception is raised.\n",
      "     |      \n",
      "     |              .. note::\n",
      "     |      \n",
      "     |                  'all' reads which overlap the region are returned. The\n",
      "     |                  first base returned will be the first base of the first\n",
      "     |                  read 'not' necessarily the first base of the region used\n",
      "     |                  in the query.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              truncate : bool\n",
      "     |      \n",
      "     |                 By default, the samtools pileup engine outputs all reads\n",
      "     |                 overlapping a region. If truncate is True and a region is\n",
      "     |                 given, only columns in the exact region specificied are\n",
      "     |                 returned.\n",
      "     |      \n",
      "     |              max_depth : int\n",
      "     |                 Maximum read depth permitted. The default limit is '8000'.\n",
      "     |      \n",
      "     |              stepper : string\n",
      "     |                 The stepper controls how the iterator advances.\n",
      "     |                 Possible options for the stepper are\n",
      "     |      \n",
      "     |                 ``all``\n",
      "     |                    skip reads in which any of the following flags are set:\n",
      "     |                    BAM_FUNMAP, BAM_FSECONDARY, BAM_FQCFAIL, BAM_FDUP\n",
      "     |      \n",
      "     |                 ``nofilter``\n",
      "     |                    uses every single read turning off any filtering.\n",
      "     |      \n",
      "     |                 ``samtools``\n",
      "     |                    same filter and read processing as in :term:`csamtools`\n",
      "     |                    pileup. For full compatibility, this requires a\n",
      "     |                    'fastafile' to be given. The following options all pertain\n",
      "     |                    to filtering of the ``samtools`` stepper.\n",
      "     |      \n",
      "     |              fastafile : :class:`~pysam.FastaFile` object.\n",
      "     |      \n",
      "     |                 This is required for some of the steppers.\n",
      "     |      \n",
      "     |              ignore_overlaps: bool\n",
      "     |      \n",
      "     |                 If set to True, detect if read pairs overlap and only take\n",
      "     |                 the higher quality base. This is the default.\n",
      "     |      \n",
      "     |              flag_filter : int\n",
      "     |      \n",
      "     |                 ignore reads where any of the bits in the flag are set. The default is\n",
      "     |                 BAM_FUNMAP | BAM_FSECONDARY | BAM_FQCFAIL | BAM_FDUP.\n",
      "     |      \n",
      "     |              flag_require : int\n",
      "     |      \n",
      "     |                 only use reads where certain flags are set. The default is 0.\n",
      "     |      \n",
      "     |              ignore_orphans: bool\n",
      "     |      \n",
      "     |                  ignore orphans (paired reads that are not in a proper pair).\n",
      "     |                  The default is to ignore orphans.\n",
      "     |         \n",
      "     |              min_base_quality: int\n",
      "     |      \n",
      "     |                 Minimum base quality. Bases below the minimum quality will\n",
      "     |                 not be output.\n",
      "     |      \n",
      "     |              adjust_capq_threshold: int\n",
      "     |      \n",
      "     |                 adjust mapping quality. The default is 0 for no\n",
      "     |                 adjustment. The recommended value for adjustment is 50.\n",
      "     |      \n",
      "     |              min_mapping_quality : int\n",
      "     |      \n",
      "     |                 only use reads above a minimum mapping quality. The default is 0.\n",
      "     |      \n",
      "     |              compute_baq: bool\n",
      "     |      \n",
      "     |                 re-alignment computing per-Base Alignment Qualities (BAQ). The\n",
      "     |                 default is to do re-alignment. Realignment requires a reference\n",
      "     |                 sequence. If none is present, no realignment will be performed.\n",
      "     |      \n",
      "     |              redo_baq: bool\n",
      "     |      \n",
      "     |                 recompute per-Base Alignment Quality on the fly ignoring\n",
      "     |                 existing base qualities. The default is False (use existing\n",
      "     |                 base qualities).\n",
      "     |      \n",
      "     |              adjust_capq_threshold: int\n",
      "     |      \n",
      "     |                  adjust mapping quality. The default is 0 for no\n",
      "     |                  adjustment. The recommended value for adjustment is 50.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              an iterator over genomic positions.\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      AlignmentFile.write(self, AlignedSegment read) -> int\n",
      "     |      \n",
      "     |      write a single :class:`pysam.AlignedSegment` to disk.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          if the writing failed\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      \n",
      "     |      int : the number of bytes written. If the file is closed,\n",
      "     |            this will be 0.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  lengths\n",
      "     |      tuple of the lengths of the :term:`reference` sequences. This is a\n",
      "     |      read-only attribute. The lengths are in the same order as\n",
      "     |      :attr:`pysam.AlignmentFile.references`\n",
      "     |  \n",
      "     |  mapped\n",
      "     |      int with total number of mapped alignments according to the\n",
      "     |      statistics recorded in the index. This is a read-only\n",
      "     |      attribute.\n",
      "     |  \n",
      "     |  nocoordinate\n",
      "     |      int with total number of reads without coordinates according to the\n",
      "     |      statistics recorded in the index. This is a read-only attribute.\n",
      "     |  \n",
      "     |  nreferences\n",
      "     |      \"int with the number of :term:`reference` sequences in the file.\n",
      "     |      This is a read-only attribute.\n",
      "     |  \n",
      "     |  reference_filename\n",
      "     |  \n",
      "     |  references\n",
      "     |      tuple with the names of :term:`reference` sequences. This is a\n",
      "     |      read-only attribute\n",
      "     |  \n",
      "     |  text\n",
      "     |      deprecated, use .header directly\n",
      "     |  \n",
      "     |  unmapped\n",
      "     |      int with total number of unmapped reads according to the statistics\n",
      "     |      recorded in the index. This number of reads includes the number of reads\n",
      "     |      without coordinates. This is a read-only attribute.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysam.libchtslib.HTSFile:\n",
      "     |  \n",
      "     |  add_hts_options(...)\n",
      "     |      HTSFile.add_hts_options(self, format_options=None)\n",
      "     |      Given a list of key=value format option strings, add them to an open htsFile\n",
      "     |  \n",
      "     |  check_truncation(...)\n",
      "     |      HTSFile.check_truncation(self, ignore_truncation=False)\n",
      "     |      Check if file is truncated.\n",
      "     |  \n",
      "     |  is_valid_reference_name(...)\n",
      "     |      HTSFile.is_valid_reference_name(self, contig)\n",
      "     |      \n",
      "     |      return True if the contig name :term:`contig` is valid; False otherwise.\n",
      "     |  \n",
      "     |  parse_region(...)\n",
      "     |      HTSFile.parse_region(self, contig=None, start=None, stop=None, region=None, tid=None, reference=None, end=None)\n",
      "     |      parse alternative ways to specify a genomic region. A region can\n",
      "     |              either be specified by :term:`contig`, `start` and\n",
      "     |              `stop`. `start` and `stop` denote 0-based, half-open\n",
      "     |              intervals. :term:`reference` and `end` are also accepted for\n",
      "     |              backward compatiblity as synonyms for :term:`contig` and\n",
      "     |              `stop`, respectively.\n",
      "     |      \n",
      "     |              Alternatively, a samtools :term:`region` string can be\n",
      "     |              supplied.\n",
      "     |      \n",
      "     |              If any of the coordinates are missing they will be replaced by\n",
      "     |              the minimum (`start`) or maximum (`stop`) coordinate.\n",
      "     |      \n",
      "     |              Note that region strings are 1-based inclusive, while `start`\n",
      "     |              and `stop` denote an interval in 0-based, half-open\n",
      "     |              coordinates (like BED files and Python slices).\n",
      "     |      \n",
      "     |              If `contig` or `region` or are ``*``, unmapped reads at the end\n",
      "     |              of a BAM file will be returned. Setting either to ``.`` will\n",
      "     |              iterate from the beginning of the file.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              tuple : a tuple of `flag`, :term:`tid`, `start` and\n",
      "     |              `stop`. The flag indicates whether no coordinates were\n",
      "     |              supplied and the genomic region is the complete genomic space.\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                 for invalid or out of bounds regions.\n",
      "     |  \n",
      "     |  reset(...)\n",
      "     |      HTSFile.reset(self)\n",
      "     |      reset file position to beginning of file just after the header.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              The file position after moving the file pointer.\n",
      "     |  \n",
      "     |  seek(...)\n",
      "     |      HTSFile.seek(self, uint64_t offset)\n",
      "     |      move file pointer to position *offset*, see :meth:`pysam.HTSFile.tell`.\n",
      "     |  \n",
      "     |  tell(...)\n",
      "     |      HTSFile.tell(self)\n",
      "     |      return current file position, see :meth:`pysam.HTSFile.seek`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysam.libchtslib.HTSFile:\n",
      "     |  \n",
      "     |  category\n",
      "     |      General file format category.  One of UNKNOWN, ALIGNMENTS,\n",
      "     |      VARIANTS, INDEX, REGIONS\n",
      "     |  \n",
      "     |  closed\n",
      "     |      return True if HTSFile is closed.\n",
      "     |  \n",
      "     |  compression\n",
      "     |      File compression.\n",
      "     |      \n",
      "     |      One of NONE, GZIP, BGZF, CUSTOM.\n",
      "     |  \n",
      "     |  description\n",
      "     |      Vaguely human readable description of the file format\n",
      "     |  \n",
      "     |  duplicate_filehandle\n",
      "     |  \n",
      "     |  filename\n",
      "     |  \n",
      "     |  format\n",
      "     |      File format.\n",
      "     |      \n",
      "     |      One of UNKNOWN, BINARY_FORMAT, TEXT_FORMAT, SAM, BAM,\n",
      "     |      BAI, CRAM, CRAI, VCF, BCF, CSI, GZI, TBI, BED.\n",
      "     |  \n",
      "     |  index_filename\n",
      "     |  \n",
      "     |  is_bam\n",
      "     |      return True if HTSFile is reading or writing a BAM alignment file\n",
      "     |  \n",
      "     |  is_bcf\n",
      "     |      return True if HTSFile is reading or writing a BCF variant file\n",
      "     |  \n",
      "     |  is_closed\n",
      "     |      return True if HTSFile is closed.\n",
      "     |  \n",
      "     |  is_cram\n",
      "     |      return True if HTSFile is reading or writing a BAM alignment file\n",
      "     |  \n",
      "     |  is_open\n",
      "     |      return True if HTSFile is open and in a valid state.\n",
      "     |  \n",
      "     |  is_read\n",
      "     |      return True if HTSFile is open for reading\n",
      "     |  \n",
      "     |  is_remote\n",
      "     |  \n",
      "     |  is_sam\n",
      "     |      return True if HTSFile is reading or writing a SAM alignment file\n",
      "     |  \n",
      "     |  is_stream\n",
      "     |  \n",
      "     |  is_vcf\n",
      "     |      return True if HTSFile is reading or writing a VCF variant file\n",
      "     |  \n",
      "     |  is_write\n",
      "     |      return True if HTSFile is open for writing\n",
      "     |  \n",
      "     |  mode\n",
      "     |  \n",
      "     |  threads\n",
      "     |  \n",
      "     |  version\n",
      "     |      Tuple of file format version numbers (major, minor)\n",
      "    \n",
      "    class AlignmentHeader(builtins.object)\n",
      "     |  AlignmentHeader()\n",
      "     |  header information for a :class:`AlignmentFile` object\n",
      "     |  \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      header_dict : dict\n",
      "     |          build header from a multi-level dictionary. The\n",
      "     |          first level are the four types ('HD', 'SQ', ...). The second\n",
      "     |          level are a list of lines, with each line being a list of\n",
      "     |          tag-value pairs. The header is constructed first from all the\n",
      "     |          defined fields, followed by user tags in alphabetical\n",
      "     |          order. Alternatively, an :class:`~pysam.AlignmentHeader`\n",
      "     |          object can be passed directly.\n",
      "     |  \n",
      "     |      text : string\n",
      "     |          use the string provided as the header\n",
      "     |  \n",
      "     |      reference_names : list\n",
      "     |          see reference_lengths\n",
      "     |  \n",
      "     |      reference_lengths : list\n",
      "     |          build header from list of chromosome names and lengths.  By\n",
      "     |          default, 'SQ' and 'LN' tags will be added to the header\n",
      "     |          text. This option can be changed by unsetting the flag\n",
      "     |          `add_sq_text`.\n",
      "     |  \n",
      "     |      add_sq_text : bool\n",
      "     |          do not add 'SQ' and 'LN' tags to header. This option permits\n",
      "     |          construction :term:`SAM` formatted files without a header.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __bool__(self, /)\n",
      "     |      self != 0\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      AlignmentHeader.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      AlignmentHeader.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      string with the full contents of the :term:`sam file` header as a\n",
      "     |      string.\n",
      "     |      \n",
      "     |      If no @SQ entries are within the text section of the header,\n",
      "     |      this will be automatically added from the reference names and\n",
      "     |      lengths stored in the binary part of the header.\n",
      "     |      \n",
      "     |      See :attr:`pysam.AlignmentFile.header.to_dict()` to get a parsed\n",
      "     |      representation of the header.\n",
      "     |  \n",
      "     |  as_dict(...)\n",
      "     |      AlignmentHeader.as_dict(self)\n",
      "     |      deprecated: use :meth:`to_dict()`\n",
      "     |  \n",
      "     |  copy(...)\n",
      "     |      AlignmentHeader.copy(self)\n",
      "     |  \n",
      "     |  get(...)\n",
      "     |      AlignmentHeader.get(self, *args)\n",
      "     |  \n",
      "     |  get_reference_length(...)\n",
      "     |      AlignmentHeader.get_reference_length(self, reference)\n",
      "     |  \n",
      "     |  get_reference_name(...)\n",
      "     |      AlignmentHeader.get_reference_name(self, tid)\n",
      "     |  \n",
      "     |  get_tid(...)\n",
      "     |      AlignmentHeader.get_tid(self, reference)\n",
      "     |      \n",
      "     |      return the numerical :term:`tid` corresponding to\n",
      "     |      :term:`reference`\n",
      "     |      \n",
      "     |      returns -1 if reference is not known.\n",
      "     |  \n",
      "     |  is_valid_tid(...)\n",
      "     |      AlignmentHeader.is_valid_tid(self, int tid)\n",
      "     |      \n",
      "     |      return True if the numerical :term:`tid` is valid; False otherwise.\n",
      "     |      \n",
      "     |      Note that the unmapped tid code (-1) counts as an invalid.\n",
      "     |  \n",
      "     |  items(...)\n",
      "     |      AlignmentHeader.items(self)\n",
      "     |  \n",
      "     |  iteritems(...)\n",
      "     |      AlignmentHeader.iteritems(self)\n",
      "     |  \n",
      "     |  keys(...)\n",
      "     |      AlignmentHeader.keys(self)\n",
      "     |  \n",
      "     |  to_dict(...)\n",
      "     |      AlignmentHeader.to_dict(self)\n",
      "     |      return two-level dictionary with header information from the file.\n",
      "     |      \n",
      "     |              The first level contains the record (``HD``, ``SQ``, etc) and\n",
      "     |              the second level contains the fields (``VN``, ``LN``, etc).\n",
      "     |      \n",
      "     |              The parser is validating and will raise an AssertionError if\n",
      "     |              if encounters any record or field tags that are not part of\n",
      "     |              the SAM specification. Use the\n",
      "     |              :attr:`pysam.AlignmentFile.text` attribute to get the unparsed\n",
      "     |              header.\n",
      "     |      \n",
      "     |              The parsing follows the SAM format specification with the\n",
      "     |              exception of the ``CL`` field. This option will consume the\n",
      "     |              rest of a header line irrespective of any additional fields.\n",
      "     |              This behaviour has been added to accommodate command line\n",
      "     |              options that contain characters that are not valid field\n",
      "     |              separators.\n",
      "     |      \n",
      "     |              If no @SQ entries are within the text section of the header,\n",
      "     |              this will be automatically added from the reference names and\n",
      "     |              lengths stored in the binary part of the header.\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      AlignmentHeader.values(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_dict(...) from builtins.type\n",
      "     |      AlignmentHeader.from_dict(type cls, header_dict)\n",
      "     |  \n",
      "     |  from_references(...) from builtins.type\n",
      "     |      AlignmentHeader.from_references(type cls, reference_names, reference_lengths, text=None, add_sq_text=True)\n",
      "     |  \n",
      "     |  from_text(...) from builtins.type\n",
      "     |      AlignmentHeader.from_text(type cls, text)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  lengths\n",
      "     |      tuple of the lengths of the :term:`reference` sequences. This is a\n",
      "     |      read-only attribute. The lengths are in the same order as\n",
      "     |      :attr:`pysam.AlignmentFile.references`\n",
      "     |  \n",
      "     |  nreferences\n",
      "     |      \"int with the number of :term:`reference` sequences in the file.\n",
      "     |      \n",
      "     |      This is a read-only attribute.\n",
      "     |  \n",
      "     |  references\n",
      "     |      tuple with the names of :term:`reference` sequences. This is a\n",
      "     |      read-only attribute\n",
      "    \n",
      "    class BGZFile(builtins.object)\n",
      "     |  The BGZFile class simulates most of the methods of a file object with\n",
      "     |  the exception of the truncate() method.\n",
      "     |  \n",
      "     |  This class only supports opening files in binary mode. If you need to open a\n",
      "     |  compressed file in text mode, use the gzip.open() function.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(...)\n",
      "     |  \n",
      "     |  __exit__(...)\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      Constructor for the BGZFile class.\n",
      "     |      \n",
      "     |      The mode argument can be any of 'r', 'rb', 'a', 'ab', 'w', 'wb', 'x', or\n",
      "     |      'xb' depending on whether the file will be read or written.  The default\n",
      "     |      is the mode of fileobj if discernible; otherwise, the default is 'rb'.\n",
      "     |      A mode of 'r' is equivalent to one of 'rb', and similarly for 'w' and\n",
      "     |      'wb', 'a' and 'ab', and 'x' and 'xb'.\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __next__(...)\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |  \n",
      "     |  close(...)\n",
      "     |  \n",
      "     |  fileno(...)\n",
      "     |      Invoke the underlying file object's fileno() method.\n",
      "     |      \n",
      "     |      This will raise AttributeError if the underlying file object\n",
      "     |      doesn't support fileno().\n",
      "     |  \n",
      "     |  flush(...)\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |  \n",
      "     |  readable(...)\n",
      "     |  \n",
      "     |  readline(...)\n",
      "     |  \n",
      "     |  rewind(...)\n",
      "     |      Return the uncompressed stream file position indicator to the\n",
      "     |      beginning of the file\n",
      "     |  \n",
      "     |  seek(...)\n",
      "     |  \n",
      "     |  seekable(...)\n",
      "     |  \n",
      "     |  tell(...)\n",
      "     |  \n",
      "     |  writable(...)\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  closed\n",
      "     |  \n",
      "     |  index\n",
      "     |  \n",
      "     |  name\n",
      "    \n",
      "    class FastaFile(builtins.object)\n",
      "     |  Random access to fasta formatted files that\n",
      "     |  have been indexed by :term:`faidx`.\n",
      "     |  \n",
      "     |  The file is automatically opened. The index file of file\n",
      "     |  ``<filename>`` is expected to be called ``<filename>.fai``.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  \n",
      "     |  filename : string\n",
      "     |      Filename of fasta file to be opened.\n",
      "     |  \n",
      "     |  filepath_index : string\n",
      "     |      Optional, filename of the index. By default this is\n",
      "     |      the filename + \".fai\".\n",
      "     |  \n",
      "     |  filepath_index_compressed : string\n",
      "     |      Optional, filename of the index if fasta file is. By default this is\n",
      "     |      the filename + \".gzi\".\n",
      "     |  \n",
      "     |  Raises\n",
      "     |  ------\n",
      "     |  \n",
      "     |  ValueError\n",
      "     |      if index file is missing\n",
      "     |  \n",
      "     |  IOError\n",
      "     |      if file could not be opened\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __contains__(...)\n",
      "     |      return true if reference in fasta file.\n",
      "     |  \n",
      "     |  __enter__(...)\n",
      "     |      FastaFile.__enter__(self)\n",
      "     |  \n",
      "     |  __exit__(...)\n",
      "     |      FastaFile.__exit__(self, exc_type, exc_value, traceback)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      FastaFile.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      FastaFile.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  close(...)\n",
      "     |      FastaFile.close(self)\n",
      "     |      close the file.\n",
      "     |  \n",
      "     |  fetch(...)\n",
      "     |      FastaFile.fetch(self, reference=None, start=None, end=None, region=None)\n",
      "     |      fetch sequences in a :term:`region`.\n",
      "     |      \n",
      "     |              A region can\n",
      "     |              either be specified by :term:`reference`, `start` and\n",
      "     |              `end`. `start` and `end` denote 0-based, half-open\n",
      "     |              intervals.\n",
      "     |      \n",
      "     |              Alternatively, a samtools :term:`region` string can be\n",
      "     |              supplied.\n",
      "     |      \n",
      "     |              If any of the coordinates are missing they will be replaced by the\n",
      "     |              minimum (`start`) or maximum (`end`) coordinate.\n",
      "     |      \n",
      "     |              Note that region strings are 1-based, while `start` and `end` denote\n",
      "     |              an interval in python coordinates.\n",
      "     |              The region is specified by :term:`reference`, `start` and `end`.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              string : a string with the sequence specified by the region.\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              IndexError\n",
      "     |                  if the coordinates are out of range\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                  if the region is invalid\n",
      "     |  \n",
      "     |  get_reference_length(...)\n",
      "     |      FastaFile.get_reference_length(self, reference)\n",
      "     |      return the length of reference.\n",
      "     |  \n",
      "     |  is_open(...)\n",
      "     |      FastaFile.is_open(self)\n",
      "     |      return true if samfile has been opened.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  closed\n",
      "     |      \"bool indicating the current state of the file object.\n",
      "     |      This is a read-only attribute; the close() method changes the value.\n",
      "     |  \n",
      "     |  filename\n",
      "     |      filename associated with this object. This is a read-only attribute.\n",
      "     |  \n",
      "     |  lengths\n",
      "     |      tuple with the lengths of :term:`reference` sequences.\n",
      "     |  \n",
      "     |  nreferences\n",
      "     |      \"int with the number of :term:`reference` sequences in the file.\n",
      "     |      This is a read-only attribute.\n",
      "     |  \n",
      "     |  references\n",
      "     |      tuple with the names of :term:`reference` sequences.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "    \n",
      "    class Fastafile(FastaFile)\n",
      "     |  Fastafile is deprecated: use FastaFile instead\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Fastafile\n",
      "     |      FastaFile\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      Fastafile.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      Fastafile.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from FastaFile:\n",
      "     |  \n",
      "     |  __contains__(...)\n",
      "     |      return true if reference in fasta file.\n",
      "     |  \n",
      "     |  __enter__(...)\n",
      "     |      FastaFile.__enter__(self)\n",
      "     |  \n",
      "     |  __exit__(...)\n",
      "     |      FastaFile.__exit__(self, exc_type, exc_value, traceback)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  close(...)\n",
      "     |      FastaFile.close(self)\n",
      "     |      close the file.\n",
      "     |  \n",
      "     |  fetch(...)\n",
      "     |      FastaFile.fetch(self, reference=None, start=None, end=None, region=None)\n",
      "     |      fetch sequences in a :term:`region`.\n",
      "     |      \n",
      "     |              A region can\n",
      "     |              either be specified by :term:`reference`, `start` and\n",
      "     |              `end`. `start` and `end` denote 0-based, half-open\n",
      "     |              intervals.\n",
      "     |      \n",
      "     |              Alternatively, a samtools :term:`region` string can be\n",
      "     |              supplied.\n",
      "     |      \n",
      "     |              If any of the coordinates are missing they will be replaced by the\n",
      "     |              minimum (`start`) or maximum (`end`) coordinate.\n",
      "     |      \n",
      "     |              Note that region strings are 1-based, while `start` and `end` denote\n",
      "     |              an interval in python coordinates.\n",
      "     |              The region is specified by :term:`reference`, `start` and `end`.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              string : a string with the sequence specified by the region.\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              IndexError\n",
      "     |                  if the coordinates are out of range\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                  if the region is invalid\n",
      "     |  \n",
      "     |  get_reference_length(...)\n",
      "     |      FastaFile.get_reference_length(self, reference)\n",
      "     |      return the length of reference.\n",
      "     |  \n",
      "     |  is_open(...)\n",
      "     |      FastaFile.is_open(self)\n",
      "     |      return true if samfile has been opened.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from FastaFile:\n",
      "     |  \n",
      "     |  closed\n",
      "     |      \"bool indicating the current state of the file object.\n",
      "     |      This is a read-only attribute; the close() method changes the value.\n",
      "     |  \n",
      "     |  filename\n",
      "     |      filename associated with this object. This is a read-only attribute.\n",
      "     |  \n",
      "     |  lengths\n",
      "     |      tuple with the lengths of :term:`reference` sequences.\n",
      "     |  \n",
      "     |  nreferences\n",
      "     |      \"int with the number of :term:`reference` sequences in the file.\n",
      "     |      This is a read-only attribute.\n",
      "     |  \n",
      "     |  references\n",
      "     |      tuple with the names of :term:`reference` sequences.\n",
      "    \n",
      "    class FastqFile(FastxFile)\n",
      "     |  FastqFile is deprecated: use FastxFile instead\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FastqFile\n",
      "     |      FastxFile\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      FastqFile.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      FastqFile.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from FastxFile:\n",
      "     |  \n",
      "     |  __enter__(...)\n",
      "     |      FastxFile.__enter__(self)\n",
      "     |  \n",
      "     |  __exit__(...)\n",
      "     |      FastxFile.__exit__(self, exc_type, exc_value, traceback)\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __next__(...)\n",
      "     |      python version of next().\n",
      "     |  \n",
      "     |  close(...)\n",
      "     |      FastxFile.close(self)\n",
      "     |      close the file.\n",
      "     |  \n",
      "     |  is_open(...)\n",
      "     |      FastxFile.is_open(self)\n",
      "     |      return true if samfile has been opened.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from FastxFile:\n",
      "     |  \n",
      "     |  closed\n",
      "     |      \"bool indicating the current state of the file object.\n",
      "     |      This is a read-only attribute; the close() method changes the value.\n",
      "     |  \n",
      "     |  filename\n",
      "     |      string with the filename associated with this object.\n",
      "    \n",
      "    class FastqProxy(builtins.object)\n",
      "     |  FastqProxy()\n",
      "     |  A single entry in a fastq file.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      FastqProxy.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      FastqProxy.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  get_quality_array(...)\n",
      "     |      FastqProxy.get_quality_array(self, int offset=33) -> array\n",
      "     |      return quality values as integer array after subtracting offset.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  comment\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of each entry in the fastq file.\n",
      "     |  \n",
      "     |  quality\n",
      "     |      The quality score of each entry in the fastq file, represented as a string.\n",
      "     |  \n",
      "     |  sequence\n",
      "     |      The sequence of each entry in the fastq file.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "    \n",
      "    class FastxFile(builtins.object)\n",
      "     |  Stream access to :term:`fasta` or :term:`fastq` formatted files.\n",
      "     |  \n",
      "     |  The file is automatically opened.\n",
      "     |  \n",
      "     |  Entries in the file can be both fastq or fasta formatted or even a\n",
      "     |  mixture of the two.\n",
      "     |  \n",
      "     |  This file object permits iterating over all entries in the\n",
      "     |  file. Random access is not implemented. The iteration returns\n",
      "     |  objects of type :class:`FastqProxy`\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  \n",
      "     |  filename : string\n",
      "     |      Filename of fasta/fastq file to be opened.\n",
      "     |  \n",
      "     |  persist : bool\n",
      "     |  \n",
      "     |      If True (default) make a copy of the entry in the file during\n",
      "     |      iteration. If set to False, no copy will be made. This will\n",
      "     |      permit much faster iteration, but an entry will not persist\n",
      "     |      when the iteration continues and an entry is read-only.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Prior to version 0.8.2, this class was called FastqFile.\n",
      "     |  \n",
      "     |  Raises\n",
      "     |  ------\n",
      "     |  \n",
      "     |  IOError\n",
      "     |      if file could not be opened\n",
      "     |  \n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> with pysam.FastxFile(filename) as fh:\n",
      "     |  ...    for entry in fh:\n",
      "     |  ...        print(entry.name)\n",
      "     |  ...        print(entry.sequence)\n",
      "     |  ...        print(entry.comment)\n",
      "     |  ...        print(entry.quality)\n",
      "     |  >>> with pysam.FastxFile(filename) as fin, open(out_filename, mode='w') as fout:\n",
      "     |  ...    for entry in fin:\n",
      "     |  ...        fout.write(str(entry))\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(...)\n",
      "     |      FastxFile.__enter__(self)\n",
      "     |  \n",
      "     |  __exit__(...)\n",
      "     |      FastxFile.__exit__(self, exc_type, exc_value, traceback)\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __next__(...)\n",
      "     |      python version of next().\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      FastxFile.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      FastxFile.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  close(...)\n",
      "     |      FastxFile.close(self)\n",
      "     |      close the file.\n",
      "     |  \n",
      "     |  is_open(...)\n",
      "     |      FastxFile.is_open(self)\n",
      "     |      return true if samfile has been opened.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  closed\n",
      "     |      \"bool indicating the current state of the file object.\n",
      "     |      This is a read-only attribute; the close() method changes the value.\n",
      "     |  \n",
      "     |  filename\n",
      "     |      string with the filename associated with this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "    \n",
      "    class FastxRecord(builtins.object)\n",
      "     |  FastxRecord(name=None, comment=None, sequence=None, quality=None, FastqProxy proxy=None)\n",
      "     |  A fasta/fastq record.\n",
      "     |  \n",
      "     |      A record must contain a name and a sequence. If either of them are\n",
      "     |      None, a ValueError is raised on writing.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __copy__(...)\n",
      "     |      FastxRecord.__copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      FastxRecord.__deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      FastxRecord.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      FastxRecord.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  get_quality_array(...)\n",
      "     |      FastxRecord.get_quality_array(self, int offset=33) -> array\n",
      "     |      return quality values as array after subtracting offset.\n",
      "     |  \n",
      "     |  set_comment(...)\n",
      "     |      FastxRecord.set_comment(self, comment)\n",
      "     |  \n",
      "     |  set_name(...)\n",
      "     |      FastxRecord.set_name(self, name)\n",
      "     |  \n",
      "     |  set_sequence(...)\n",
      "     |      FastxRecord.set_sequence(self, sequence, quality=None)\n",
      "     |      set sequence of this record.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  comment\n",
      "     |      comment: str\n",
      "     |  \n",
      "     |  name\n",
      "     |      name: str\n",
      "     |  \n",
      "     |  quality\n",
      "     |      quality: str\n",
      "     |  \n",
      "     |  sequence\n",
      "     |      sequence: str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "    \n",
      "    class GZIterator(builtins.object)\n",
      "     |  GZIterator(filename, int buffer_size=65536, encoding='ascii')\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      iterate line-by-line through gzip (or bgzip)\n",
      "     |      compressed file.\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __next__(...)\n",
      "     |      python version of next().\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      GZIterator.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      GZIterator.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "    \n",
      "    class GZIteratorHead(GZIterator)\n",
      "     |  iterate line-by-line through gzip (or bgzip)\n",
      "     |  compressed file returning comments at top of file.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GZIteratorHead\n",
      "     |      GZIterator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __next__(...)\n",
      "     |      python version of next().\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      GZIteratorHead.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      GZIteratorHead.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GZIterator:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      iterate line-by-line through gzip (or bgzip)\n",
      "     |      compressed file.\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "    \n",
      "    class HFile(builtins.object)\n",
      "     |  HFile(name, mode='r', closedf=True)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(...)\n",
      "     |      HFile.__enter__(self)\n",
      "     |  \n",
      "     |  __exit__(...)\n",
      "     |      HFile.__exit__(self, type, value, tb)\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __next__(...)\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      HFile.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      HFile.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  close(...)\n",
      "     |      HFile.close(self)\n",
      "     |  \n",
      "     |  fileno(...)\n",
      "     |      HFile.fileno(self)\n",
      "     |  \n",
      "     |  flush(...)\n",
      "     |      HFile.flush(self)\n",
      "     |  \n",
      "     |  isatty(...)\n",
      "     |      HFile.isatty(self)\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      HFile.read(self, Py_ssize_t size=-1)\n",
      "     |  \n",
      "     |  readable(...)\n",
      "     |      HFile.readable(self)\n",
      "     |  \n",
      "     |  readall(...)\n",
      "     |      HFile.readall(self)\n",
      "     |  \n",
      "     |  readinto(...)\n",
      "     |      HFile.readinto(self, buf)\n",
      "     |  \n",
      "     |  readline(...)\n",
      "     |      HFile.readline(self, Py_ssize_t size=-1)\n",
      "     |  \n",
      "     |  readlines(...)\n",
      "     |      HFile.readlines(self)\n",
      "     |  \n",
      "     |  seek(...)\n",
      "     |      HFile.seek(self, Py_ssize_t offset, int whence=0)\n",
      "     |  \n",
      "     |  seekable(...)\n",
      "     |      HFile.seekable(self)\n",
      "     |  \n",
      "     |  tell(...)\n",
      "     |      HFile.tell(self)\n",
      "     |  \n",
      "     |  truncate(...)\n",
      "     |      HFile.truncate(self, size=None)\n",
      "     |  \n",
      "     |  writable(...)\n",
      "     |      HFile.writable(self)\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      HFile.write(self, bytes b)\n",
      "     |  \n",
      "     |  writelines(...)\n",
      "     |      HFile.writelines(self, lines)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  closed\n",
      "     |  \n",
      "     |  mode\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "    \n",
      "    class HTSFile(builtins.object)\n",
      "     |  Base class for HTS file types\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(...)\n",
      "     |      HTSFile.__enter__(self)\n",
      "     |  \n",
      "     |  __exit__(...)\n",
      "     |      HTSFile.__exit__(self, exc_type, exc_value, traceback)\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      HTSFile.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      HTSFile.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  add_hts_options(...)\n",
      "     |      HTSFile.add_hts_options(self, format_options=None)\n",
      "     |      Given a list of key=value format option strings, add them to an open htsFile\n",
      "     |  \n",
      "     |  check_truncation(...)\n",
      "     |      HTSFile.check_truncation(self, ignore_truncation=False)\n",
      "     |      Check if file is truncated.\n",
      "     |  \n",
      "     |  close(...)\n",
      "     |      HTSFile.close(self)\n",
      "     |  \n",
      "     |  get_reference_name(...)\n",
      "     |      HTSFile.get_reference_name(self, tid)\n",
      "     |      \n",
      "     |      return :term:`contig` name corresponding to numerical :term:`tid`\n",
      "     |  \n",
      "     |  get_tid(...)\n",
      "     |      HTSFile.get_tid(self, contig)\n",
      "     |      \n",
      "     |      return the numerical :term:`tid` corresponding to\n",
      "     |      :term:`contig`\n",
      "     |      \n",
      "     |      returns -1 if contig is not known.\n",
      "     |  \n",
      "     |  is_valid_reference_name(...)\n",
      "     |      HTSFile.is_valid_reference_name(self, contig)\n",
      "     |      \n",
      "     |      return True if the contig name :term:`contig` is valid; False otherwise.\n",
      "     |  \n",
      "     |  is_valid_tid(...)\n",
      "     |      HTSFile.is_valid_tid(self, tid)\n",
      "     |      \n",
      "     |      return True if the numerical :term:`tid` is valid; False otherwise.\n",
      "     |      \n",
      "     |      returns -1 if contig is not known.\n",
      "     |  \n",
      "     |  parse_region(...)\n",
      "     |      HTSFile.parse_region(self, contig=None, start=None, stop=None, region=None, tid=None, reference=None, end=None)\n",
      "     |      parse alternative ways to specify a genomic region. A region can\n",
      "     |              either be specified by :term:`contig`, `start` and\n",
      "     |              `stop`. `start` and `stop` denote 0-based, half-open\n",
      "     |              intervals. :term:`reference` and `end` are also accepted for\n",
      "     |              backward compatiblity as synonyms for :term:`contig` and\n",
      "     |              `stop`, respectively.\n",
      "     |      \n",
      "     |              Alternatively, a samtools :term:`region` string can be\n",
      "     |              supplied.\n",
      "     |      \n",
      "     |              If any of the coordinates are missing they will be replaced by\n",
      "     |              the minimum (`start`) or maximum (`stop`) coordinate.\n",
      "     |      \n",
      "     |              Note that region strings are 1-based inclusive, while `start`\n",
      "     |              and `stop` denote an interval in 0-based, half-open\n",
      "     |              coordinates (like BED files and Python slices).\n",
      "     |      \n",
      "     |              If `contig` or `region` or are ``*``, unmapped reads at the end\n",
      "     |              of a BAM file will be returned. Setting either to ``.`` will\n",
      "     |              iterate from the beginning of the file.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              tuple : a tuple of `flag`, :term:`tid`, `start` and\n",
      "     |              `stop`. The flag indicates whether no coordinates were\n",
      "     |              supplied and the genomic region is the complete genomic space.\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                 for invalid or out of bounds regions.\n",
      "     |  \n",
      "     |  reset(...)\n",
      "     |      HTSFile.reset(self)\n",
      "     |      reset file position to beginning of file just after the header.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              The file position after moving the file pointer.\n",
      "     |  \n",
      "     |  seek(...)\n",
      "     |      HTSFile.seek(self, uint64_t offset)\n",
      "     |      move file pointer to position *offset*, see :meth:`pysam.HTSFile.tell`.\n",
      "     |  \n",
      "     |  tell(...)\n",
      "     |      HTSFile.tell(self)\n",
      "     |      return current file position, see :meth:`pysam.HTSFile.seek`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  category\n",
      "     |      General file format category.  One of UNKNOWN, ALIGNMENTS,\n",
      "     |      VARIANTS, INDEX, REGIONS\n",
      "     |  \n",
      "     |  closed\n",
      "     |      return True if HTSFile is closed.\n",
      "     |  \n",
      "     |  compression\n",
      "     |      File compression.\n",
      "     |      \n",
      "     |      One of NONE, GZIP, BGZF, CUSTOM.\n",
      "     |  \n",
      "     |  description\n",
      "     |      Vaguely human readable description of the file format\n",
      "     |  \n",
      "     |  duplicate_filehandle\n",
      "     |  \n",
      "     |  filename\n",
      "     |  \n",
      "     |  format\n",
      "     |      File format.\n",
      "     |      \n",
      "     |      One of UNKNOWN, BINARY_FORMAT, TEXT_FORMAT, SAM, BAM,\n",
      "     |      BAI, CRAM, CRAI, VCF, BCF, CSI, GZI, TBI, BED.\n",
      "     |  \n",
      "     |  index_filename\n",
      "     |  \n",
      "     |  is_bam\n",
      "     |      return True if HTSFile is reading or writing a BAM alignment file\n",
      "     |  \n",
      "     |  is_bcf\n",
      "     |      return True if HTSFile is reading or writing a BCF variant file\n",
      "     |  \n",
      "     |  is_closed\n",
      "     |      return True if HTSFile is closed.\n",
      "     |  \n",
      "     |  is_cram\n",
      "     |      return True if HTSFile is reading or writing a BAM alignment file\n",
      "     |  \n",
      "     |  is_open\n",
      "     |      return True if HTSFile is open and in a valid state.\n",
      "     |  \n",
      "     |  is_read\n",
      "     |      return True if HTSFile is open for reading\n",
      "     |  \n",
      "     |  is_remote\n",
      "     |  \n",
      "     |  is_sam\n",
      "     |      return True if HTSFile is reading or writing a SAM alignment file\n",
      "     |  \n",
      "     |  is_stream\n",
      "     |  \n",
      "     |  is_vcf\n",
      "     |      return True if HTSFile is reading or writing a VCF variant file\n",
      "     |  \n",
      "     |  is_write\n",
      "     |      return True if HTSFile is open for writing\n",
      "     |  \n",
      "     |  mode\n",
      "     |  \n",
      "     |  threads\n",
      "     |  \n",
      "     |  version\n",
      "     |      Tuple of file format version numbers (major, minor)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "    \n",
      "    class IndexedReads(builtins.object)\n",
      "     |  IndexedReads(AlignmentFile samfile, int multiple_iterators=True)\n",
      "     |  *(AlignmentFile samfile, multiple_iterators=True)\n",
      "     |  \n",
      "     |      Index a Sam/BAM-file by query name while keeping the\n",
      "     |      original sort order intact.\n",
      "     |  \n",
      "     |      The index is kept in memory and can be substantial.\n",
      "     |  \n",
      "     |      By default, the file is re-openend to avoid conflicts if multiple\n",
      "     |      operators work on the same file. Set `multiple_iterators` = False\n",
      "     |      to not re-open `samfile`.\n",
      "     |  \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |  \n",
      "     |      samfile : AlignmentFile\n",
      "     |          File to be indexed.\n",
      "     |  \n",
      "     |      multiple_iterators : bool\n",
      "     |          Flag indicating whether the file should be reopened. Reopening prevents\n",
      "     |          existing iterators being affected by the indexing.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      IndexedReads.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      IndexedReads.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  build(...)\n",
      "     |      IndexedReads.build(self)\n",
      "     |      build the index.\n",
      "     |  \n",
      "     |  find(...)\n",
      "     |      IndexedReads.find(self, query_name)\n",
      "     |      find `query_name` in index.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              IteratorRowSelection\n",
      "     |                  Returns an iterator over all reads with query_name.\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              KeyError\n",
      "     |                  if the `query_name` is not in the index.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class IteratorColumn(builtins.object)\n",
      "     |  abstract base class for iterators over columns.\n",
      "     |  \n",
      "     |  IteratorColumn objects wrap the pileup functionality of samtools.\n",
      "     |  \n",
      "     |  For reasons of efficiency, the iterator points to the current\n",
      "     |  pileup buffer. The pileup buffer is updated at every iteration.\n",
      "     |  This might cause some unexpected behavious. For example,\n",
      "     |  consider the conversion to a list::\n",
      "     |  \n",
      "     |     f = AlignmentFile(\"file.bam\", \"rb\")\n",
      "     |     result = list(f.pileup())\n",
      "     |  \n",
      "     |  Here, ``result`` will contain ``n`` objects of type\n",
      "     |  :class:`~pysam.PileupColumn` for ``n`` columns, but each object in\n",
      "     |  ``result`` will contain the same information.\n",
      "     |  \n",
      "     |  The desired behaviour can be achieved by list comprehension::\n",
      "     |  \n",
      "     |     result = [x.pileups() for x in f.pileup()]\n",
      "     |  \n",
      "     |  ``result`` will be a list of ``n`` lists of objects of type\n",
      "     |  :class:`~pysam.PileupRead`.\n",
      "     |  \n",
      "     |  If the iterator is associated with a :class:`~pysam.Fastafile`\n",
      "     |  using the :meth:`add_reference` method, then the iterator will\n",
      "     |  export the current sequence via the methods :meth:`get_sequence`\n",
      "     |  and :meth:`seq_len`.\n",
      "     |  \n",
      "     |  See :class:`~AlignmentFile.pileup` for kwargs to the iterator.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      IteratorColumn.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      IteratorColumn.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  addReference(...)\n",
      "     |      IteratorColumn.addReference(self, FastaFile fastafile)\n",
      "     |  \n",
      "     |  add_reference(...)\n",
      "     |      IteratorColumn.add_reference(self, FastaFile fastafile)\n",
      "     |      \n",
      "     |      add reference sequences in `fastafile` to iterator.\n",
      "     |  \n",
      "     |  hasReference(...)\n",
      "     |      IteratorColumn.hasReference(self)\n",
      "     |  \n",
      "     |  has_reference(...)\n",
      "     |      IteratorColumn.has_reference(self)\n",
      "     |      \n",
      "     |      return true if iterator is associated with a reference\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  seq_len\n",
      "     |      current sequence length.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "    \n",
      "    class IteratorRow(builtins.object)\n",
      "     |  IteratorRow(AlignmentFile samfile, int multiple_iterators=False)\n",
      "     |  abstract base class for iterators over mapped reads.\n",
      "     |  \n",
      "     |      Various iterators implement different behaviours for wrapping around\n",
      "     |      contig boundaries. Examples include:\n",
      "     |  \n",
      "     |      :class:`pysam.IteratorRowRegion`\n",
      "     |          iterate within a single contig and a defined region.\n",
      "     |  \n",
      "     |      :class:`pysam.IteratorRowAll`\n",
      "     |          iterate until EOF. This iterator will also include unmapped reads.\n",
      "     |  \n",
      "     |      :class:`pysam.IteratorRowAllRefs`\n",
      "     |          iterate over all reads in all reference sequences.\n",
      "     |  \n",
      "     |      The method :meth:`AlignmentFile.fetch` returns an IteratorRow.\n",
      "     |  \n",
      "     |      .. note::\n",
      "     |  \n",
      "     |          It is usually not necessary to create an object of this class\n",
      "     |          explicitly. It is returned as a result of call to a\n",
      "     |          :meth:`AlignmentFile.fetch`.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      IteratorRow.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      IteratorRow.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class PileupColumn(builtins.object)\n",
      "     |  PileupColumn()\n",
      "     |  A pileup of reads at a particular reference sequence position\n",
      "     |      (:term:`column`). A pileup column contains all the reads that map\n",
      "     |      to a certain target base.\n",
      "     |  \n",
      "     |      This class is a proxy for results returned by the samtools pileup\n",
      "     |      engine.  If the underlying engine iterator advances, the results\n",
      "     |      of this column will change.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(...)\n",
      "     |      return number of reads aligned to this column.\n",
      "     |      \n",
      "     |      see :meth:`get_num_aligned`\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      PileupColumn.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      PileupColumn.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  get_mapping_qualities(...)\n",
      "     |      PileupColumn.get_mapping_qualities(self)\n",
      "     |      query mapping quality scores at pileup column position.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              list: a list of quality scores\n",
      "     |  \n",
      "     |  get_num_aligned(...)\n",
      "     |      PileupColumn.get_num_aligned(self)\n",
      "     |      return number of aligned bases at pileup column position.\n",
      "     |              \n",
      "     |              This method applies a base quality filter and the number is\n",
      "     |              equal to the size of :meth:`get_query_sequences`,\n",
      "     |              :meth:`get_mapping_qualities`, etc.\n",
      "     |  \n",
      "     |  get_query_names(...)\n",
      "     |      PileupColumn.get_query_names(self)\n",
      "     |      query/read names aligned at pileup column position.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              list: a list of query names at pileup column position.\n",
      "     |  \n",
      "     |  get_query_positions(...)\n",
      "     |      PileupColumn.get_query_positions(self)\n",
      "     |      positions in read at pileup column position.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              list: a list of read positions\n",
      "     |  \n",
      "     |  get_query_qualities(...)\n",
      "     |      PileupColumn.get_query_qualities(self)\n",
      "     |      query base quality scores at pileup column position.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              list: a list of quality scores\n",
      "     |  \n",
      "     |  get_query_sequences(...)\n",
      "     |      PileupColumn.get_query_sequences(self, bool mark_matches=False, bool mark_ends=False, bool add_indels=False)\n",
      "     |      query bases/sequences at pileup column position.\n",
      "     |      \n",
      "     |              Optionally, the bases/sequences can be annotated according to the samtools\n",
      "     |              mpileup format. This is the format description from the samtools mpileup tool::\n",
      "     |              \n",
      "     |                 Information on match, mismatch, indel, strand, mapping\n",
      "     |                 quality and start and end of a read are all encoded at the\n",
      "     |                 read base column. At this column, a dot stands for a match\n",
      "     |                 to the reference base on the forward strand, a comma for a\n",
      "     |                 match on the reverse strand, a '>' or '<' for a reference\n",
      "     |                 skip, `ACGTN' for a mismatch on the forward strand and\n",
      "     |                 `acgtn' for a mismatch on the reverse strand. A pattern\n",
      "     |                 `\\+[0-9]+[ACGTNacgtn]+' indicates there is an insertion\n",
      "     |                 between this reference position and the next reference\n",
      "     |                 position. The length of the insertion is given by the\n",
      "     |                 integer in the pattern, followed by the inserted\n",
      "     |                 sequence. Similarly, a pattern `-[0-9]+[ACGTNacgtn]+'\n",
      "     |                 represents a deletion from the reference. The deleted bases\n",
      "     |                 will be presented as `*' in the following lines. Also at\n",
      "     |                 the read base column, a symbol `^' marks the start of a\n",
      "     |                 read. The ASCII of the character following `^' minus 33\n",
      "     |                 gives the mapping quality. A symbol `$' marks the end of a\n",
      "     |                 read segment\n",
      "     |      \n",
      "     |              To reproduce samtools mpileup format, set all of mark_matches,\n",
      "     |              mark_ends and add_indels to True.\n",
      "     |              \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              mark_matches: bool\n",
      "     |      \n",
      "     |                If True, output bases matching the reference as \",\" or \".\"\n",
      "     |                for forward and reverse strand, respectively. This mark\n",
      "     |                requires the reference sequence. If no reference is\n",
      "     |                present, this option is ignored.\n",
      "     |      \n",
      "     |              mark_ends : bool\n",
      "     |      \n",
      "     |                If True, add markers \"^\" and \"$\" for read start and end, respectively.\n",
      "     |      \n",
      "     |              add_indels : bool\n",
      "     |      \n",
      "     |                If True, add bases for bases inserted into the reference and\n",
      "     |                'N's for base skipped from the reference. If a reference sequence\n",
      "     |                is given, add the actual bases.\n",
      "     |       \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              list: a list of bases/sequences per read at pileup column position.\n",
      "     |  \n",
      "     |  set_min_base_quality(...)\n",
      "     |      PileupColumn.set_min_base_quality(self, min_base_quality)\n",
      "     |      set the minimum base quality for this pileup column.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  n\n",
      "     |      deprecated: use nsegments\n",
      "     |  \n",
      "     |  nsegments\n",
      "     |      number of reads mapping to this column.\n",
      "     |      \n",
      "     |      Note that this number ignores the base quality filter.\n",
      "     |  \n",
      "     |  pileups\n",
      "     |      list of reads (:class:`pysam.PileupRead`) aligned to this column\n",
      "     |  \n",
      "     |  pos\n",
      "     |      deprecated: use reference_pos\n",
      "     |  \n",
      "     |  reference_id\n",
      "     |      the reference sequence number as defined in the header\n",
      "     |  \n",
      "     |  reference_name\n",
      "     |      :term:`reference` name (None if no AlignmentFile is associated)\n",
      "     |  \n",
      "     |  reference_pos\n",
      "     |      the position in the reference sequence (0-based).\n",
      "     |  \n",
      "     |  tid\n",
      "     |      deprecated: use reference_id\n",
      "    \n",
      "    class PileupRead(builtins.object)\n",
      "     |  PileupRead()\n",
      "     |  Representation of a read aligned to a particular position in the\n",
      "     |      reference sequence.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      PileupRead.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      PileupRead.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  alignment\n",
      "     |      a :class:`pysam.AlignedSegment` object of the aligned read\n",
      "     |  \n",
      "     |  indel\n",
      "     |      indel length for the position following the current pileup site.\n",
      "     |      \n",
      "     |      This quantity peeks ahead to the next cigar operation in this\n",
      "     |      alignment. If the next operation is an insertion, indel will\n",
      "     |      be positive. If the next operation is a deletion, it will be\n",
      "     |      negation. 0 if the next operation is not an indel.\n",
      "     |  \n",
      "     |  is_del\n",
      "     |      1 iff the base on the padded read is a deletion\n",
      "     |  \n",
      "     |  is_head\n",
      "     |      1 iff the base on the padded read is the left-most base.\n",
      "     |  \n",
      "     |  is_refskip\n",
      "     |      1 iff the base on the padded read is part of CIGAR N op.\n",
      "     |  \n",
      "     |  is_tail\n",
      "     |      1 iff the base on the padded read is the right-most base.\n",
      "     |  \n",
      "     |  level\n",
      "     |      the level of the read in the \"viewer\" mode. Note that this value\n",
      "     |      is currently not computed.\n",
      "     |  \n",
      "     |  query_position\n",
      "     |      position of the read base at the pileup site, 0-based.\n",
      "     |      None if is_del or is_refskip is set.\n",
      "     |  \n",
      "     |  query_position_or_next\n",
      "     |      position of the read base at the pileup site, 0-based.\n",
      "     |      \n",
      "     |      If the current position is a deletion, returns the next\n",
      "     |      aligned base.\n",
      "    \n",
      "    class Samfile(pysam.libcalignmentfile.AlignmentFile)\n",
      "     |  Deprecated alternative for :class:`~pysam.AlignmentFile`\n",
      "     |  \n",
      "     |  Added for backwards compatibility with pysam <= 0.8.0\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Samfile\n",
      "     |      pysam.libcalignmentfile.AlignmentFile\n",
      "     |      pysam.libchtslib.HTSFile\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      Samfile.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      Samfile.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysam.libcalignmentfile.AlignmentFile:\n",
      "     |  \n",
      "     |  __enter__(...)\n",
      "     |      AlignmentFile.__enter__(self)\n",
      "     |  \n",
      "     |  __exit__(...)\n",
      "     |      AlignmentFile.__exit__(self, exc_type, exc_value, traceback)\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __next__(...)\n",
      "     |  \n",
      "     |  check_index(...)\n",
      "     |      AlignmentFile.check_index(self)\n",
      "     |      return True if index is present.\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              AttributeError\n",
      "     |                  if htsfile is :term:`SAM` formatted and thus has no index.\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                  if htsfile is closed or index could not be opened.\n",
      "     |  \n",
      "     |  close(...)\n",
      "     |      AlignmentFile.close(self)\n",
      "     |      closes the :class:`pysam.AlignmentFile`.\n",
      "     |  \n",
      "     |  count(...)\n",
      "     |      AlignmentFile.count(self, contig=None, start=None, stop=None, region=None, until_eof=False, read_callback='nofilter', reference=None, end=None)\n",
      "     |      count the number of reads in :term:`region`\n",
      "     |      \n",
      "     |              The region is specified by :term:`contig`, `start` and `stop`.\n",
      "     |              :term:`reference` and `end` are also accepted for backward\n",
      "     |              compatiblity as synonyms for :term:`contig` and `stop`,\n",
      "     |              respectively.  Alternatively, a :term:`samtools` :term:`region`\n",
      "     |              string can be supplied.\n",
      "     |      \n",
      "     |              A :term:`SAM` file does not allow random access and if\n",
      "     |              `region` or `contig` are given, an exception is raised.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              contig : string\n",
      "     |                  reference_name of the genomic region (chromosome)\n",
      "     |      \n",
      "     |              start : int\n",
      "     |                  start of the genomic region (0-based inclusive)\n",
      "     |      \n",
      "     |              stop : int\n",
      "     |                  end of the genomic region (0-based exclusive)\n",
      "     |      \n",
      "     |              region : string\n",
      "     |                  a region string in samtools format.\n",
      "     |      \n",
      "     |              until_eof : bool\n",
      "     |                  count until the end of the file, possibly including\n",
      "     |                  unmapped reads as well.\n",
      "     |      \n",
      "     |              read_callback: string or function\n",
      "     |      \n",
      "     |                  select a call-back to ignore reads when counting. It can\n",
      "     |                  be either a string with the following values:\n",
      "     |      \n",
      "     |                  ``all``\n",
      "     |                      skip reads in which any of the following\n",
      "     |                      flags are set: BAM_FUNMAP, BAM_FSECONDARY, BAM_FQCFAIL,\n",
      "     |                      BAM_FDUP\n",
      "     |      \n",
      "     |                  ``nofilter``\n",
      "     |                      uses every single read\n",
      "     |      \n",
      "     |                  Alternatively, `read_callback` can be a function\n",
      "     |                  ``check_read(read)`` that should return True only for\n",
      "     |                  those reads that shall be included in the counting.\n",
      "     |      \n",
      "     |              reference : string\n",
      "     |                  backward compatible synonym for `contig`\n",
      "     |      \n",
      "     |              end : int\n",
      "     |                  backward compatible synonym for `stop`\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                  if the genomic coordinates are out of range or invalid.\n",
      "     |  \n",
      "     |  count_coverage(...)\n",
      "     |      AlignmentFile.count_coverage(self, contig, start=None, stop=None, region=None, quality_threshold=15, read_callback='all', reference=None, end=None)\n",
      "     |      count the coverage of genomic positions by reads in :term:`region`.\n",
      "     |      \n",
      "     |              The region is specified by :term:`contig`, `start` and `stop`.\n",
      "     |              :term:`reference` and `end` are also accepted for backward\n",
      "     |              compatiblity as synonyms for :term:`contig` and `stop`,\n",
      "     |              respectively.  Alternatively, a :term:`samtools` :term:`region`\n",
      "     |              string can be supplied.  The coverage is computed per-base [ACGT].\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              contig : string\n",
      "     |                  reference_name of the genomic region (chromosome)\n",
      "     |      \n",
      "     |              start : int\n",
      "     |                  start of the genomic region (0-based inclusive). If not\n",
      "     |                  given, count from the start of the chromosome.\n",
      "     |      \n",
      "     |              stop : int\n",
      "     |                  end of the genomic region (0-based exclusive). If not given,\n",
      "     |                  count to the end of the chromosome.\n",
      "     |      \n",
      "     |              region : int\n",
      "     |                  a region string.\n",
      "     |      \n",
      "     |              quality_threshold : int\n",
      "     |                  quality_threshold is the minimum quality score (in phred) a\n",
      "     |                  base has to reach to be counted.\n",
      "     |      \n",
      "     |              read_callback: string or function\n",
      "     |      \n",
      "     |                  select a call-back to ignore reads when counting. It can\n",
      "     |                  be either a string with the following values:\n",
      "     |      \n",
      "     |                  ``all``\n",
      "     |                      skip reads in which any of the following\n",
      "     |                      flags are set: BAM_FUNMAP, BAM_FSECONDARY, BAM_FQCFAIL,\n",
      "     |                      BAM_FDUP\n",
      "     |      \n",
      "     |                  ``nofilter``\n",
      "     |                      uses every single read\n",
      "     |      \n",
      "     |                  Alternatively, `read_callback` can be a function\n",
      "     |                  ``check_read(read)`` that should return True only for\n",
      "     |                  those reads that shall be included in the counting.\n",
      "     |      \n",
      "     |              reference : string\n",
      "     |                  backward compatible synonym for `contig`\n",
      "     |      \n",
      "     |              end : int\n",
      "     |                  backward compatible synonym for `stop`\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                  if the genomic coordinates are out of range or invalid.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              four array.arrays of the same length in order A C G T : tuple\n",
      "     |  \n",
      "     |  fetch(...)\n",
      "     |      AlignmentFile.fetch(self, contig=None, start=None, stop=None, region=None, tid=None, until_eof=False, multiple_iterators=False, reference=None, end=None)\n",
      "     |      fetch reads aligned in a :term:`region`.\n",
      "     |      \n",
      "     |              See :meth:`~pysam.HTSFile.parse_region` for more information\n",
      "     |              on how genomic regions can be specified. :term:`reference` and\n",
      "     |              `end` are also accepted for backward compatiblity as synonyms\n",
      "     |              for :term:`contig` and `stop`, respectively.\n",
      "     |      \n",
      "     |              Without a `contig` or `region` all mapped reads in the file\n",
      "     |              will be fetched. The reads will be returned ordered by reference\n",
      "     |              sequence, which will not necessarily be the order within the\n",
      "     |              file. This mode of iteration still requires an index. If there is\n",
      "     |              no index, use `until_eof=True`.\n",
      "     |      \n",
      "     |              If only `contig` is set, all reads aligned to `contig`\n",
      "     |              will be fetched.\n",
      "     |      \n",
      "     |              A :term:`SAM` file does not allow random access. If `region`\n",
      "     |              or `contig` are given, an exception is raised.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              until_eof : bool\n",
      "     |      \n",
      "     |                 If `until_eof` is True, all reads from the current file\n",
      "     |                 position will be returned in order as they are within the\n",
      "     |                 file. Using this option will also fetch unmapped reads.\n",
      "     |      \n",
      "     |              multiple_iterators : bool\n",
      "     |      \n",
      "     |                 If `multiple_iterators` is True, multiple\n",
      "     |                 iterators on the same file can be used at the same time. The\n",
      "     |                 iterator returned will receive its own copy of a filehandle to\n",
      "     |                 the file effectively re-opening the file. Re-opening a file\n",
      "     |                 creates some overhead, so beware.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              An iterator over a collection of reads.\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                  if the genomic coordinates are out of range or invalid or the\n",
      "     |                  file does not permit random access to genomic coordinates.\n",
      "     |  \n",
      "     |  find_introns(...)\n",
      "     |      AlignmentFile.find_introns(self, read_iterator)\n",
      "     |      Return a dictionary {(start, stop): count}\n",
      "     |              Listing the intronic sites in the reads (identified by 'N' in the cigar strings),\n",
      "     |              and their support ( = number of reads ).\n",
      "     |      \n",
      "     |              read_iterator can be the result of a .fetch(...) call.\n",
      "     |              Or it can be a generator filtering such reads. Example\n",
      "     |              samfile.find_introns((read for read in samfile.fetch(...) if read.is_reverse)\n",
      "     |  \n",
      "     |  find_introns_slow(...)\n",
      "     |      AlignmentFile.find_introns_slow(self, read_iterator)\n",
      "     |      Return a dictionary {(start, stop): count}\n",
      "     |              Listing the intronic sites in the reads (identified by 'N' in the cigar strings),\n",
      "     |              and their support ( = number of reads ).\n",
      "     |      \n",
      "     |              read_iterator can be the result of a .fetch(...) call.\n",
      "     |              Or it can be a generator filtering such reads. Example\n",
      "     |              samfile.find_introns((read for read in samfile.fetch(...) if read.is_reverse)\n",
      "     |  \n",
      "     |  get_index_statistics(...)\n",
      "     |      AlignmentFile.get_index_statistics(self)\n",
      "     |      return statistics about mapped/unmapped reads per chromosome as\n",
      "     |              they are stored in the index.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |              list : a list of records for each chromosome. Each record has the attributes 'contig',\n",
      "     |                     'mapped', 'unmapped' and 'total'.\n",
      "     |  \n",
      "     |  get_reference_length(...)\n",
      "     |      AlignmentFile.get_reference_length(self, reference)\n",
      "     |      \n",
      "     |      return :term:`reference` name corresponding to numerical :term:`tid`\n",
      "     |  \n",
      "     |  get_reference_name(...)\n",
      "     |      AlignmentFile.get_reference_name(self, tid)\n",
      "     |      \n",
      "     |      return :term:`reference` name corresponding to numerical :term:`tid`\n",
      "     |  \n",
      "     |  get_tid(...)\n",
      "     |      AlignmentFile.get_tid(self, reference)\n",
      "     |      \n",
      "     |      return the numerical :term:`tid` corresponding to\n",
      "     |      :term:`reference`\n",
      "     |      \n",
      "     |      returns -1 if reference is not known.\n",
      "     |  \n",
      "     |  getrname(...)\n",
      "     |      AlignmentFile.getrname(self, tid)\n",
      "     |      deprecated, use get_reference_name() instead\n",
      "     |  \n",
      "     |  gettid(...)\n",
      "     |      AlignmentFile.gettid(self, reference)\n",
      "     |      deprecated, use get_tid() instead\n",
      "     |  \n",
      "     |  has_index(...)\n",
      "     |      AlignmentFile.has_index(self)\n",
      "     |      return true if htsfile has an existing (and opened) index.\n",
      "     |  \n",
      "     |  head(...)\n",
      "     |      AlignmentFile.head(self, n, multiple_iterators=True)\n",
      "     |      return an iterator over the first n alignments.\n",
      "     |      \n",
      "     |              This iterator is is useful for inspecting the bam-file.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              multiple_iterators : bool\n",
      "     |      \n",
      "     |                  is set to True by default in order to\n",
      "     |                  avoid changing the current file position.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              an iterator over a collection of reads\n",
      "     |  \n",
      "     |  is_valid_tid(...)\n",
      "     |      AlignmentFile.is_valid_tid(self, int tid)\n",
      "     |      \n",
      "     |      return True if the numerical :term:`tid` is valid; False otherwise.\n",
      "     |      \n",
      "     |      Note that the unmapped tid code (-1) counts as an invalid.\n",
      "     |  \n",
      "     |  mate(...)\n",
      "     |      AlignmentFile.mate(self, AlignedSegment read)\n",
      "     |      return the mate of :class:`~pysam.AlignedSegment` `read`.\n",
      "     |      \n",
      "     |              .. note::\n",
      "     |      \n",
      "     |                  Calling this method will change the file position.\n",
      "     |                  This might interfere with any iterators that have\n",
      "     |                  not re-opened the file.\n",
      "     |      \n",
      "     |              .. note::\n",
      "     |      \n",
      "     |                 This method is too slow for high-throughput processing.\n",
      "     |                 If a read needs to be processed with its mate, work\n",
      "     |                 from a read name sorted file or, better, cache reads.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              :class:`~pysam.AlignedSegment` : the mate\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                  if the read is unpaired or the mate is unmapped\n",
      "     |  \n",
      "     |  pileup(...)\n",
      "     |      AlignmentFile.pileup(self, contig=None, start=None, stop=None, region=None, reference=None, end=None, **kwargs)\n",
      "     |      perform a :term:`pileup` within a :term:`region`. The region is\n",
      "     |              specified by :term:`contig`, `start` and `stop` (using\n",
      "     |              0-based indexing).  :term:`reference` and `end` are also accepted for\n",
      "     |              backward compatiblity as synonyms for :term:`contig` and `stop`,\n",
      "     |              respectively.  Alternatively, a samtools 'region' string\n",
      "     |              can be supplied.\n",
      "     |      \n",
      "     |              Without 'contig' or 'region' all reads will be used for the\n",
      "     |              pileup. The reads will be returned ordered by\n",
      "     |              :term:`contig` sequence, which will not necessarily be the\n",
      "     |              order within the file.\n",
      "     |      \n",
      "     |              Note that :term:`SAM` formatted files do not allow random\n",
      "     |              access.  In these files, if a 'region' or 'contig' are\n",
      "     |              given an exception is raised.\n",
      "     |      \n",
      "     |              .. note::\n",
      "     |      \n",
      "     |                  'all' reads which overlap the region are returned. The\n",
      "     |                  first base returned will be the first base of the first\n",
      "     |                  read 'not' necessarily the first base of the region used\n",
      "     |                  in the query.\n",
      "     |      \n",
      "     |              Parameters\n",
      "     |              ----------\n",
      "     |      \n",
      "     |              truncate : bool\n",
      "     |      \n",
      "     |                 By default, the samtools pileup engine outputs all reads\n",
      "     |                 overlapping a region. If truncate is True and a region is\n",
      "     |                 given, only columns in the exact region specificied are\n",
      "     |                 returned.\n",
      "     |      \n",
      "     |              max_depth : int\n",
      "     |                 Maximum read depth permitted. The default limit is '8000'.\n",
      "     |      \n",
      "     |              stepper : string\n",
      "     |                 The stepper controls how the iterator advances.\n",
      "     |                 Possible options for the stepper are\n",
      "     |      \n",
      "     |                 ``all``\n",
      "     |                    skip reads in which any of the following flags are set:\n",
      "     |                    BAM_FUNMAP, BAM_FSECONDARY, BAM_FQCFAIL, BAM_FDUP\n",
      "     |      \n",
      "     |                 ``nofilter``\n",
      "     |                    uses every single read turning off any filtering.\n",
      "     |      \n",
      "     |                 ``samtools``\n",
      "     |                    same filter and read processing as in :term:`csamtools`\n",
      "     |                    pileup. For full compatibility, this requires a\n",
      "     |                    'fastafile' to be given. The following options all pertain\n",
      "     |                    to filtering of the ``samtools`` stepper.\n",
      "     |      \n",
      "     |              fastafile : :class:`~pysam.FastaFile` object.\n",
      "     |      \n",
      "     |                 This is required for some of the steppers.\n",
      "     |      \n",
      "     |              ignore_overlaps: bool\n",
      "     |      \n",
      "     |                 If set to True, detect if read pairs overlap and only take\n",
      "     |                 the higher quality base. This is the default.\n",
      "     |      \n",
      "     |              flag_filter : int\n",
      "     |      \n",
      "     |                 ignore reads where any of the bits in the flag are set. The default is\n",
      "     |                 BAM_FUNMAP | BAM_FSECONDARY | BAM_FQCFAIL | BAM_FDUP.\n",
      "     |      \n",
      "     |              flag_require : int\n",
      "     |      \n",
      "     |                 only use reads where certain flags are set. The default is 0.\n",
      "     |      \n",
      "     |              ignore_orphans: bool\n",
      "     |      \n",
      "     |                  ignore orphans (paired reads that are not in a proper pair).\n",
      "     |                  The default is to ignore orphans.\n",
      "     |         \n",
      "     |              min_base_quality: int\n",
      "     |      \n",
      "     |                 Minimum base quality. Bases below the minimum quality will\n",
      "     |                 not be output.\n",
      "     |      \n",
      "     |              adjust_capq_threshold: int\n",
      "     |      \n",
      "     |                 adjust mapping quality. The default is 0 for no\n",
      "     |                 adjustment. The recommended value for adjustment is 50.\n",
      "     |      \n",
      "     |              min_mapping_quality : int\n",
      "     |      \n",
      "     |                 only use reads above a minimum mapping quality. The default is 0.\n",
      "     |      \n",
      "     |              compute_baq: bool\n",
      "     |      \n",
      "     |                 re-alignment computing per-Base Alignment Qualities (BAQ). The\n",
      "     |                 default is to do re-alignment. Realignment requires a reference\n",
      "     |                 sequence. If none is present, no realignment will be performed.\n",
      "     |      \n",
      "     |              redo_baq: bool\n",
      "     |      \n",
      "     |                 recompute per-Base Alignment Quality on the fly ignoring\n",
      "     |                 existing base qualities. The default is False (use existing\n",
      "     |                 base qualities).\n",
      "     |      \n",
      "     |              adjust_capq_threshold: int\n",
      "     |      \n",
      "     |                  adjust mapping quality. The default is 0 for no\n",
      "     |                  adjustment. The recommended value for adjustment is 50.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              an iterator over genomic positions.\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      AlignmentFile.write(self, AlignedSegment read) -> int\n",
      "     |      \n",
      "     |      write a single :class:`pysam.AlignedSegment` to disk.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          if the writing failed\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      \n",
      "     |      int : the number of bytes written. If the file is closed,\n",
      "     |            this will be 0.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysam.libcalignmentfile.AlignmentFile:\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  lengths\n",
      "     |      tuple of the lengths of the :term:`reference` sequences. This is a\n",
      "     |      read-only attribute. The lengths are in the same order as\n",
      "     |      :attr:`pysam.AlignmentFile.references`\n",
      "     |  \n",
      "     |  mapped\n",
      "     |      int with total number of mapped alignments according to the\n",
      "     |      statistics recorded in the index. This is a read-only\n",
      "     |      attribute.\n",
      "     |  \n",
      "     |  nocoordinate\n",
      "     |      int with total number of reads without coordinates according to the\n",
      "     |      statistics recorded in the index. This is a read-only attribute.\n",
      "     |  \n",
      "     |  nreferences\n",
      "     |      \"int with the number of :term:`reference` sequences in the file.\n",
      "     |      This is a read-only attribute.\n",
      "     |  \n",
      "     |  reference_filename\n",
      "     |  \n",
      "     |  references\n",
      "     |      tuple with the names of :term:`reference` sequences. This is a\n",
      "     |      read-only attribute\n",
      "     |  \n",
      "     |  text\n",
      "     |      deprecated, use .header directly\n",
      "     |  \n",
      "     |  unmapped\n",
      "     |      int with total number of unmapped reads according to the statistics\n",
      "     |      recorded in the index. This number of reads includes the number of reads\n",
      "     |      without coordinates. This is a read-only attribute.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysam.libchtslib.HTSFile:\n",
      "     |  \n",
      "     |  add_hts_options(...)\n",
      "     |      HTSFile.add_hts_options(self, format_options=None)\n",
      "     |      Given a list of key=value format option strings, add them to an open htsFile\n",
      "     |  \n",
      "     |  check_truncation(...)\n",
      "     |      HTSFile.check_truncation(self, ignore_truncation=False)\n",
      "     |      Check if file is truncated.\n",
      "     |  \n",
      "     |  is_valid_reference_name(...)\n",
      "     |      HTSFile.is_valid_reference_name(self, contig)\n",
      "     |      \n",
      "     |      return True if the contig name :term:`contig` is valid; False otherwise.\n",
      "     |  \n",
      "     |  parse_region(...)\n",
      "     |      HTSFile.parse_region(self, contig=None, start=None, stop=None, region=None, tid=None, reference=None, end=None)\n",
      "     |      parse alternative ways to specify a genomic region. A region can\n",
      "     |              either be specified by :term:`contig`, `start` and\n",
      "     |              `stop`. `start` and `stop` denote 0-based, half-open\n",
      "     |              intervals. :term:`reference` and `end` are also accepted for\n",
      "     |              backward compatiblity as synonyms for :term:`contig` and\n",
      "     |              `stop`, respectively.\n",
      "     |      \n",
      "     |              Alternatively, a samtools :term:`region` string can be\n",
      "     |              supplied.\n",
      "     |      \n",
      "     |              If any of the coordinates are missing they will be replaced by\n",
      "     |              the minimum (`start`) or maximum (`stop`) coordinate.\n",
      "     |      \n",
      "     |              Note that region strings are 1-based inclusive, while `start`\n",
      "     |              and `stop` denote an interval in 0-based, half-open\n",
      "     |              coordinates (like BED files and Python slices).\n",
      "     |      \n",
      "     |              If `contig` or `region` or are ``*``, unmapped reads at the end\n",
      "     |              of a BAM file will be returned. Setting either to ``.`` will\n",
      "     |              iterate from the beginning of the file.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              tuple : a tuple of `flag`, :term:`tid`, `start` and\n",
      "     |              `stop`. The flag indicates whether no coordinates were\n",
      "     |              supplied and the genomic region is the complete genomic space.\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                 for invalid or out of bounds regions.\n",
      "     |  \n",
      "     |  reset(...)\n",
      "     |      HTSFile.reset(self)\n",
      "     |      reset file position to beginning of file just after the header.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              The file position after moving the file pointer.\n",
      "     |  \n",
      "     |  seek(...)\n",
      "     |      HTSFile.seek(self, uint64_t offset)\n",
      "     |      move file pointer to position *offset*, see :meth:`pysam.HTSFile.tell`.\n",
      "     |  \n",
      "     |  tell(...)\n",
      "     |      HTSFile.tell(self)\n",
      "     |      return current file position, see :meth:`pysam.HTSFile.seek`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysam.libchtslib.HTSFile:\n",
      "     |  \n",
      "     |  category\n",
      "     |      General file format category.  One of UNKNOWN, ALIGNMENTS,\n",
      "     |      VARIANTS, INDEX, REGIONS\n",
      "     |  \n",
      "     |  closed\n",
      "     |      return True if HTSFile is closed.\n",
      "     |  \n",
      "     |  compression\n",
      "     |      File compression.\n",
      "     |      \n",
      "     |      One of NONE, GZIP, BGZF, CUSTOM.\n",
      "     |  \n",
      "     |  description\n",
      "     |      Vaguely human readable description of the file format\n",
      "     |  \n",
      "     |  duplicate_filehandle\n",
      "     |  \n",
      "     |  filename\n",
      "     |  \n",
      "     |  format\n",
      "     |      File format.\n",
      "     |      \n",
      "     |      One of UNKNOWN, BINARY_FORMAT, TEXT_FORMAT, SAM, BAM,\n",
      "     |      BAI, CRAM, CRAI, VCF, BCF, CSI, GZI, TBI, BED.\n",
      "     |  \n",
      "     |  index_filename\n",
      "     |  \n",
      "     |  is_bam\n",
      "     |      return True if HTSFile is reading or writing a BAM alignment file\n",
      "     |  \n",
      "     |  is_bcf\n",
      "     |      return True if HTSFile is reading or writing a BCF variant file\n",
      "     |  \n",
      "     |  is_closed\n",
      "     |      return True if HTSFile is closed.\n",
      "     |  \n",
      "     |  is_cram\n",
      "     |      return True if HTSFile is reading or writing a BAM alignment file\n",
      "     |  \n",
      "     |  is_open\n",
      "     |      return True if HTSFile is open and in a valid state.\n",
      "     |  \n",
      "     |  is_read\n",
      "     |      return True if HTSFile is open for reading\n",
      "     |  \n",
      "     |  is_remote\n",
      "     |  \n",
      "     |  is_sam\n",
      "     |      return True if HTSFile is reading or writing a SAM alignment file\n",
      "     |  \n",
      "     |  is_stream\n",
      "     |  \n",
      "     |  is_vcf\n",
      "     |      return True if HTSFile is reading or writing a VCF variant file\n",
      "     |  \n",
      "     |  is_write\n",
      "     |      return True if HTSFile is open for writing\n",
      "     |  \n",
      "     |  mode\n",
      "     |  \n",
      "     |  threads\n",
      "     |  \n",
      "     |  version\n",
      "     |      Tuple of file format version numbers (major, minor)\n",
      "    \n",
      "    class SamtoolsError(builtins.Exception)\n",
      "     |  SamtoolsError(value)\n",
      "     |  \n",
      "     |  exception raised in case of an error incurred in the samtools\n",
      "     |  library.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SamtoolsError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, value)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class TabixFile(pysam.libchtslib.HTSFile)\n",
      "     |  Random access to bgzf formatted files that\n",
      "     |  have been indexed by :term:`tabix`.\n",
      "     |  \n",
      "     |  The file is automatically opened. The index file of file\n",
      "     |  ``<filename>`` is expected to be called ``<filename>.tbi``\n",
      "     |  by default (see parameter `index`).\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  \n",
      "     |  filename : string\n",
      "     |      Filename of bgzf file to be opened.\n",
      "     |  \n",
      "     |  index : string\n",
      "     |      The filename of the index. If not set, the default is to\n",
      "     |      assume that the index is called ``filename.tbi`\n",
      "     |  \n",
      "     |  mode : char\n",
      "     |      The file opening mode. Currently, only ``r`` is permitted.\n",
      "     |      \n",
      "     |  parser : :class:`pysam.Parser`\n",
      "     |  \n",
      "     |      sets the default parser for this tabix file. If `parser`\n",
      "     |      is None, the results are returned as an unparsed string.\n",
      "     |      Otherwise, `parser` is assumed to be a functor that will return\n",
      "     |      parsed data (see for example :class:`~pysam.asTuple` and\n",
      "     |      :class:`~pysam.asGTF`).\n",
      "     |  \n",
      "     |  encoding : string\n",
      "     |  \n",
      "     |      The encoding passed to the parser\n",
      "     |  \n",
      "     |  threads: integer\n",
      "     |      Number of threads to use for decompressing Tabix files.\n",
      "     |      (Default=1)\n",
      "     |  \n",
      "     |  \n",
      "     |  Raises\n",
      "     |  ------\n",
      "     |  \n",
      "     |  ValueError\n",
      "     |      if index file is missing.\n",
      "     |  \n",
      "     |  IOError\n",
      "     |      if file could not be opened\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TabixFile\n",
      "     |      pysam.libchtslib.HTSFile\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      TabixFile.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      TabixFile.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  close(...)\n",
      "     |      TabixFile.close(self)\n",
      "     |      \n",
      "     |      closes the :class:`pysam.TabixFile`.\n",
      "     |  \n",
      "     |  fetch(...)\n",
      "     |      TabixFile.fetch(self, reference=None, start=None, end=None, region=None, parser=None, multiple_iterators=False)\n",
      "     |      fetch one or more rows in a :term:`region` using 0-based\n",
      "     |              indexing. The region is specified by :term:`reference`,\n",
      "     |              *start* and *end*. Alternatively, a samtools :term:`region`\n",
      "     |              string can be supplied.\n",
      "     |      \n",
      "     |              Without *reference* or *region* all entries will be fetched. \n",
      "     |              \n",
      "     |              If only *reference* is set, all reads matching on *reference*\n",
      "     |              will be fetched.\n",
      "     |      \n",
      "     |              If *parser* is None, the default parser will be used for\n",
      "     |              parsing.\n",
      "     |              \n",
      "     |              Set *multiple_iterators* to true if you will be using multiple\n",
      "     |              iterators on the same file at the same time. The iterator\n",
      "     |              returned will receive its own copy of a filehandle to the file\n",
      "     |              effectively re-opening the file. Re-opening a file creates\n",
      "     |              some overhead, so beware.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  contigs\n",
      "     |      list of chromosome names\n",
      "     |  \n",
      "     |  filename_index\n",
      "     |  \n",
      "     |  header\n",
      "     |      the file header.\n",
      "     |      \n",
      "     |      The file header consists of the lines at the beginning of a\n",
      "     |      file that are prefixed by the comment character ``#``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          The header is returned as an iterator presenting lines\n",
      "     |          without the newline character.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysam.libchtslib.HTSFile:\n",
      "     |  \n",
      "     |  __enter__(...)\n",
      "     |      HTSFile.__enter__(self)\n",
      "     |  \n",
      "     |  __exit__(...)\n",
      "     |      HTSFile.__exit__(self, exc_type, exc_value, traceback)\n",
      "     |  \n",
      "     |  add_hts_options(...)\n",
      "     |      HTSFile.add_hts_options(self, format_options=None)\n",
      "     |      Given a list of key=value format option strings, add them to an open htsFile\n",
      "     |  \n",
      "     |  check_truncation(...)\n",
      "     |      HTSFile.check_truncation(self, ignore_truncation=False)\n",
      "     |      Check if file is truncated.\n",
      "     |  \n",
      "     |  get_reference_name(...)\n",
      "     |      HTSFile.get_reference_name(self, tid)\n",
      "     |      \n",
      "     |      return :term:`contig` name corresponding to numerical :term:`tid`\n",
      "     |  \n",
      "     |  get_tid(...)\n",
      "     |      HTSFile.get_tid(self, contig)\n",
      "     |      \n",
      "     |      return the numerical :term:`tid` corresponding to\n",
      "     |      :term:`contig`\n",
      "     |      \n",
      "     |      returns -1 if contig is not known.\n",
      "     |  \n",
      "     |  is_valid_reference_name(...)\n",
      "     |      HTSFile.is_valid_reference_name(self, contig)\n",
      "     |      \n",
      "     |      return True if the contig name :term:`contig` is valid; False otherwise.\n",
      "     |  \n",
      "     |  is_valid_tid(...)\n",
      "     |      HTSFile.is_valid_tid(self, tid)\n",
      "     |      \n",
      "     |      return True if the numerical :term:`tid` is valid; False otherwise.\n",
      "     |      \n",
      "     |      returns -1 if contig is not known.\n",
      "     |  \n",
      "     |  parse_region(...)\n",
      "     |      HTSFile.parse_region(self, contig=None, start=None, stop=None, region=None, tid=None, reference=None, end=None)\n",
      "     |      parse alternative ways to specify a genomic region. A region can\n",
      "     |              either be specified by :term:`contig`, `start` and\n",
      "     |              `stop`. `start` and `stop` denote 0-based, half-open\n",
      "     |              intervals. :term:`reference` and `end` are also accepted for\n",
      "     |              backward compatiblity as synonyms for :term:`contig` and\n",
      "     |              `stop`, respectively.\n",
      "     |      \n",
      "     |              Alternatively, a samtools :term:`region` string can be\n",
      "     |              supplied.\n",
      "     |      \n",
      "     |              If any of the coordinates are missing they will be replaced by\n",
      "     |              the minimum (`start`) or maximum (`stop`) coordinate.\n",
      "     |      \n",
      "     |              Note that region strings are 1-based inclusive, while `start`\n",
      "     |              and `stop` denote an interval in 0-based, half-open\n",
      "     |              coordinates (like BED files and Python slices).\n",
      "     |      \n",
      "     |              If `contig` or `region` or are ``*``, unmapped reads at the end\n",
      "     |              of a BAM file will be returned. Setting either to ``.`` will\n",
      "     |              iterate from the beginning of the file.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              tuple : a tuple of `flag`, :term:`tid`, `start` and\n",
      "     |              `stop`. The flag indicates whether no coordinates were\n",
      "     |              supplied and the genomic region is the complete genomic space.\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                 for invalid or out of bounds regions.\n",
      "     |  \n",
      "     |  reset(...)\n",
      "     |      HTSFile.reset(self)\n",
      "     |      reset file position to beginning of file just after the header.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              The file position after moving the file pointer.\n",
      "     |  \n",
      "     |  seek(...)\n",
      "     |      HTSFile.seek(self, uint64_t offset)\n",
      "     |      move file pointer to position *offset*, see :meth:`pysam.HTSFile.tell`.\n",
      "     |  \n",
      "     |  tell(...)\n",
      "     |      HTSFile.tell(self)\n",
      "     |      return current file position, see :meth:`pysam.HTSFile.seek`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysam.libchtslib.HTSFile:\n",
      "     |  \n",
      "     |  category\n",
      "     |      General file format category.  One of UNKNOWN, ALIGNMENTS,\n",
      "     |      VARIANTS, INDEX, REGIONS\n",
      "     |  \n",
      "     |  closed\n",
      "     |      return True if HTSFile is closed.\n",
      "     |  \n",
      "     |  compression\n",
      "     |      File compression.\n",
      "     |      \n",
      "     |      One of NONE, GZIP, BGZF, CUSTOM.\n",
      "     |  \n",
      "     |  description\n",
      "     |      Vaguely human readable description of the file format\n",
      "     |  \n",
      "     |  duplicate_filehandle\n",
      "     |  \n",
      "     |  filename\n",
      "     |  \n",
      "     |  format\n",
      "     |      File format.\n",
      "     |      \n",
      "     |      One of UNKNOWN, BINARY_FORMAT, TEXT_FORMAT, SAM, BAM,\n",
      "     |      BAI, CRAM, CRAI, VCF, BCF, CSI, GZI, TBI, BED.\n",
      "     |  \n",
      "     |  index_filename\n",
      "     |  \n",
      "     |  is_bam\n",
      "     |      return True if HTSFile is reading or writing a BAM alignment file\n",
      "     |  \n",
      "     |  is_bcf\n",
      "     |      return True if HTSFile is reading or writing a BCF variant file\n",
      "     |  \n",
      "     |  is_closed\n",
      "     |      return True if HTSFile is closed.\n",
      "     |  \n",
      "     |  is_cram\n",
      "     |      return True if HTSFile is reading or writing a BAM alignment file\n",
      "     |  \n",
      "     |  is_open\n",
      "     |      return True if HTSFile is open and in a valid state.\n",
      "     |  \n",
      "     |  is_read\n",
      "     |      return True if HTSFile is open for reading\n",
      "     |  \n",
      "     |  is_remote\n",
      "     |  \n",
      "     |  is_sam\n",
      "     |      return True if HTSFile is reading or writing a SAM alignment file\n",
      "     |  \n",
      "     |  is_stream\n",
      "     |  \n",
      "     |  is_vcf\n",
      "     |      return True if HTSFile is reading or writing a VCF variant file\n",
      "     |  \n",
      "     |  is_write\n",
      "     |      return True if HTSFile is open for writing\n",
      "     |  \n",
      "     |  mode\n",
      "     |  \n",
      "     |  threads\n",
      "     |  \n",
      "     |  version\n",
      "     |      Tuple of file format version numbers (major, minor)\n",
      "    \n",
      "    class Tabixfile(TabixFile)\n",
      "     |  Tabixfile is deprecated: use TabixFile instead\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Tabixfile\n",
      "     |      TabixFile\n",
      "     |      pysam.libchtslib.HTSFile\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      Tabixfile.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      Tabixfile.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from TabixFile:\n",
      "     |  \n",
      "     |  close(...)\n",
      "     |      TabixFile.close(self)\n",
      "     |      \n",
      "     |      closes the :class:`pysam.TabixFile`.\n",
      "     |  \n",
      "     |  fetch(...)\n",
      "     |      TabixFile.fetch(self, reference=None, start=None, end=None, region=None, parser=None, multiple_iterators=False)\n",
      "     |      fetch one or more rows in a :term:`region` using 0-based\n",
      "     |              indexing. The region is specified by :term:`reference`,\n",
      "     |              *start* and *end*. Alternatively, a samtools :term:`region`\n",
      "     |              string can be supplied.\n",
      "     |      \n",
      "     |              Without *reference* or *region* all entries will be fetched. \n",
      "     |              \n",
      "     |              If only *reference* is set, all reads matching on *reference*\n",
      "     |              will be fetched.\n",
      "     |      \n",
      "     |              If *parser* is None, the default parser will be used for\n",
      "     |              parsing.\n",
      "     |              \n",
      "     |              Set *multiple_iterators* to true if you will be using multiple\n",
      "     |              iterators on the same file at the same time. The iterator\n",
      "     |              returned will receive its own copy of a filehandle to the file\n",
      "     |              effectively re-opening the file. Re-opening a file creates\n",
      "     |              some overhead, so beware.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from TabixFile:\n",
      "     |  \n",
      "     |  contigs\n",
      "     |      list of chromosome names\n",
      "     |  \n",
      "     |  filename_index\n",
      "     |  \n",
      "     |  header\n",
      "     |      the file header.\n",
      "     |      \n",
      "     |      The file header consists of the lines at the beginning of a\n",
      "     |      file that are prefixed by the comment character ``#``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          The header is returned as an iterator presenting lines\n",
      "     |          without the newline character.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysam.libchtslib.HTSFile:\n",
      "     |  \n",
      "     |  __enter__(...)\n",
      "     |      HTSFile.__enter__(self)\n",
      "     |  \n",
      "     |  __exit__(...)\n",
      "     |      HTSFile.__exit__(self, exc_type, exc_value, traceback)\n",
      "     |  \n",
      "     |  add_hts_options(...)\n",
      "     |      HTSFile.add_hts_options(self, format_options=None)\n",
      "     |      Given a list of key=value format option strings, add them to an open htsFile\n",
      "     |  \n",
      "     |  check_truncation(...)\n",
      "     |      HTSFile.check_truncation(self, ignore_truncation=False)\n",
      "     |      Check if file is truncated.\n",
      "     |  \n",
      "     |  get_reference_name(...)\n",
      "     |      HTSFile.get_reference_name(self, tid)\n",
      "     |      \n",
      "     |      return :term:`contig` name corresponding to numerical :term:`tid`\n",
      "     |  \n",
      "     |  get_tid(...)\n",
      "     |      HTSFile.get_tid(self, contig)\n",
      "     |      \n",
      "     |      return the numerical :term:`tid` corresponding to\n",
      "     |      :term:`contig`\n",
      "     |      \n",
      "     |      returns -1 if contig is not known.\n",
      "     |  \n",
      "     |  is_valid_reference_name(...)\n",
      "     |      HTSFile.is_valid_reference_name(self, contig)\n",
      "     |      \n",
      "     |      return True if the contig name :term:`contig` is valid; False otherwise.\n",
      "     |  \n",
      "     |  is_valid_tid(...)\n",
      "     |      HTSFile.is_valid_tid(self, tid)\n",
      "     |      \n",
      "     |      return True if the numerical :term:`tid` is valid; False otherwise.\n",
      "     |      \n",
      "     |      returns -1 if contig is not known.\n",
      "     |  \n",
      "     |  parse_region(...)\n",
      "     |      HTSFile.parse_region(self, contig=None, start=None, stop=None, region=None, tid=None, reference=None, end=None)\n",
      "     |      parse alternative ways to specify a genomic region. A region can\n",
      "     |              either be specified by :term:`contig`, `start` and\n",
      "     |              `stop`. `start` and `stop` denote 0-based, half-open\n",
      "     |              intervals. :term:`reference` and `end` are also accepted for\n",
      "     |              backward compatiblity as synonyms for :term:`contig` and\n",
      "     |              `stop`, respectively.\n",
      "     |      \n",
      "     |              Alternatively, a samtools :term:`region` string can be\n",
      "     |              supplied.\n",
      "     |      \n",
      "     |              If any of the coordinates are missing they will be replaced by\n",
      "     |              the minimum (`start`) or maximum (`stop`) coordinate.\n",
      "     |      \n",
      "     |              Note that region strings are 1-based inclusive, while `start`\n",
      "     |              and `stop` denote an interval in 0-based, half-open\n",
      "     |              coordinates (like BED files and Python slices).\n",
      "     |      \n",
      "     |              If `contig` or `region` or are ``*``, unmapped reads at the end\n",
      "     |              of a BAM file will be returned. Setting either to ``.`` will\n",
      "     |              iterate from the beginning of the file.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              tuple : a tuple of `flag`, :term:`tid`, `start` and\n",
      "     |              `stop`. The flag indicates whether no coordinates were\n",
      "     |              supplied and the genomic region is the complete genomic space.\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                 for invalid or out of bounds regions.\n",
      "     |  \n",
      "     |  reset(...)\n",
      "     |      HTSFile.reset(self)\n",
      "     |      reset file position to beginning of file just after the header.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              The file position after moving the file pointer.\n",
      "     |  \n",
      "     |  seek(...)\n",
      "     |      HTSFile.seek(self, uint64_t offset)\n",
      "     |      move file pointer to position *offset*, see :meth:`pysam.HTSFile.tell`.\n",
      "     |  \n",
      "     |  tell(...)\n",
      "     |      HTSFile.tell(self)\n",
      "     |      return current file position, see :meth:`pysam.HTSFile.seek`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysam.libchtslib.HTSFile:\n",
      "     |  \n",
      "     |  category\n",
      "     |      General file format category.  One of UNKNOWN, ALIGNMENTS,\n",
      "     |      VARIANTS, INDEX, REGIONS\n",
      "     |  \n",
      "     |  closed\n",
      "     |      return True if HTSFile is closed.\n",
      "     |  \n",
      "     |  compression\n",
      "     |      File compression.\n",
      "     |      \n",
      "     |      One of NONE, GZIP, BGZF, CUSTOM.\n",
      "     |  \n",
      "     |  description\n",
      "     |      Vaguely human readable description of the file format\n",
      "     |  \n",
      "     |  duplicate_filehandle\n",
      "     |  \n",
      "     |  filename\n",
      "     |  \n",
      "     |  format\n",
      "     |      File format.\n",
      "     |      \n",
      "     |      One of UNKNOWN, BINARY_FORMAT, TEXT_FORMAT, SAM, BAM,\n",
      "     |      BAI, CRAM, CRAI, VCF, BCF, CSI, GZI, TBI, BED.\n",
      "     |  \n",
      "     |  index_filename\n",
      "     |  \n",
      "     |  is_bam\n",
      "     |      return True if HTSFile is reading or writing a BAM alignment file\n",
      "     |  \n",
      "     |  is_bcf\n",
      "     |      return True if HTSFile is reading or writing a BCF variant file\n",
      "     |  \n",
      "     |  is_closed\n",
      "     |      return True if HTSFile is closed.\n",
      "     |  \n",
      "     |  is_cram\n",
      "     |      return True if HTSFile is reading or writing a BAM alignment file\n",
      "     |  \n",
      "     |  is_open\n",
      "     |      return True if HTSFile is open and in a valid state.\n",
      "     |  \n",
      "     |  is_read\n",
      "     |      return True if HTSFile is open for reading\n",
      "     |  \n",
      "     |  is_remote\n",
      "     |  \n",
      "     |  is_sam\n",
      "     |      return True if HTSFile is reading or writing a SAM alignment file\n",
      "     |  \n",
      "     |  is_stream\n",
      "     |  \n",
      "     |  is_vcf\n",
      "     |      return True if HTSFile is reading or writing a VCF variant file\n",
      "     |  \n",
      "     |  is_write\n",
      "     |      return True if HTSFile is open for writing\n",
      "     |  \n",
      "     |  mode\n",
      "     |  \n",
      "     |  threads\n",
      "     |  \n",
      "     |  version\n",
      "     |      Tuple of file format version numbers (major, minor)\n",
      "    \n",
      "    class VCF(builtins.object)\n",
      "     |  VCF(_copy=None, reference=None, regions=None, lines=None, leftalign=False)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |      VCF.__del__(self)\n",
      "     |  \n",
      "     |  __init__(self, _copy=None, reference=None, regions=None, lines=None, leftalign=False)\n",
      "     |      VCF.__init__(self, _copy=None, reference=None, regions=None, lines=None, leftalign=False)\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      VCF.close(self)\n",
      "     |  \n",
      "     |  compare_calls(self, pos1, ref1, alt1, pos2, ref2, alt2)\n",
      "     |      VCF.compare_calls(self, pos1, ref1, alt1, pos2, ref2, alt2)\n",
      "     |      Utility function: compares two calls for equality\n",
      "     |  \n",
      "     |  connect(self, filename, encoding='ascii')\n",
      "     |      VCF.connect(self, filename, encoding='ascii')\n",
      "     |      connect to tabix file.\n",
      "     |  \n",
      "     |  convertGT(self, GTstring)\n",
      "     |      VCF.convertGT(self, GTstring)\n",
      "     |  \n",
      "     |  convertGTback(self, GTdata)\n",
      "     |      VCF.convertGTback(self, GTdata)\n",
      "     |  \n",
      "     |  enter_default_format(self)\n",
      "     |      VCF.enter_default_format(self)\n",
      "     |  \n",
      "     |  error(self, line, error, opt=None)\n",
      "     |      VCF.error(self, line, error, opt=None)\n",
      "     |  \n",
      "     |  fetch(self, reference=None, start=None, end=None, region=None)\n",
      "     |      VCF.fetch(self, reference=None, start=None, end=None, region=None)\n",
      "     |      Parse a stream of VCF-formatted lines.\n",
      "     |             Initializes class instance and return generator\n",
      "     |  \n",
      "     |  format_format(self, fmt, filter=False)\n",
      "     |      VCF.format_format(self, fmt, filter=False)\n",
      "     |  \n",
      "     |  format_formatdata(self, data, format, key=True, value=True, separator=':')\n",
      "     |      VCF.format_formatdata(self, data, format, key=True, value=True, separator=':')\n",
      "     |  \n",
      "     |  get_expected(self, format, formatdict, alt)\n",
      "     |      VCF.get_expected(self, format, formatdict, alt)\n",
      "     |  \n",
      "     |  getfilter(self)\n",
      "     |      VCF.getfilter(self)\n",
      "     |      Dictionary of ##FILTER tags, as VCF.FORMAT values\n",
      "     |  \n",
      "     |  getformat(self)\n",
      "     |      VCF.getformat(self)\n",
      "     |      Dictionary of ##FORMAT tags, as VCF.FORMAT values\n",
      "     |  \n",
      "     |  getheader(self)\n",
      "     |      VCF.getheader(self)\n",
      "     |      List of header key-value pairs (strings)\n",
      "     |  \n",
      "     |  getinfo(self)\n",
      "     |      VCF.getinfo(self)\n",
      "     |      Dictionary of ##INFO tags, as VCF.FORMAT values\n",
      "     |  \n",
      "     |  getsamples(self)\n",
      "     |      VCF.getsamples(self)\n",
      "     |      List of samples in VCF file\n",
      "     |  \n",
      "     |  ignoreerror(self, errorstring)\n",
      "     |      VCF.ignoreerror(self, errorstring)\n",
      "     |  \n",
      "     |  inregion(self, chrom, pos)\n",
      "     |      VCF.inregion(self, chrom, pos)\n",
      "     |  \n",
      "     |  parse(self, stream)\n",
      "     |      VCF.parse(self, stream)\n",
      "     |      Parse a stream of VCF-formatted lines.  Initializes class instance and return generator\n",
      "     |  \n",
      "     |  parse_data(self, line, lineparse=False)\n",
      "     |      VCF.parse_data(self, line, lineparse=False)\n",
      "     |  \n",
      "     |  parse_format(self, line, format, filter=False)\n",
      "     |      VCF.parse_format(self, line, format, filter=False)\n",
      "     |  \n",
      "     |  parse_formatdata(self, key, value, formatdict, line)\n",
      "     |      VCF.parse_formatdata(self, key, value, formatdict, line)\n",
      "     |  \n",
      "     |  parse_header(self, line)\n",
      "     |      VCF.parse_header(self, line)\n",
      "     |  \n",
      "     |  parse_heading(self, line)\n",
      "     |      VCF.parse_heading(self, line)\n",
      "     |  \n",
      "     |  setfilter(self, filter)\n",
      "     |      VCF.setfilter(self, filter)\n",
      "     |      Dictionary of ##FILTER tags, as VCF.FORMAT values\n",
      "     |  \n",
      "     |  setformat(self, format)\n",
      "     |      VCF.setformat(self, format)\n",
      "     |      Dictionary of ##FORMAT tags, as VCF.FORMAT values\n",
      "     |  \n",
      "     |  setheader(self, header)\n",
      "     |      VCF.setheader(self, header)\n",
      "     |      List of header key-value pairs (strings)\n",
      "     |  \n",
      "     |  setinfo(self, info)\n",
      "     |      VCF.setinfo(self, info)\n",
      "     |      Dictionary of ##INFO tags, as VCF.FORMAT values\n",
      "     |  \n",
      "     |  setreference(self, ref)\n",
      "     |      VCF.setreference(self, ref)\n",
      "     |      Provide a reference sequence; a Python class supporting a fetch(chromosome, start, end) method, e.g. PySam.FastaFile\n",
      "     |  \n",
      "     |  setregions(self, regions)\n",
      "     |      VCF.setregions(self, regions)\n",
      "     |  \n",
      "     |  setsamples(self, samples)\n",
      "     |      VCF.setsamples(self, samples)\n",
      "     |      List of samples in VCF file\n",
      "     |  \n",
      "     |  setversion(self, version)\n",
      "     |      VCF.setversion(self, version)\n",
      "     |  \n",
      "     |  validate(self, record)\n",
      "     |      VCF.validate(self, record)\n",
      "     |      validate vcf record.\n",
      "     |      \n",
      "     |              returns a validated record.\n",
      "     |  \n",
      "     |  warnerror(self, errorstring)\n",
      "     |      VCF.warnerror(self, errorstring)\n",
      "     |  \n",
      "     |  write(self, stream, datagenerator)\n",
      "     |      VCF.write(self, stream, datagenerator)\n",
      "     |      Writes a VCF file to a stream, using a data generator (or list)\n",
      "     |  \n",
      "     |  write_data(self, stream, data)\n",
      "     |      VCF.write_data(self, stream, data)\n",
      "     |  \n",
      "     |  write_header(self, stream)\n",
      "     |      VCF.write_header(self, stream)\n",
      "     |  \n",
      "     |  write_heading(self, stream)\n",
      "     |      VCF.write_heading(self, stream)\n",
      "     |  \n",
      "     |  writeheader(self, stream)\n",
      "     |      VCF.writeheader(self, stream)\n",
      "     |      Writes a VCF header\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  NT_ALLELES = 2\n",
      "     |  \n",
      "     |  NT_GENOTYPES = 4\n",
      "     |  \n",
      "     |  NT_NR_ALLELES = 3\n",
      "     |  \n",
      "     |  NT_NUMBER = 1\n",
      "     |  \n",
      "     |  NT_PHASED_GENOTYPES = 5\n",
      "     |  \n",
      "     |  NT_UNKNOWN = 0\n",
      "    \n",
      "    class VCFRecord(pysam.libctabixproxies.TupleProxy)\n",
      "     |  VCFRecord(vcf)\n",
      "     |  vcf record.\n",
      "     |  \n",
      "     |      initialized from data and vcf meta\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VCFRecord\n",
      "     |      pysam.libctabixproxies.TupleProxy\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      VCFRecord.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      VCFRecord.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  error(...)\n",
      "     |      VCFRecord.error(self, line, error, opt=None)\n",
      "     |      raise error.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  alt\n",
      "     |  \n",
      "     |  contig\n",
      "     |  \n",
      "     |  filter\n",
      "     |  \n",
      "     |  format\n",
      "     |  \n",
      "     |  id\n",
      "     |  \n",
      "     |  info\n",
      "     |  \n",
      "     |  pos\n",
      "     |  \n",
      "     |  qual\n",
      "     |  \n",
      "     |  ref\n",
      "     |  \n",
      "     |  samples\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysam.libctabixproxies.TupleProxy:\n",
      "     |  \n",
      "     |  __copy__(...)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __next__(...)\n",
      "     |      python version of next().\n",
      "     |  \n",
      "     |  __setitem__(...)\n",
      "     |      set item at *index* to *value*\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      return original data\n",
      "     |  \n",
      "     |  compare(...)\n",
      "     |      return -1,0,1, if contents in this are binary\n",
      "     |      <,=,> to *other*\n",
      "     |  \n",
      "     |  getMaxFields(...)\n",
      "     |      return maximum number of fields. Return \n",
      "     |      0 for unknown length.\n",
      "     |  \n",
      "     |  getMinFields(...)\n",
      "     |      return minimum number of fields.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pysam.libctabixproxies.TupleProxy:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class VariantFile(pysam.libchtslib.HTSFile)\n",
      "     |  VariantFile(*args, **kwargs)\n",
      "     |  *(filename, mode=None, index_filename=None, header=None, drop_samples=False,\n",
      "     |      duplicate_filehandle=True, ignore_truncation=False, threads=1)*\n",
      "     |  \n",
      "     |      A :term:`VCF`/:term:`BCF` formatted file. The file is automatically\n",
      "     |      opened.\n",
      "     |  \n",
      "     |      If an index for a variant file exists (.csi or .tbi), it will be\n",
      "     |      opened automatically.  Without an index random access to records\n",
      "     |      via :meth:`fetch` is disabled.\n",
      "     |  \n",
      "     |      For writing, a :class:`VariantHeader` object must be provided,\n",
      "     |      typically obtained from another :term:`VCF` file/:term:`BCF`\n",
      "     |      file.\n",
      "     |  \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mode : string\n",
      "     |          *mode* should be ``r`` for reading or ``w`` for writing. The default is\n",
      "     |          text mode (:term:`VCF`).  For binary (:term:`BCF`) I/O you should append\n",
      "     |          ``b`` for compressed or ``u`` for uncompressed :term:`BCF` output.\n",
      "     |  \n",
      "     |          If ``b`` is present, it must immediately follow ``r`` or ``w``.  Valid\n",
      "     |          modes are ``r``, ``w``, ``wh``, ``rb``, ``wb``, ``wbu`` and ``wb0``.\n",
      "     |          For instance, to open a :term:`BCF` formatted file for reading, type::\n",
      "     |  \n",
      "     |              f = pysam.VariantFile('ex1.bcf','r')\n",
      "     |  \n",
      "     |          If mode is not specified, we will try to auto-detect the file type.  All\n",
      "     |          of the following should work::\n",
      "     |  \n",
      "     |              f1 = pysam.VariantFile('ex1.bcf')\n",
      "     |              f2 = pysam.VariantFile('ex1.vcf')\n",
      "     |              f3 = pysam.VariantFile('ex1.vcf.gz')\n",
      "     |  \n",
      "     |      index_filename : string\n",
      "     |          Explicit path to an index file.\n",
      "     |  \n",
      "     |      header : VariantHeader\n",
      "     |          :class:`VariantHeader` object required for writing.\n",
      "     |  \n",
      "     |      drop_samples: bool\n",
      "     |          Ignore sample information when reading.\n",
      "     |  \n",
      "     |      duplicate_filehandle: bool\n",
      "     |          By default, file handles passed either directly or through\n",
      "     |          File-like objects will be duplicated before passing them to\n",
      "     |          htslib. The duplication prevents issues where the same stream\n",
      "     |          will be closed by htslib and through destruction of the\n",
      "     |          high-level python object. Set to False to turn off\n",
      "     |          duplication.\n",
      "     |  \n",
      "     |      ignore_truncation: bool\n",
      "     |          Issue a warning, instead of raising an error if the current file\n",
      "     |          appears to be truncated due to a missing EOF marker.  Only applies\n",
      "     |          to bgzipped formats. (Default=False)\n",
      "     |  \n",
      "     |      threads: integer\n",
      "     |          Number of threads to use for compressing/decompressing VCF/BCF files.\n",
      "     |          Setting threads to > 1 cannot be combined with `ignore_truncation`.\n",
      "     |          (Default=1)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VariantFile\n",
      "     |      pysam.libchtslib.HTSFile\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __next__(...)\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      VariantFile.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      VariantFile.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  close(...)\n",
      "     |      VariantFile.close(self)\n",
      "     |      closes the :class:`pysam.VariantFile`.\n",
      "     |  \n",
      "     |  copy(...)\n",
      "     |      VariantFile.copy(self)\n",
      "     |  \n",
      "     |  fetch(...)\n",
      "     |      VariantFile.fetch(self, contig=None, start=None, stop=None, region=None, reopen=False, end=None, reference=None)\n",
      "     |      fetch records in a :term:`region` using 0-based indexing. The\n",
      "     |              region is specified by :term:`contig`, *start* and *end*.\n",
      "     |              Alternatively, a samtools :term:`region` string can be supplied.\n",
      "     |      \n",
      "     |              Without *contig* or *region* all mapped records will be fetched.  The\n",
      "     |              records will be returned ordered by contig, which will not necessarily\n",
      "     |              be the order within the file.\n",
      "     |      \n",
      "     |              Set *reopen* to true if you will be using multiple iterators on the\n",
      "     |              same file at the same time.  The iterator returned will receive its\n",
      "     |              own copy of a filehandle to the file effectively re-opening the\n",
      "     |              file.  Re-opening a file incurrs some overhead, so use with care.\n",
      "     |      \n",
      "     |              If only *contig* is set, all records on *contig* will be fetched.\n",
      "     |              If both *region* and *contig* are given, an exception is raised.\n",
      "     |      \n",
      "     |              Note that a bgzipped :term:`VCF`.gz file without a tabix/CSI index\n",
      "     |              (.tbi/.csi) or a :term:`BCF` file without a CSI index can only be\n",
      "     |              read sequentially.\n",
      "     |  \n",
      "     |  get_reference_name(...)\n",
      "     |      VariantFile.get_reference_name(self, tid)\n",
      "     |      \n",
      "     |      return :term:`reference` name corresponding to numerical :term:`tid`\n",
      "     |  \n",
      "     |  get_tid(...)\n",
      "     |      VariantFile.get_tid(self, reference)\n",
      "     |      \n",
      "     |      return the numerical :term:`tid` corresponding to\n",
      "     |      :term:`reference`\n",
      "     |      \n",
      "     |      returns -1 if reference is not known.\n",
      "     |  \n",
      "     |  is_valid_tid(...)\n",
      "     |      VariantFile.is_valid_tid(self, tid)\n",
      "     |      \n",
      "     |      return True if the numerical :term:`tid` is valid; False otherwise.\n",
      "     |      \n",
      "     |      returns -1 if reference is not known.\n",
      "     |  \n",
      "     |  new_record(...)\n",
      "     |      VariantFile.new_record(self, *args, **kwargs)\n",
      "     |      Create a new empty :class:`VariantRecord`.\n",
      "     |      \n",
      "     |              See :meth:`VariantHeader.new_record`\n",
      "     |  \n",
      "     |  open(...)\n",
      "     |      VariantFile.open(self, filename, mode='r', index_filename=None, VariantHeader header=None, drop_samples=False, duplicate_filehandle=True, ignore_truncation=False, threads=1)\n",
      "     |      open a vcf/bcf file.\n",
      "     |      \n",
      "     |              If open is called on an existing VariantFile, the current file will be\n",
      "     |              closed and a new file will be opened.\n",
      "     |  \n",
      "     |  reset(...)\n",
      "     |      VariantFile.reset(self)\n",
      "     |      reset file position to beginning of file just after the header.\n",
      "     |  \n",
      "     |  subset_samples(...)\n",
      "     |      VariantFile.subset_samples(self, include_samples)\n",
      "     |      \n",
      "     |      Read only a subset of samples to reduce processing time and memory.\n",
      "     |      Must be called prior to retrieving records.\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      VariantFile.write(self, VariantRecord record) -> int\n",
      "     |      \n",
      "     |      write a single :class:`pysam.VariantRecord` to disk.\n",
      "     |      \n",
      "     |      returns the number of bytes written.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  drop_samples\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  header_written\n",
      "     |  \n",
      "     |  index\n",
      "     |  \n",
      "     |  is_reading\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysam.libchtslib.HTSFile:\n",
      "     |  \n",
      "     |  __enter__(...)\n",
      "     |      HTSFile.__enter__(self)\n",
      "     |  \n",
      "     |  __exit__(...)\n",
      "     |      HTSFile.__exit__(self, exc_type, exc_value, traceback)\n",
      "     |  \n",
      "     |  add_hts_options(...)\n",
      "     |      HTSFile.add_hts_options(self, format_options=None)\n",
      "     |      Given a list of key=value format option strings, add them to an open htsFile\n",
      "     |  \n",
      "     |  check_truncation(...)\n",
      "     |      HTSFile.check_truncation(self, ignore_truncation=False)\n",
      "     |      Check if file is truncated.\n",
      "     |  \n",
      "     |  is_valid_reference_name(...)\n",
      "     |      HTSFile.is_valid_reference_name(self, contig)\n",
      "     |      \n",
      "     |      return True if the contig name :term:`contig` is valid; False otherwise.\n",
      "     |  \n",
      "     |  parse_region(...)\n",
      "     |      HTSFile.parse_region(self, contig=None, start=None, stop=None, region=None, tid=None, reference=None, end=None)\n",
      "     |      parse alternative ways to specify a genomic region. A region can\n",
      "     |              either be specified by :term:`contig`, `start` and\n",
      "     |              `stop`. `start` and `stop` denote 0-based, half-open\n",
      "     |              intervals. :term:`reference` and `end` are also accepted for\n",
      "     |              backward compatiblity as synonyms for :term:`contig` and\n",
      "     |              `stop`, respectively.\n",
      "     |      \n",
      "     |              Alternatively, a samtools :term:`region` string can be\n",
      "     |              supplied.\n",
      "     |      \n",
      "     |              If any of the coordinates are missing they will be replaced by\n",
      "     |              the minimum (`start`) or maximum (`stop`) coordinate.\n",
      "     |      \n",
      "     |              Note that region strings are 1-based inclusive, while `start`\n",
      "     |              and `stop` denote an interval in 0-based, half-open\n",
      "     |              coordinates (like BED files and Python slices).\n",
      "     |      \n",
      "     |              If `contig` or `region` or are ``*``, unmapped reads at the end\n",
      "     |              of a BAM file will be returned. Setting either to ``.`` will\n",
      "     |              iterate from the beginning of the file.\n",
      "     |      \n",
      "     |              Returns\n",
      "     |              -------\n",
      "     |      \n",
      "     |              tuple : a tuple of `flag`, :term:`tid`, `start` and\n",
      "     |              `stop`. The flag indicates whether no coordinates were\n",
      "     |              supplied and the genomic region is the complete genomic space.\n",
      "     |      \n",
      "     |              Raises\n",
      "     |              ------\n",
      "     |      \n",
      "     |              ValueError\n",
      "     |                 for invalid or out of bounds regions.\n",
      "     |  \n",
      "     |  seek(...)\n",
      "     |      HTSFile.seek(self, uint64_t offset)\n",
      "     |      move file pointer to position *offset*, see :meth:`pysam.HTSFile.tell`.\n",
      "     |  \n",
      "     |  tell(...)\n",
      "     |      HTSFile.tell(self)\n",
      "     |      return current file position, see :meth:`pysam.HTSFile.seek`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysam.libchtslib.HTSFile:\n",
      "     |  \n",
      "     |  category\n",
      "     |      General file format category.  One of UNKNOWN, ALIGNMENTS,\n",
      "     |      VARIANTS, INDEX, REGIONS\n",
      "     |  \n",
      "     |  closed\n",
      "     |      return True if HTSFile is closed.\n",
      "     |  \n",
      "     |  compression\n",
      "     |      File compression.\n",
      "     |      \n",
      "     |      One of NONE, GZIP, BGZF, CUSTOM.\n",
      "     |  \n",
      "     |  description\n",
      "     |      Vaguely human readable description of the file format\n",
      "     |  \n",
      "     |  duplicate_filehandle\n",
      "     |  \n",
      "     |  filename\n",
      "     |  \n",
      "     |  format\n",
      "     |      File format.\n",
      "     |      \n",
      "     |      One of UNKNOWN, BINARY_FORMAT, TEXT_FORMAT, SAM, BAM,\n",
      "     |      BAI, CRAM, CRAI, VCF, BCF, CSI, GZI, TBI, BED.\n",
      "     |  \n",
      "     |  index_filename\n",
      "     |  \n",
      "     |  is_bam\n",
      "     |      return True if HTSFile is reading or writing a BAM alignment file\n",
      "     |  \n",
      "     |  is_bcf\n",
      "     |      return True if HTSFile is reading or writing a BCF variant file\n",
      "     |  \n",
      "     |  is_closed\n",
      "     |      return True if HTSFile is closed.\n",
      "     |  \n",
      "     |  is_cram\n",
      "     |      return True if HTSFile is reading or writing a BAM alignment file\n",
      "     |  \n",
      "     |  is_open\n",
      "     |      return True if HTSFile is open and in a valid state.\n",
      "     |  \n",
      "     |  is_read\n",
      "     |      return True if HTSFile is open for reading\n",
      "     |  \n",
      "     |  is_remote\n",
      "     |  \n",
      "     |  is_sam\n",
      "     |      return True if HTSFile is reading or writing a SAM alignment file\n",
      "     |  \n",
      "     |  is_stream\n",
      "     |  \n",
      "     |  is_vcf\n",
      "     |      return True if HTSFile is reading or writing a VCF variant file\n",
      "     |  \n",
      "     |  is_write\n",
      "     |      return True if HTSFile is open for writing\n",
      "     |  \n",
      "     |  mode\n",
      "     |  \n",
      "     |  threads\n",
      "     |  \n",
      "     |  version\n",
      "     |      Tuple of file format version numbers (major, minor)\n",
      "    \n",
      "    class VariantHeader(builtins.object)\n",
      "     |  VariantHeader()\n",
      "     |  header information for a :class:`VariantFile` object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __bool__(self, /)\n",
      "     |      self != 0\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      VariantHeader.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      VariantHeader.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  add_line(...)\n",
      "     |      VariantHeader.add_line(self, line)\n",
      "     |      Add a metadata line to this header\n",
      "     |  \n",
      "     |  add_meta(...)\n",
      "     |      VariantHeader.add_meta(self, key, value=None, items=None)\n",
      "     |      Add metadata to this header\n",
      "     |  \n",
      "     |  add_record(...)\n",
      "     |      VariantHeader.add_record(self, VariantHeaderRecord record)\n",
      "     |      Add an existing :class:`VariantHeaderRecord` to this header\n",
      "     |  \n",
      "     |  add_sample(...)\n",
      "     |      VariantHeader.add_sample(self, name)\n",
      "     |      Add a new sample to this header\n",
      "     |  \n",
      "     |  copy(...)\n",
      "     |      VariantHeader.copy(self)\n",
      "     |  \n",
      "     |  merge(...)\n",
      "     |      VariantHeader.merge(self, VariantHeader header)\n",
      "     |  \n",
      "     |  new_record(...)\n",
      "     |      VariantHeader.new_record(self, contig=None, start=0, stop=0, alleles=None, id=None, qual=None, filter=None, info=None, samples=None, **kwargs)\n",
      "     |      Create a new empty VariantRecord.\n",
      "     |      \n",
      "     |              Arguments are currently experimental.  Use with caution and expect\n",
      "     |              changes in upcoming releases.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  alts\n",
      "     |      alt metadata (:class:`dict` ID->record).\n",
      "     |      \n",
      "     |      The data returned just a snapshot of alt records, is created\n",
      "     |      every time the property is requested, and modifications will\n",
      "     |      not be reflected in the header metadata and vice versa.\n",
      "     |      \n",
      "     |      i.e. it is just a dict that reflects the state of alt records\n",
      "     |      at the time it is created.\n",
      "     |  \n",
      "     |  contigs\n",
      "     |      contig information (:class:`VariantHeaderContigs`)\n",
      "     |  \n",
      "     |  filters\n",
      "     |      filter metadata (:class:`VariantHeaderMetadata`)\n",
      "     |  \n",
      "     |  formats\n",
      "     |      format metadata (:class:`VariantHeaderMetadata`)\n",
      "     |  \n",
      "     |  info\n",
      "     |      info metadata (:class:`VariantHeaderMetadata`)\n",
      "     |  \n",
      "     |  records\n",
      "     |      header records (:class:`VariantHeaderRecords`)\n",
      "     |  \n",
      "     |  samples\n",
      "     |      samples (:class:`VariantHeaderSamples`)\n",
      "     |  \n",
      "     |  version\n",
      "     |      VCF version\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "    \n",
      "    class VariantHeaderRecord(builtins.object)\n",
      "     |  VariantHeaderRecord(*args, **kwargs)\n",
      "     |  header record from a :class:`VariantHeader` object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __bool__(self, /)\n",
      "     |      self != 0\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __getitem__(...)\n",
      "     |      get attribute value\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      VariantHeaderRecord.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      VariantHeaderRecord.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  get(...)\n",
      "     |      VariantHeaderRecord.get(self, key, default=None)\n",
      "     |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      "     |  \n",
      "     |  items(...)\n",
      "     |      VariantHeaderRecord.items(self)\n",
      "     |      D.items() -> list of D's (key, value) pairs, as 2-tuples\n",
      "     |  \n",
      "     |  iteritems(...)\n",
      "     |      VariantHeaderRecord.iteritems(self)\n",
      "     |      D.iteritems() -> an iterator over the (key, value) items of D\n",
      "     |  \n",
      "     |  iterkeys(...)\n",
      "     |      VariantHeaderRecord.iterkeys(self)\n",
      "     |      D.iterkeys() -> an iterator over the keys of D\n",
      "     |  \n",
      "     |  itervalues(...)\n",
      "     |      VariantHeaderRecord.itervalues(self)\n",
      "     |      D.itervalues() -> an iterator over the values of D\n",
      "     |  \n",
      "     |  keys(...)\n",
      "     |      VariantHeaderRecord.keys(self)\n",
      "     |      D.keys() -> list of D's keys\n",
      "     |  \n",
      "     |  pop(...)\n",
      "     |      VariantHeaderRecord.pop(self, key, default=_nothing)\n",
      "     |  \n",
      "     |  remove(...)\n",
      "     |      VariantHeaderRecord.remove(self)\n",
      "     |  \n",
      "     |  update(...)\n",
      "     |      VariantHeaderRecord.update(self, items=None, **kwargs)\n",
      "     |      D.update([E, ]**F) -> None.\n",
      "     |      \n",
      "     |              Update D from dict/iterable E and F.\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      VariantHeaderRecord.values(self)\n",
      "     |      D.values() -> list of D's values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  attrs\n",
      "     |      sequence of additional header attributes\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  key\n",
      "     |      header key (the part before '=', in FILTER/INFO/FORMAT/contig/fileformat etc.)\n",
      "     |  \n",
      "     |  type\n",
      "     |      header type: FILTER, INFO, FORMAT, CONTIG, STRUCTURED, or GENERIC\n",
      "     |  \n",
      "     |  value\n",
      "     |      header value.  Set only for generic lines, None for FILTER/INFO, etc.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class VariantRecord(builtins.object)\n",
      "     |  VariantRecord(*args, **kwargs)\n",
      "     |  Variant record\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      VariantRecord.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      VariantRecord.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  copy(...)\n",
      "     |      VariantRecord.copy(self)\n",
      "     |      return a copy of this VariantRecord object\n",
      "     |  \n",
      "     |  translate(...)\n",
      "     |      VariantRecord.translate(self, VariantHeader dst_header)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  alleles\n",
      "     |      tuple of reference allele followed by alt alleles\n",
      "     |  \n",
      "     |  alts\n",
      "     |      tuple of alt alleles\n",
      "     |  \n",
      "     |  chrom\n",
      "     |      chromosome/contig name\n",
      "     |  \n",
      "     |  contig\n",
      "     |      chromosome/contig name\n",
      "     |  \n",
      "     |  filter\n",
      "     |      filter information (see :class:`VariantRecordFilter`)\n",
      "     |  \n",
      "     |  format\n",
      "     |      sample format metadata (see :class:`VariantRecordFormat`)\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  id\n",
      "     |      record identifier or None if not available\n",
      "     |  \n",
      "     |  info\n",
      "     |      info data (see :class:`VariantRecordInfo`)\n",
      "     |  \n",
      "     |  pos\n",
      "     |      record start position on chrom/contig (1-based inclusive)\n",
      "     |  \n",
      "     |  qual\n",
      "     |      phred scaled quality score or None if not available\n",
      "     |  \n",
      "     |  ref\n",
      "     |      reference allele\n",
      "     |  \n",
      "     |  rid\n",
      "     |      internal reference id number\n",
      "     |  \n",
      "     |  rlen\n",
      "     |      record length on chrom/contig (aka rec.stop - rec.start)\n",
      "     |  \n",
      "     |  samples\n",
      "     |      sample data (see :class:`VariantRecordSamples`)\n",
      "     |  \n",
      "     |  start\n",
      "     |      record start position on chrom/contig (0-based inclusive)\n",
      "     |  \n",
      "     |  stop\n",
      "     |      record stop position on chrom/contig (0-based exclusive)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class asBed(Parser)\n",
      "     |  converts a :term:`tabix row` into a bed record\n",
      "     |  with the following fields:\n",
      "     |  \n",
      "     |  +-----------+-----------+------------------------------------------+\n",
      "     |  |*Column*   |*Field*    |*Contents*                                |\n",
      "     |  |           |           |                                          |\n",
      "     |  +-----------+-----------+------------------------------------------+\n",
      "     |  |1          |contig     |contig                                    |\n",
      "     |  |           |           |                                          |\n",
      "     |  +-----------+-----------+------------------------------------------+\n",
      "     |  |2          |start      |genomic start coordinate (zero-based)     |\n",
      "     |  +-----------+-----------+------------------------------------------+\n",
      "     |  |3          |end        |genomic end coordinate plus one           |\n",
      "     |  |           |           |(zero-based)                              |\n",
      "     |  +-----------+-----------+------------------------------------------+\n",
      "     |  |4          |name       |name of feature.                          |\n",
      "     |  +-----------+-----------+------------------------------------------+\n",
      "     |  |5          |score      |score of feature                          |\n",
      "     |  +-----------+-----------+------------------------------------------+\n",
      "     |  |6          |strand     |strand of feature                         |\n",
      "     |  +-----------+-----------+------------------------------------------+\n",
      "     |  |7          |thickStart |thickStart                                |\n",
      "     |  +-----------+-----------+------------------------------------------+\n",
      "     |  |8          |thickEnd   |thickEnd                                  |\n",
      "     |  +-----------+-----------+------------------------------------------+\n",
      "     |  |9          |itemRGB    |itemRGB                                   |\n",
      "     |  +-----------+-----------+------------------------------------------+\n",
      "     |  |10         |blockCount |number of bocks                           |\n",
      "     |  +-----------+-----------+------------------------------------------+\n",
      "     |  |11         |blockSizes |',' separated string of block sizes       |\n",
      "     |  +-----------+-----------+------------------------------------------+\n",
      "     |  |12         |blockStarts|',' separated string of block genomic     |\n",
      "     |  |           |           |start positions                           |\n",
      "     |  +-----------+-----------+------------------------------------------+\n",
      "     |  \n",
      "     |  Only the first three fields are required. Additional\n",
      "     |  fields are optional, but if one is defined, all the preceding\n",
      "     |  need to be defined as well.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      asBed\n",
      "     |      Parser\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      asBed.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      asBed.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Parser:\n",
      "     |  \n",
      "     |  __call__(self, /, *args, **kwargs)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_encoding(...)\n",
      "     |      Parser.get_encoding(self)\n",
      "     |  \n",
      "     |  set_encoding(...)\n",
      "     |      Parser.set_encoding(self, encoding)\n",
      "    \n",
      "    class asGFF3(Parser)\n",
      "     |  converts a :term:`tabix row` into a GFF record with the following\n",
      "     |  fields:\n",
      "     |  \n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |*Column*  |*Name*    |*Content*                      |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |1         |contig    |the chromosome name            |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |2         |feature   |The feature type               |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |3         |source    |The feature source             |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |4         |start     |genomic start coordinate       |\n",
      "     |  |          |          |(0-based)                      |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |5         |end       |genomic end coordinate         |\n",
      "     |  |          |          |(0-based)                      |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |6         |score     |feature score                  |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |7         |strand    |strand                         |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |8         |frame     |frame                          |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |9         |attributes|the attribute field            |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      asGFF3\n",
      "     |      Parser\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      asGFF3.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      asGFF3.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Parser:\n",
      "     |  \n",
      "     |  __call__(self, /, *args, **kwargs)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_encoding(...)\n",
      "     |      Parser.get_encoding(self)\n",
      "     |  \n",
      "     |  set_encoding(...)\n",
      "     |      Parser.set_encoding(self, encoding)\n",
      "    \n",
      "    class asGTF(Parser)\n",
      "     |  converts a :term:`tabix row` into a GTF record with the following\n",
      "     |  fields:\n",
      "     |  \n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |*Column*  |*Name*    |*Content*                      |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |1         |contig    |the chromosome name            |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |2         |feature   |The feature type               |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |3         |source    |The feature source             |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |4         |start     |genomic start coordinate       |\n",
      "     |  |          |          |(0-based)                      |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |5         |end       |genomic end coordinate         |\n",
      "     |  |          |          |(0-based)                      |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |6         |score     |feature score                  |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |7         |strand    |strand                         |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |8         |frame     |frame                          |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  |9         |attributes|the attribute field            |\n",
      "     |  +----------+----------+-------------------------------+\n",
      "     |  \n",
      "     |  GTF formatted entries also define the following fields that\n",
      "     |  are derived from the attributes field:\n",
      "     |  \n",
      "     |  +--------------------+------------------------------+\n",
      "     |  |*Name*              |*Content*                     |\n",
      "     |  +--------------------+------------------------------+\n",
      "     |  |gene_id             |the gene identifier           |\n",
      "     |  +--------------------+------------------------------+\n",
      "     |  |transcript_id       |the transcript identifier     |\n",
      "     |  +--------------------+------------------------------+\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      asGTF\n",
      "     |      Parser\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      asGTF.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      asGTF.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Parser:\n",
      "     |  \n",
      "     |  __call__(self, /, *args, **kwargs)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_encoding(...)\n",
      "     |      Parser.get_encoding(self)\n",
      "     |  \n",
      "     |  set_encoding(...)\n",
      "     |      Parser.set_encoding(self, encoding)\n",
      "    \n",
      "    class asTuple(Parser)\n",
      "     |  converts a :term:`tabix row` into a python tuple.\n",
      "     |  \n",
      "     |  A field in a row is accessed by numeric index.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      asTuple\n",
      "     |      Parser\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      asTuple.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      asTuple.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Parser:\n",
      "     |  \n",
      "     |  __call__(self, /, *args, **kwargs)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_encoding(...)\n",
      "     |      Parser.get_encoding(self)\n",
      "     |  \n",
      "     |  set_encoding(...)\n",
      "     |      Parser.set_encoding(self, encoding)\n",
      "    \n",
      "    class asVCF(Parser)\n",
      "     |  converts a :term:`tabix row` into a VCF record with\n",
      "     |  the following fields:\n",
      "     |  \n",
      "     |  +----------+---------+------------------------------------+\n",
      "     |  |*Column*  |*Field*  |*Contents*                          |\n",
      "     |  |          |         |                                    |\n",
      "     |  +----------+---------+------------------------------------+\n",
      "     |  |1         |contig   |chromosome                          |\n",
      "     |  +----------+---------+------------------------------------+\n",
      "     |  |2         |pos      |chromosomal position, zero-based    |\n",
      "     |  +----------+---------+------------------------------------+\n",
      "     |  |3         |id       |id                                  |\n",
      "     |  +----------+---------+------------------------------------+\n",
      "     |  |4         |ref      |reference allele                    |\n",
      "     |  +----------+---------+------------------------------------+\n",
      "     |  |5         |alt      |alternate alleles                   |\n",
      "     |  +----------+---------+------------------------------------+\n",
      "     |  |6         |qual     |quality                             |\n",
      "     |  +----------+---------+------------------------------------+\n",
      "     |  |7         |filter   |filter                              |\n",
      "     |  +----------+---------+------------------------------------+\n",
      "     |  |8         |info     |info                                |\n",
      "     |  +----------+---------+------------------------------------+\n",
      "     |  |9         |format   |format specifier.                   |\n",
      "     |  +----------+---------+------------------------------------+\n",
      "     |  \n",
      "     |  Access to genotypes is via index::\n",
      "     |  \n",
      "     |      contig = vcf.contig\n",
      "     |      first_sample_genotype = vcf[0]\n",
      "     |      second_sample_genotype = vcf[1]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      asVCF\n",
      "     |      Parser\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      asVCF.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      asVCF.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Parser:\n",
      "     |  \n",
      "     |  __call__(self, /, *args, **kwargs)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_encoding(...)\n",
      "     |      Parser.get_encoding(self)\n",
      "     |  \n",
      "     |  set_encoding(...)\n",
      "     |      Parser.set_encoding(self, encoding)\n",
      "    \n",
      "    class tabix_file_iterator(builtins.object)\n",
      "     |  iterate over a compressed or uncompressed ``infile``.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __next__(...)\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |      tabix_file_iterator.__reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |      tabix_file_iterator.__setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  next(...)\n",
      "     |      tabix_file_iterator.next(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "    \n",
      "    class tabix_generic_iterator(builtins.object)\n",
      "     |  tabix_generic_iterator(infile, parser)\n",
      "     |  \n",
      "     |  iterate over ``infile``.\n",
      "     |  \n",
      "     |  Permits the use of file-like objects for example from the gzip module.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, infile, parser)\n",
      "     |      tabix_generic_iterator.__init__(self, infile, parser)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      tabix_generic_iterator.__iter__(self)\n",
      "     |  \n",
      "     |  __next__(self)\n",
      "     |      tabix_generic_iterator.__next__(self)\n",
      "     |  \n",
      "     |  next(self)\n",
      "     |      tabix_generic_iterator.next(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    array_to_qualitystring(...)\n",
      "        convert an array of quality values to a string.\n",
      "    \n",
      "    get_verbosity(...)\n",
      "        get_verbosity()\n",
      "        Return the value of htslib's hts_verbose global variable.\n",
      "    \n",
      "    qualities_to_qualitystring(...)\n",
      "        convert a list or array of quality scores to the string\n",
      "        representation used in the SAM format.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        offset : int\n",
      "            offset to be added to the quality scores to arrive at\n",
      "            the characters of the quality string (default=33).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        string\n",
      "             a quality string\n",
      "    \n",
      "    qualitystring_to_array(...)\n",
      "        convert a qualitystring to an array of quality values.\n",
      "    \n",
      "    set_verbosity(...)\n",
      "        set_verbosity(int verbosity)\n",
      "        Set htslib's hts_verbose global variable to the specified value.\n",
      "    \n",
      "    tabix_compress(...)\n",
      "        tabix_compress(filename_in, filename_out, force=False)\n",
      "        compress *filename_in* writing the output to *filename_out*.\n",
      "            \n",
      "            Raise an IOError if *filename_out* already exists, unless *force*\n",
      "            is set.\n",
      "    \n",
      "    tabix_index(...)\n",
      "        tabix_index(filename, force=False, seq_col=None, start_col=None, end_col=None, preset=None, meta_char='#', int line_skip=0, zerobased=False, int min_shift=-1, index=None, keep_original=False, csi=False)\n",
      "        index tab-separated *filename* using tabix.\n",
      "        \n",
      "            An existing index will not be overwritten unless *force* is set.\n",
      "        \n",
      "            The index will be built from coordinates in columns *seq_col*,\n",
      "            *start_col* and *end_col*.\n",
      "        \n",
      "            The contents of *filename* have to be sorted by contig and\n",
      "            position - the method does not check if the file is sorted.\n",
      "        \n",
      "            Column indices are 0-based. Note that this is different from the\n",
      "            tabix command line utility where column indices start at 1.\n",
      "            \n",
      "            Coordinates in the file are assumed to be 1-based unless\n",
      "            *zerobased* is set.\n",
      "        \n",
      "            If *preset* is provided, the column coordinates are taken from a\n",
      "            preset. Valid values for preset are \"gff\", \"bed\", \"sam\", \"vcf\",\n",
      "            psltbl\", \"pileup\".\n",
      "            \n",
      "            Lines beginning with *meta_char* and the first *line_skip* lines\n",
      "            will be skipped.\n",
      "        \n",
      "            If *filename* is not detected as a gzip file it will be automatically\n",
      "            compressed. The original file will be removed and only the compressed\n",
      "            file will be retained.\n",
      "        \n",
      "            *min-shift* sets the minimal interval size to 1<<INT; 0 for the\n",
      "            old tabix index. The default of -1 is changed inside htslib to \n",
      "            the old tabix default of 0.\n",
      "        \n",
      "            *index* controls the filename which should be used for creating the index.\n",
      "            If not set, the default is to append ``.tbi`` to *filename*.\n",
      "        \n",
      "            If *csi* is set, create a CSI index, the default is to create a\n",
      "            TBI index.\n",
      "        \n",
      "            When automatically compressing files, if *keep_original* is set the\n",
      "            uncompressed file will not be deleted.\n",
      "        \n",
      "            returns the filename of the compressed data\n",
      "    \n",
      "    tabix_iterator(...)\n",
      "        tabix_iterator(infile, parser)\n",
      "        return an iterator over all entries in a file.\n",
      "            \n",
      "            Results are returned parsed as specified by the *parser*. If\n",
      "            *parser* is None, the results are returned as an unparsed string.\n",
      "            Otherwise, *parser* is assumed to be a functor that will return\n",
      "            parsed data (see for example :class:`~pysam.asTuple` and\n",
      "            :class:`~pysam.asGTF`).\n",
      "\n",
      "DATA\n",
      "    CBACK = <CIGAR_OPS.CBACK: 9>\n",
      "    CDEL = <CIGAR_OPS.CDEL: 2>\n",
      "    CDIFF = <CIGAR_OPS.CDIFF: 8>\n",
      "    CEQUAL = <CIGAR_OPS.CEQUAL: 7>\n",
      "    CHARD_CLIP = <CIGAR_OPS.CHARD_CLIP: 5>\n",
      "    CINS = <CIGAR_OPS.CINS: 1>\n",
      "    CMATCH = <CIGAR_OPS.CMATCH: 0>\n",
      "    CPAD = <CIGAR_OPS.CPAD: 6>\n",
      "    CREF_SKIP = <CIGAR_OPS.CREF_SKIP: 3>\n",
      "    CSOFT_CLIP = <CIGAR_OPS.CSOFT_CLIP: 4>\n",
      "    FDUP = <SAM_FLAGS.FDUP: 1024>\n",
      "    FMREVERSE = <SAM_FLAGS.FMREVERSE: 32>\n",
      "    FMUNMAP = <SAM_FLAGS.FMUNMAP: 8>\n",
      "    FPAIRED = <SAM_FLAGS.FPAIRED: 1>\n",
      "    FPROPER_PAIR = <SAM_FLAGS.FPROPER_PAIR: 2>\n",
      "    FQCFAIL = <SAM_FLAGS.FQCFAIL: 512>\n",
      "    FREAD1 = <SAM_FLAGS.FREAD1: 64>\n",
      "    FREAD2 = <SAM_FLAGS.FREAD2: 128>\n",
      "    FREVERSE = <SAM_FLAGS.FREVERSE: 16>\n",
      "    FSECONDARY = <SAM_FLAGS.FSECONDARY: 256>\n",
      "    FSUPPLEMENTARY = <SAM_FLAGS.FSUPPLEMENTARY: 2048>\n",
      "    FUNMAP = <SAM_FLAGS.FUNMAP: 4>\n",
      "    KEY_NAMES = ['name', 'flag', 'ref_name', 'ref_pos', 'map_quality', 'ci...\n",
      "    __all__ = ['get_verbosity', 'set_verbosity', 'HFile', 'HTSFile', 'qual...\n",
      "    __samtools_version__ = '1.9'\n",
      "    __warningregistry__ = {'version': 10}\n",
      "\n",
      "VERSION\n",
      "    0.15.2\n",
      "\n",
      "FILE\n",
      "    /d0/home/adamk/pysccnv/venv/lib/python3.7/site-packages/pysam/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pysam\n",
    "help(pysam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "polya_matcher = re.compile(\"^(T+)\")\n",
    "\n",
    "c = collections.Counter()\n",
    "\n",
    "with pysam.AlignmentFile(\"5k_pbmc_protein_v3_possorted_genome_bam.bam\", \"rb\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 10**7:\n",
    "            break\n",
    "        if line.cigartuples[0][0] != 4:\n",
    "            continue\n",
    "        if not polya_matcher.match(line.seq):\n",
    "            continue\n",
    "        tags = {i:j for i, j in line.get_tags()}\n",
    "        try:\n",
    "            c[tags[\"CB\"], tags[\"UB\"], tags[\"GN\"], line.reference_start] += 1\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('TAGTGCATCTTCGCTG-1', 'TCCATGTCATAA', 'AL627309.1', 89403): 1,\n",
       "         ('GCAGTTAAGCACACCC-1', 'GTAAGAGTACCC', 'AL627309.1', 89518): 1,\n",
       "         ('ACCAACACAGCGAACA-1', 'CCAGGCAATCGG', 'AL627309.1', 89543): 2,\n",
       "         ('GTATTTCGTCGAAGCA-1', 'ACCCACTGGGTC', 'AL627309.1', 89543): 1,\n",
       "         ('TAATCTCAGTTGTAAG-1',\n",
       "          'CTCTCCTGTGGA',\n",
       "          'AL627309.1;AL627309.3',\n",
       "          89763): 1,\n",
       "         ('TGTAACGAGTAGCCAG-1', 'GAATAAGAGATG', 'AL669831.5', 787356): 1,\n",
       "         ('GCACTAAAGATGCTGG-1', 'ATGCACCATTTT', 'AL669831.5', 809851): 1,\n",
       "         ('AGTGTTGGTTCAGCTA-1', 'ATTTTTATGTAG', 'LINC00115', 826205): 1,\n",
       "         ('CGTAAGTAGTGGAAGA-1', 'CATGAATTTAGG', 'LINC00115', 826205): 1,\n",
       "         ('GATAGAACATGCCGGT-1', 'AAACGCCATCAT', 'LINC00115', 826205): 1,\n",
       "         ('CTGCAGGTCACCGCTT-1', 'GGCCGATGGGCC', 'LINC00115', 826372): 1,\n",
       "         ('AACCAACCACAGTATC-1', 'ACCCGCTCATGG', 'LINC00115', 826619): 1,\n",
       "         ('AACCAACCACAGTATC-1', 'ACCCGCTCATGG', 'LINC00115', 826627): 1,\n",
       "         ('GTTACAGTCCGGCTTT-1', 'CGTTAATATATA', 'NOC2L', 944206): 1,\n",
       "         ('AACAGGGGTCAACATC-1', 'TCCGGCCTGGTA', 'NOC2L', 944211): 1,\n",
       "         ('TCATGCCCACGGAAGT-1', 'AACTAGGATAGT', 'NOC2L', 944211): 1,\n",
       "         ('ATGGGTTAGCGGGTAT-1', 'AGTTTCCAAAGA', 'NOC2L', 944213): 1,\n",
       "         ('CCGTAGGCAATCCTTT-1', 'TCAAGCAGCGCT', 'NOC2L', 944213): 1,\n",
       "         ('TGCTCGTGTTCCATTT-1', 'GGCCAAGCCGGC', 'NOC2L', 944213): 1,\n",
       "         ('AAAGGATAGAGGCCAT-1', 'GAATGCTAATTA', 'NOC2L', 944214): 2,\n",
       "         ('CTGTAGACACACCTTC-1', 'TTTGATATCTTT', 'NOC2L', 944214): 1,\n",
       "         ('CGAGGAATCGAGTCCG-1', 'CATTTGTCCTAT', 'NOC2L', 944215): 3,\n",
       "         ('AAGTCGTCACTACCCT-1', 'TATTCTGCCTTA', 'NOC2L', 944216): 1,\n",
       "         ('CAGATACTCAGAGCGA-1', 'ATTGACTGTACA', 'NOC2L', 944265): 1,\n",
       "         ('AGATCGTCAGTCTCTC-1', 'GAAAACGTCAGC', 'NOC2L', 944307): 1,\n",
       "         ('AGGGTCCAGGCTCTCG-1', 'AGTGTTGTGGAT', 'NOC2L', 944307): 1,\n",
       "         ('AGGTAGGCAGCTCCTT-1', 'TATATTTCATGA', 'NOC2L', 944307): 1,\n",
       "         ('ATCGCCTTCCCTAGGG-1', 'TAATGGGCGCAA', 'NOC2L', 944307): 2,\n",
       "         ('ATCGTGAAGGGCTTCC-1', 'GCATCGAGTCTA', 'NOC2L', 944307): 1,\n",
       "         ('CCGGACAGTTAGGACG-1', 'ACGGACATTCCT', 'NOC2L', 944307): 2,\n",
       "         ('CTCAGAACAAATCCCA-1', 'GTAACGCCCCAC', 'NOC2L', 944307): 1,\n",
       "         ('CTTGATTAGTAGCCAG-1', 'ATCTATTAGTGA', 'NOC2L', 944307): 1,\n",
       "         ('GACCGTGCATGTCTAG-1', 'GCCTACATTGTT', 'NOC2L', 944307): 1,\n",
       "         ('GGGCGTTCAATCTAGC-1', 'CCTATTGCTGGT', 'NOC2L', 944307): 1,\n",
       "         ('TCAGCAATCTCTGCCA-1', 'TTTACATTAGAT', 'NOC2L', 944307): 1,\n",
       "         ('TTCGGTCCAGCGTGAA-1', 'GGTTTCCTCGGC', 'NOC2L', 944307): 1,\n",
       "         ('TTTACCAGTGAGTTGG-1', 'ACCTGATCGCTA', 'NOC2L', 944307): 1,\n",
       "         ('GCGAGAACAGCTTTGA-1', 'ATTAATTTGGGG', 'NOC2L', 944409): 1,\n",
       "         ('AAAGGATGTGATTAGA-1', 'AGGGTAATTCAA', 'NOC2L', 944415): 1,\n",
       "         ('AGTCAACGTACAGCGA-1', 'TTTCAAGTCACT', 'NOC2L', 944415): 1,\n",
       "         ('ATTTCTGCAGACAAAT-1', 'CGATTCCATGCT', 'NOC2L', 944415): 3,\n",
       "         ('CAAGACTAGTGCAGCA-1', 'AGTCGAATTTAA', 'NOC2L', 944415): 1,\n",
       "         ('CATCGCTTCGGCTTCT-1', 'AGTGAACACCGT', 'NOC2L', 944415): 1,\n",
       "         ('CGAGAAGGTTAGCTAC-1', 'CCGAATAATGGT', 'NOC2L', 944415): 1,\n",
       "         ('GAGAGGTCAAGTGATA-1', 'GCCGGTTATTCT', 'NOC2L', 944415): 1,\n",
       "         ('GGGCGTTCAATCTAGC-1', 'GGCATCTTCGTC', 'NOC2L', 944415): 1,\n",
       "         ('GTGACGCTCAACCTTT-1', 'ACAGCTGTGACT', 'NOC2L', 944415): 1,\n",
       "         ('GTGCAGCGTTTATGCG-1', 'AATTTACTTGCT', 'NOC2L', 944415): 1,\n",
       "         ('GTGTAACCACATTACG-1', 'TTTATTCAGGTG', 'NOC2L', 944415): 1,\n",
       "         ('CAACGATGTGCAATGG-1', 'AATGTCGATTCA', 'NOC2L', 958019): 1,\n",
       "         ('AACAACCCATGACTCA-1', 'CCGCCAGAGACA', 'NOC2L', 958260): 2,\n",
       "         ('AACAACCCATGACTCA-1', 'CCGCCAGAGACA', 'NOC2L', 958266): 1,\n",
       "         ('CGGGCATAGATGCTTC-1', 'CTTTCTGTTCAC', 'NOC2L', 958292): 1,\n",
       "         ('AGACAAATCTGAGCAT-1', 'GAGAAACCTTTT', 'NOC2L', 958347): 1,\n",
       "         ('AGAGCCCCAGCAGGAT-1', 'GTAGGAAAGGCC', 'NOC2L', 958384): 1,\n",
       "         ('CCAATTTGTAGTCTGT-1', 'CGAAATTCGCCC', 'KLHL17', 965341): 1,\n",
       "         ('CTCCCTCCAAGGAGTC-1', 'ACATACTAGCCA', 'AL645608.8', 995998): 1,\n",
       "         ('CAGATTGTCGACCCAG-1', 'TGGTTCCGCTTA', 'AL645608.8', 996380): 1,\n",
       "         ('CCGTTCAAGTGAATAC-1', 'CAGAAATAAATG', 'AL645608.8', 996460): 1,\n",
       "         ('CAACCAACATCGGAAG-1', 'ATCCGTCCCAGG', 'AL645608.8', 996508): 1,\n",
       "         ('CCGTTCAAGTGAATAC-1', 'CAGAAATAAATG', 'AL645608.8', 996526): 2,\n",
       "         ('CCGTTCAAGTGAATAC-1', 'CAGAAATAAATG', 'AL645608.8', 996592): 1,\n",
       "         ('AAAGTGAGTTTGTTGG-1', 'TAAGTCAAGTAT', 'HES4', 998961): 1,\n",
       "         ('AAGTGAAGTATCGTAC-1', 'CTTAACCCGCTT', 'HES4', 998961): 1,\n",
       "         ('AGTTCCCAGGTGCGAT-1', 'GTGAGGCTTTAT', 'HES4', 998961): 1,\n",
       "         ('CAACAACGTGGGTCAA-1', 'CTGACTAGGCCT', 'HES4', 998961): 1,\n",
       "         ('CCGGGTAAGGTTGGAC-1', 'GTGTTGTTACCA', 'HES4', 998961): 1,\n",
       "         ('TCAGTGAAGGACCCAA-1', 'CACAGCCTAAGT', 'HES4', 998961): 1,\n",
       "         ('TCGACGGCATGGCTGC-1', 'TGCGGCGGCAGA', 'HES4', 998961): 1,\n",
       "         ('TCTACCGAGCTACTGT-1', 'TACAGAGACCCG', 'HES4', 998961): 1,\n",
       "         ('TGAGTCACAAAGGATT-1', 'CTTGAATGTGCA', 'HES4', 998961): 3,\n",
       "         ('TGGGAAGCAGACTGCC-1', 'AGTGATACAGCC', 'HES4', 998961): 1,\n",
       "         ('TTCGATTAGCTAGAGC-1', 'CTCTCCGTTCAG', 'HES4', 998961): 1,\n",
       "         ('TTGATGGTCGCTGTCT-1', 'ACTTCCTGCCTG', 'HES4', 998961): 1,\n",
       "         ('AATTTCCAGGTTCCGC-1', 'CACCCTTGGTGC', 'HES4', 998963): 2,\n",
       "         ('ATGGGAGAGCCACTCG-1', 'TCATCGGAAGGG', 'HES4', 998963): 1,\n",
       "         ('CAACAACGTGGGTCAA-1', 'GTTTCAGCGCAA', 'HES4', 998963): 1,\n",
       "         ('GGTAACTAGTCCCAGC-1', 'GCTACCGCGAGG', 'HES4', 998963): 1,\n",
       "         ('TCAAGACGTATCGCAT-1', 'GCACCATGTTGG', 'HES4', 998963): 1,\n",
       "         ('ATCGTAGCAGTAGTGG-1', 'TACTTGAACTTG', 'HES4', 999239): 1,\n",
       "         ('GATTCGATCTGGACCG-1', 'CATCCATCATTG', 'HES4', 999268): 1,\n",
       "         ('CGCCATTGTGCAGTGA-1', 'CTATATGTGTGC', 'HES4', 999563): 1,\n",
       "         ('GACCCTTTCATTGTGG-1', 'TCCTTCAGTACT', 'ISG15', 1014148): 1,\n",
       "         ('GTGGGAATCACGACTA-1', 'CATTTTGTCCGA', 'ISG15', 1014164): 1,\n",
       "         ('GGGATGAGTTGTCCCT-1', 'TTAATTGGCTCC', 'ISG15', 1014171): 1,\n",
       "         ('CATAAGCCACCATTCC-1', 'TTAAACCGGCTG', 'ISG15', 1014193): 1,\n",
       "         ('AGGGCCTAGTTCCGTA-1', 'CTTGCAGCTGGG', 'ISG15', 1014240): 1,\n",
       "         ('TGTTCTACATTCACAG-1', 'ACGGTACTTACC', 'ISG15', 1014249): 1,\n",
       "         ('CGATGGCGTACTAACC-1', 'TTAATGCTTCCA', 'ISG15', 1014252): 1,\n",
       "         ('AGATGAAGTTCTCACC-1', 'TCTTTATCGGGG', 'ISG15', 1014255): 1,\n",
       "         ('CGTTCTGTCCGTTGAA-1', 'CTTGTTAGAACT', 'ISG15', 1014255): 1,\n",
       "         ('TCAAGACAGAGTAACT-1', 'TAACTCTCTATG', 'ISG15', 1014255): 2,\n",
       "         ('AACCAACGTAACATCC-1', 'GAAAATGGCCTT', 'ISG15', 1014274): 1,\n",
       "         ('AACCATGAGATCGGTG-1', 'CGACCCCTGGAT', 'ISG15', 1014274): 1,\n",
       "         ('ACACTGAGTGCCCGTA-1', 'ATCGCTATATAC', 'ISG15', 1014274): 1,\n",
       "         ('ACACTGAGTTCGTTCC-1', 'CTTGGCATGAGG', 'ISG15', 1014274): 1,\n",
       "         ('ACATGCACACTCTAGA-1', 'ATTATGATCTCC', 'ISG15', 1014274): 1,\n",
       "         ('ACCCTCACACTACCCT-1', 'TAGATACCAAGT', 'ISG15', 1014274): 1,\n",
       "         ('ACCCTTGGTCTGTCAA-1', 'TGGGCCCGGCCT', 'ISG15', 1014274): 1,\n",
       "         ('ACGTACAAGCGACATG-1', 'GTTACATAAAAT', 'ISG15', 1014274): 1,\n",
       "         ('ACGTAGTAGCCGGATA-1', 'CTCACCTATAGC', 'ISG15', 1014274): 1,\n",
       "         ('ACGTCCTGTCCTGGTG-1', 'GCAACGGTTTAT', 'ISG15', 1014274): 1,\n",
       "         ('ACTATGGAGGGCCAAT-1', 'ATGTCTCGCCTC', 'ISG15', 1014274): 1,\n",
       "         ('AGAAATGAGTTAGTAG-1', 'CGCCACTCGCAG', 'ISG15', 1014274): 1,\n",
       "         ('AGAACCTCAAGAGTAT-1', 'TTTCGGATTGCG', 'ISG15', 1014274): 2,\n",
       "         ('AGAAGTACAGTAGAAT-1', 'GTGCGTTATCTC', 'ISG15', 1014274): 1,\n",
       "         ('AGACCATCATTACTCT-1', 'TTCTATTCGCCA', 'ISG15', 1014274): 1,\n",
       "         ('AGAGCCCAGGTGCGAT-1', 'CTGTTGCTGTCA', 'ISG15', 1014274): 1,\n",
       "         ('AGATCCAGTGGTCCCA-1', 'TAGTCCAAATAT', 'ISG15', 1014274): 1,\n",
       "         ('AGCATCAAGTCTGGTT-1', 'GAATTCGAGTTT', 'ISG15', 1014274): 1,\n",
       "         ('AGCTACAGTTCTGAGT-1', 'TTATATGCCATC', 'ISG15', 1014274): 1,\n",
       "         ('ATCATTCGTAGCACAG-1', 'CCTCGGACATGA', 'ISG15', 1014274): 1,\n",
       "         ('CAGATTGTCGACCCAG-1', 'CTTCTATAGTTT', 'ISG15', 1014274): 1,\n",
       "         ('CAGCAATGTGATGGCA-1', 'ACGTTATCTTAA', 'ISG15', 1014274): 2,\n",
       "         ('CAGCAATGTGATGGCA-1', 'TAAACTCTTTTT', 'ISG15', 1014274): 1,\n",
       "         ('CATGCAAAGACAGCTG-1', 'TACGGTTACAAT', 'ISG15', 1014274): 1,\n",
       "         ('CCTATCGAGAAAGCGA-1', 'GTATTAGAATTA', 'ISG15', 1014274): 1,\n",
       "         ('CCTCAACAGACTCTTG-1', 'ATTTCTTTCTAC', 'ISG15', 1014274): 1,\n",
       "         ('CGAGGAATCGAGTCCG-1', 'TTCATGCCTTTT', 'ISG15', 1014274): 2,\n",
       "         ('CGAGTTAAGTGGCGAT-1', 'TAATCTAATTCG', 'ISG15', 1014274): 1,\n",
       "         ('CGATGGCGTACTAACC-1', 'TTAATGCTTCCA', 'ISG15', 1014274): 1,\n",
       "         ('CTCATTAAGCGATCGA-1', 'GCCTTCAGGCTA', 'ISG15', 1014274): 1,\n",
       "         ('CTGCATCTCGTGAGAG-1', 'GTTGCTGGGTAT', 'ISG15', 1014274): 1,\n",
       "         ('GAGCTGCTCTCGAACA-1', 'CTTCGTTAAACA', 'ISG15', 1014274): 1,\n",
       "         ('GCAGCCAAGACATATG-1', 'AACCATATTTGT', 'ISG15', 1014274): 1,\n",
       "         ('GCAGGCTTCCTACGAA-1', 'CACCATCTCTCC', 'ISG15', 1014274): 1,\n",
       "         ('GCAGGCTTCCTACGAA-1', 'TCCCCCTGGATC', 'ISG15', 1014274): 1,\n",
       "         ('GCTACAACACTAACGT-1', 'GCTCCTAAATTC', 'ISG15', 1014274): 1,\n",
       "         ('GGAGGTACAACACACT-1', 'TACCCCCACTTC', 'ISG15', 1014274): 1,\n",
       "         ('GGGTCACAGCACTAAA-1', 'CGTTCATCACAT', 'ISG15', 1014274): 1,\n",
       "         ('GTAATGCTCTGGGCGT-1', 'AATTATACAGCA', 'ISG15', 1014274): 1,\n",
       "         ('GTATTTCGTGACCGAA-1', 'GGAATTAGCATG', 'ISG15', 1014274): 1,\n",
       "         ('GTCATCCCAGCTTCCT-1', 'TATCTTCATTAT', 'ISG15', 1014274): 1,\n",
       "         ('GTGTTCCTCGTGACTA-1', 'TCTATTTCAGTA', 'ISG15', 1014274): 1,\n",
       "         ('TCATGCCGTCACTTAG-1', 'CTATTTACTGGG', 'ISG15', 1014274): 1,\n",
       "         ('TCGGGTGAGCGTCAGA-1', 'GGGTTCTGTTTC', 'ISG15', 1014274): 1,\n",
       "         ('TCTCTGGGTCGCTCGA-1', 'GGTACAGTTGCT', 'ISG15', 1014274): 1,\n",
       "         ('TGATCAGAGCGTTACT-1', 'CTGTGCCTGAAA', 'ISG15', 1014274): 2,\n",
       "         ('TTCACGCGTACGGCAA-1', 'CCAACCATACCC', 'ISG15', 1014274): 3,\n",
       "         ('TTCGGTCCAGCGTGAA-1', 'TGAAAGGTACGA', 'ISG15', 1014274): 2,\n",
       "         ('TTCGGTCCAGCGTGAA-1', 'TTCAGCTACCAA', 'ISG15', 1014274): 1,\n",
       "         ('TTGCGTCCACGACAGA-1', 'AAGCTTAGGAAA', 'ISG15', 1014274): 1,\n",
       "         ('TTGGGATCATCATTTC-1', 'TCCACACACTCA', 'ISG15', 1014274): 1,\n",
       "         ('TTGGTTTCAGACAAGC-1', 'CGTATATCTAAG', 'ISG15', 1014274): 1,\n",
       "         ('GCTACAACACTAACGT-1', 'TCTTAAGCCCTC', 'ISG15', 1014276): 1,\n",
       "         ('GGAAGTGGTCCGGTCA-1', 'ATTCATTGTTCT', 'ISG15', 1014276): 1,\n",
       "         ('ACGTAGTAGCCGGATA-1', 'CTCACCTATAGC', 'ISG15', 1014281): 1,\n",
       "         ('AAGGAATGTCGCAGTC-1', 'GATGGGGTATAT', 'ISG15', 1014285): 1,\n",
       "         ('ACTGTGATCGGTTCAA-1', 'ATATTTTACAGC', 'ISG15', 1014343): 1,\n",
       "         ('CGTGCTTAGATCCAAA-1', 'TATTTTATACTA', 'ISG15', 1014390): 1,\n",
       "         ('GGGATGACAGAATTCC-1', 'CGCTCCAACACT', 'ISG15', 1014419): 2,\n",
       "         ('GGCACGTGTCGTCGGT-1', 'TAATACTAGTTT', 'ISG15', 1014424): 1,\n",
       "         ('GATGACTGTCGCCACA-1', 'CTGCATTCGCGC', 'C1orf159', 1081822): 1,\n",
       "         ('GACGCTGCACCCGTAG-1', 'GTTCTCTAGTAT', 'C1orf159', 1081961): 1,\n",
       "         ('TAGGTTGTCCAATCTT-1', 'CCATCTACCATT', 'C1orf159', 1082027): 1,\n",
       "         ('AATGCCAAGATAGGGA-1', 'AATCAGTGACGC', 'TNFRSF18', 1203507): 1,\n",
       "         ('GCCTGTTAGTGCCAGA-1', 'TCGGCTACGCAT', 'TNFRSF18', 1203507): 1,\n",
       "         ('TTCTAACTCTTGGATG-1', 'CCAAGTTCACCA', 'TNFRSF18', 1203507): 1,\n",
       "         ('CAGATCAAGTCCTGTA-1', 'TTTTCCGGTAAA', 'TNFRSF18', 1203508): 1,\n",
       "         ('GGGTATTAGAAACCAT-1', 'TAAACGCACTGA', 'TNFRSF18', 1203678): 1,\n",
       "         ('TGAGGGAAGCCGATCC-1', 'TCTGCCAGAGCC', 'TNFRSF4', 1211325): 1,\n",
       "         ('AAGGTAACAAAGCACG-1', 'AGATCCATATAT', 'TNFRSF4', 1211339): 2,\n",
       "         ('AGTAGCTAGGTACAAT-1', 'GCTTTTTTTTTT', 'TNFRSF4', 1211339): 1,\n",
       "         ('ACAGGGACAGGGAGAG-1', 'GCTGGAAGATTG', 'TNFRSF4', 1211344): 1,\n",
       "         ('AGGATCTCAAGTGCAG-1', 'ACGATTTGAGCA', 'TNFRSF4', 1211344): 1,\n",
       "         ('CACAACACACAATTCG-1', 'TGTAGCTTGTCA', 'TNFRSF4', 1211344): 1,\n",
       "         ('CAGCGTGCATCGCTAA-1', 'GATCTTTGACAC', 'TNFRSF4', 1211344): 1,\n",
       "         ('CCTTTGGAGCAGAAAG-1', 'GTACGTCCCAGA', 'TNFRSF4', 1211344): 2,\n",
       "         ('GCTACAACATCCGGCA-1', 'AGCCATACCTAG', 'TNFRSF4', 1211344): 1,\n",
       "         ('GCTGAATTCCATGCAA-1', 'CGCTTCTCGCGA', 'TNFRSF4', 1211344): 1,\n",
       "         ('GGCAGTCCAGCTGTGC-1', 'AATTTCTATATT', 'TNFRSF4', 1211344): 1,\n",
       "         ('TCTATACGTTCAAGGG-1', 'AAAGTGAATATA', 'TNFRSF4', 1211344): 1,\n",
       "         ('TTGGGTATCATTGTGG-1', 'CTACGTCTGTCA', 'TNFRSF4', 1211344): 1,\n",
       "         ('ACTCTCGCAAGAATAC-1', 'GCTACTCGCCTA', 'TNFRSF4', 1211385): 1,\n",
       "         ('GTTACCCGTCTGTGCG-1', 'CGACTCACGACG', 'TNFRSF4', 1211444): 1,\n",
       "         ('TAAGCCAAGGGACAGG-1', 'AAGTTATCCAGG', 'TNFRSF4', 1211486): 1,\n",
       "         ('GTTGCTCGTCACCCTT-1', 'TGGACACCATCG', 'TNFRSF4', 1211518): 1,\n",
       "         ('TGCGGGTCATGGAGAC-1', 'TGTACACAAAAT', 'TNFRSF4', 1211580): 1,\n",
       "         ('ATCAGGTGTACACTCA-1', 'TTGCTTAATACA', 'SDF4', 1216907): 2,\n",
       "         ('ATCGGATGTGTTGAGG-1', 'TTCATTAAAACT', 'SDF4', 1216907): 1,\n",
       "         ('ATGAAAGGTGTGTACT-1', 'GCTGTTAATGCG', 'SDF4', 1216907): 1,\n",
       "         ('CCGTTCAAGTGAATAC-1', 'CGTTCGTTGCCT', 'SDF4', 1216907): 1,\n",
       "         ('CGAAGTTTCAAGCTTG-1', 'TGTCGCGACGCG', 'SDF4', 1216907): 1,\n",
       "         ('CTGTAGAAGCCATCCG-1', 'TCAACCTATTCA', 'SDF4', 1216907): 1,\n",
       "         ('GTACAACGTTAAACCC-1', 'AGCCTAGGCTAT', 'SDF4', 1216907): 1,\n",
       "         ('TACCTCGGTGAGGATC-1', 'GCATGTTTGTTT', 'SDF4', 1216907): 2,\n",
       "         ('TAGTGCATCTGACGCG-1', 'AAACGTGTTGCA', 'SDF4', 1216907): 1,\n",
       "         ('TCATCCGAGGCTCTAT-1', 'AACAATTTTCCC', 'SDF4', 1216907): 1,\n",
       "         ('TCATTCATCGGATACT-1', 'GAAAGTCCAAGG', 'SDF4', 1216907): 1,\n",
       "         ('AGAGAATAGAGCAAGA-1', 'CGCCGTTTTAGT', 'SDF4', 1216913): 1,\n",
       "         ('AGCGTATTCGCAAGAG-1', 'TCTCCTACATTC', 'SDF4', 1216913): 1,\n",
       "         ('CACTGTCGTCTAATCG-1', 'TCGCATTTCTGT', 'SDF4', 1216913): 1,\n",
       "         ('CCTCTAGTCAGGCGAA-1', 'ACATACTAGAAT', 'SDF4', 1216913): 1,\n",
       "         ('GGTGTCGAGGTTAGTA-1', 'GTATTCGAATTC', 'SDF4', 1216913): 1,\n",
       "         ('TTTCACATCGACGACC-1', 'CTCATATGATAA', 'SDF4', 1216913): 1,\n",
       "         ('GGGTTATCATGACAGG-1', 'CATCTTTATCGG', 'SDF4', 1216918): 1,\n",
       "         ('AAGATAGAGCTGCCTG-1', 'CATACTCACTCG', 'SDF4', 1216920): 1,\n",
       "         ('ACGTTCCAGTCAGCGA-1', 'TGTAATATATTC', 'SDF4', 1216928): 1,\n",
       "         ('AACCTGAAGTGCAGGT-1', 'TAGACTCAGAGG', 'SDF4', 1216930): 1,\n",
       "         ('CAACCTCGTCAACCAT-1', 'GCTCAACAATTT', 'SDF4', 1216930): 1,\n",
       "         ('CAGGCCAAGAGGCCAT-1', 'TTTCGTCTAATA', 'SDF4', 1216930): 1,\n",
       "         ('CAGTGCGCACCTGTCT-1', 'TGCCTGACGCAT', 'SDF4', 1216930): 1,\n",
       "         ('CCTCACAGTTGATGTC-1', 'AAACTACATACA', 'SDF4', 1216930): 3,\n",
       "         ('GAGGCAAAGGTCTGGA-1', 'GATGTTATATGT', 'SDF4', 1216930): 1,\n",
       "         ('GAGGGTAAGGGTAATT-1', 'AACGCCGAGCCA', 'SDF4', 1216930): 1,\n",
       "         ('GGATCTATCCAATCCC-1', 'GATTTCCCTGTC', 'SDF4', 1216930): 1,\n",
       "         ('GTTCGCTCAAAGGTTA-1', 'CCTAGACGGACT', 'SDF4', 1216930): 2,\n",
       "         ('GTTGTGAGTCTCTCCA-1', 'ACAGGCAGGCGT', 'SDF4', 1216930): 1,\n",
       "         ('TCTCCGAGTACCAGAG-1', 'AGCTCTAAGTTT', 'SDF4', 1216930): 1,\n",
       "         ('TGCAGTAAGTCAACAA-1', 'TCTAACATCCGA', 'SDF4', 1216930): 2,\n",
       "         ('TGTTGGAGTAGAATAC-1', 'CTCTTGGTGTGT', 'SDF4', 1216930): 1,\n",
       "         ('TTGAACGAGGGCCTCT-1', 'CCAACGCATGGG', 'SDF4', 1216930): 1,\n",
       "         ('AGGTCTAAGAGGGTCT-1', 'GGCCTACTGCCC', 'SDF4', 1216932): 1,\n",
       "         ('GAGTTGTCAGTCGCTG-1', 'GTCTGCCTTGAC', 'SDF4', 1216932): 1,\n",
       "         ('AACACACTCTATCACT-1', 'TTCCTATCGTAA', 'SDF4', 1216934): 2,\n",
       "         ('TAGCACACAGCGACCT-1', 'CTTTCAGGACTC', 'SDF4', 1216934): 1,\n",
       "         ('TTCGATTAGCCTATCA-1', 'ATGTATGCCAGC', 'SDF4', 1216934): 1,\n",
       "         ('TGGATCAGTAACATGA-1', 'ACGATCCCCTGG', 'SDF4', 1216966): 1,\n",
       "         ('ACCATTTGTTGCGTAT-1', 'TACAAATAGGGG', 'SDF4', 1217053): 1,\n",
       "         ('TGAGACTTCCATAAGC-1', 'ATATACACTTTC', 'SDF4', 1217070): 1,\n",
       "         ('TGGATGTCAACATCGT-1', 'ATCTCTCGCGAA', 'SDF4', 1217070): 1,\n",
       "         ('GAAGTAACACTTTATC-1', 'TCGTTTGTATGA', 'SDF4', 1217082): 1,\n",
       "         ('TCTATCATCATGTCTT-1', 'AACGTAGTTGTT', 'SDF4', 1217082): 1,\n",
       "         ('TACCGGGAGGGTTAAT-1', 'TCTCCGGACGTG', 'SDF4', 1217091): 1,\n",
       "         ('CTACTATCAGCGGTTC-1', 'TTGTGACGCAAA', 'SDF4', 1217093): 1,\n",
       "         ('GAATCACCAACCTAAC-1', 'CGAGGACCTACA', 'SDF4', 1217095): 1,\n",
       "         ('GTCACTCCAATGGCCC-1', 'TCATACATGTTG', 'SDF4', 1217095): 1,\n",
       "         ('TGCTCGTCATCGGAGA-1', 'TCGAGTCCGCTA', 'SDF4', 1217095): 1,\n",
       "         ('GGTGAAGCAGGTATGG-1', 'TAAATTTAGTAT', 'SDF4', 1217096): 1,\n",
       "         ('CTGTAGATCTAGTGAC-1', 'AGTCCACTTTGG', 'SDF4', 1217106): 1,\n",
       "         ('CACAACAGTGCCTAAT-1', 'CCAAACGTTATA', 'SDF4', 1217112): 1,\n",
       "         ('TACTGCCAGTATAGAC-1', 'TTCAATGTCTTC', 'SDF4', 1217118): 1,\n",
       "         ('TCGTGCTTCCGTCACT-1', 'TTTGTGCCCCTC', 'SDF4', 1217119): 1,\n",
       "         ('TGACTCCTCCCATGGG-1', 'CAGCGTGAACAG', 'SDF4', 1217119): 1,\n",
       "         ('TGATCAGAGCGTTACT-1', 'ACATCACCCCTT', 'SDF4', 1217119): 1,\n",
       "         ('GGTTAACTCGCCAGAC-1', 'CTGCTTATATCT', 'SDF4', 1217128): 1,\n",
       "         ('GAGACCCGTAAGGTCG-1', 'ATGCATAAATAT', 'SDF4', 1217132): 1,\n",
       "         ('CGCCAGACAATCACGT-1', 'TTGGACACCTGG', 'SDF4', 1217161): 1,\n",
       "         ('TTGGGTAAGGCCCACT-1', 'TTGTTGTTCCAT', 'SDF4', 1217161): 1,\n",
       "         ('CCTCTCCAGAAATTCG-1', 'CATTTAAAATAG', 'SDF4', 1217239): 1,\n",
       "         ('ATCCATTTCTTGTTAC-1', 'CTAGTCCTCTGT', 'SDF4', 1217245): 1,\n",
       "         ('ACCCTCAGTCCATAGT-1', 'AACGGGACGTCG', 'SDF4', 1218492): 1,\n",
       "         ('CGTAAGTAGGAAGTCC-1', 'CAGCGCACTATG', 'SDF4', 1218492): 1,\n",
       "         ('CACGAATTCATCTGTT-1', 'ATCCGTTCATCC', 'SDF4', 1218768): 1,\n",
       "         ('CTGATCCCAGACTCTA-1', 'CCTGGACATCGC', 'SDF4', 1218768): 2,\n",
       "         ('GAACTGTAGACTACGG-1', 'ACGGCATTAGAC', 'SDF4', 1218768): 1,\n",
       "         ('TCATCCGTCTAACGCA-1', 'GTCGAATCCATA', 'SDF4', 1218768): 1,\n",
       "         ('GAACACTCAATGGCAG-1', 'GGGTTATGTTTT', 'SDF4', 1223243): 1,\n",
       "         ('GGTTAACCATAGTCGT-1', 'CGCCACAGGCCT', 'SDF4', 1223243): 2,\n",
       "         ('TTGGTTTTCTTCCCGA-1', 'TATGATGTTGAT', 'SDF4', 1223243): 1,\n",
       "         ('ATTCCCGCAAGCACAG-1', 'CCCCTCACTTGA', 'SDF4', 1228580): 1,\n",
       "         ('TGTGGCGGTGGCACTC-1', 'GGTCACCCCTAT', 'SDF4', 1228795): 1,\n",
       "         ('TTAGGCACAGCGCTTG-1', 'CTTGCCAAAGCT', 'B3GALT6', 1233328): 1,\n",
       "         ('TATTGCTCACACGGTC-1', 'AACACAGCCGGT', 'B3GALT6', 1233538): 1,\n",
       "         ('CAGCCAGAGAACCGCA-1', 'TTCCTAATAATC', 'B3GALT6', 1233986): 1,\n",
       "         ('CCTGTTGCACAACGAG-1', 'GACCCGTAATAA', 'C1QTNF12', 1242452): 1,\n",
       "         ('GGAAGTGAGTTGAAGT-1', 'GGACACCCTGGG', 'C1QTNF12', 1242452): 1,\n",
       "         ('TTCGATTGTATGAGCG-1', 'GGTTTCTATTGC', 'C1QTNF12', 1242597): 1,\n",
       "         ('GATAGAATCTTCCCAG-1', 'TCGACCTTTTTG', 'UBE2J2', 1253908): 1,\n",
       "         ('AGCCAATCACCAGCCA-1', 'CTTCCTGTTAGT', 'UBE2J2', 1253911): 1,\n",
       "         ('AGGCATTAGTGCTACT-1', 'GCCTTCACGTTA', 'UBE2J2', 1253911): 1,\n",
       "         ('CAATACGAGCTCATAC-1', 'CATTCGGCATGC', 'UBE2J2', 1253911): 1,\n",
       "         ('CATGCTCGTGGTCTCG-1', 'ATAATTTATCAT', 'UBE2J2', 1253911): 1,\n",
       "         ('CCAATTTGTGGCCCAT-1', 'AACATTGCTTCG', 'UBE2J2', 1253911): 1,\n",
       "         ('GTTCTATAGAAGCTCG-1', 'CGGTTATCAGCT', 'UBE2J2', 1253911): 2,\n",
       "         ('CTCCGATTCATTCATC-1', 'CAAAATTTGAAT', 'UBE2J2', 1253913): 1,\n",
       "         ('GAGTGAGAGTGGTTGG-1', 'GGCCTCCACATA', 'UBE2J2', 1253915): 1,\n",
       "         ('ATACCTTAGTGCCTCG-1', 'TCGAACTTTAGT', 'UBE2J2', 1253916): 1,\n",
       "         ('TCTCTGGGTTCTCGCT-1', 'GTATCGCTCGTT', 'UBE2J2', 1253919): 1,\n",
       "         ('TCATGCCAGGGTCAAC-1', 'GCTCAAGTCGAT', 'UBE2J2', 1253939): 1,\n",
       "         ('GCGTGCACAGAACTCT-1', 'CTCACGGCACCC', 'UBE2J2', 1254073): 1,\n",
       "         ('TCATTACAGGGCAACT-1', 'ACACGTAATATT', 'UBE2J2', 1254086): 1,\n",
       "         ('AATCACGGTCCATACA-1', 'AACTGCGTTGTT', 'UBE2J2', 1254129): 1,\n",
       "         ('AGAAATGCATGACTTG-1', 'TGTGACGATTTC', 'UBE2J2', 1254897): 1,\n",
       "         ('AACGTCAAGTAATACG-1', 'CGACTTGGTTTG', 'UBE2J2', 1254900): 2,\n",
       "         ('AAGGTAAAGTCACTAC-1', 'AACCCACGGGCC', 'UBE2J2', 1254900): 1,\n",
       "         ('AAGTTCGAGCACTGGA-1', 'GGTTGTTACGCT', 'UBE2J2', 1254900): 2,\n",
       "         ('ACCAACACAGCGAACA-1', 'TCCGCGTGCCGA', 'UBE2J2', 1254900): 1,\n",
       "         ('ACTGCAAAGCGATCGA-1', 'ACTGTCTCCCGG', 'UBE2J2', 1254900): 1,\n",
       "         ('AGAACCTCAAGAGTAT-1', 'GGACTTTCAGAG', 'UBE2J2', 1254900): 1,\n",
       "         ('AGATGCTGTAACTAAG-1', 'CAATTTGTCTCA', 'UBE2J2', 1254900): 1,\n",
       "         ('AGTTCGACACACCTGG-1', 'CGGTTCCTCATG', 'UBE2J2', 1254900): 1,\n",
       "         ('ATACCTTTCACGAACT-1', 'TGCCCAGAAGGA', 'UBE2J2', 1254900): 1,\n",
       "         ('ATCCGTCCAGATTTCG-1', 'TTCTTCGGAATG', 'UBE2J2', 1254900): 1,\n",
       "         ('CATCCGTTCTTGGCTC-1', 'ATTTCTAAGTGA', 'UBE2J2', 1254900): 1,\n",
       "         ('CGGGACTCATTGGATC-1', 'TCACTTTTATTG', 'UBE2J2', 1254900): 1,\n",
       "         ('CTACCTGCAAACTAAG-1', 'TACCCCCCCTGA', 'UBE2J2', 1254900): 1,\n",
       "         ('GAGACCCGTTCAAACC-1', 'TGTCCTGGTCAC', 'UBE2J2', 1254900): 2,\n",
       "         ('GATCAGTTCTGGGCAC-1', 'ACATCTTCGAAC', 'UBE2J2', 1254900): 1,\n",
       "         ('GATGTTGCACATTGTG-1', 'CGAGGTATTTTA', 'UBE2J2', 1254900): 1,\n",
       "         ('GTTACCCTCCTACCAC-1', 'AGATTCTTAATG', 'UBE2J2', 1254900): 1,\n",
       "         ('GTTACGAGTGGGAGAG-1', 'GCGTATCCGAGG', 'UBE2J2', 1254900): 1,\n",
       "         ('TAGACTGGTTGGATCT-1', 'TAATGTGATTAT', 'UBE2J2', 1254900): 1,\n",
       "         ('TATGTTCAGGCTATCT-1', 'CTGTACACCGAT', 'UBE2J2', 1254900): 1,\n",
       "         ('TCAGTGACACGCGCAT-1', 'CCTCTTCCCGGC', 'UBE2J2', 1254900): 1,\n",
       "         ('TCCGAAAGTTACGCCG-1', 'CTTATCTACTCC', 'UBE2J2', 1254900): 1,\n",
       "         ('TCCGGGACACGCAAAG-1', 'GCTTACGACTTA', 'UBE2J2', 1254900): 2,\n",
       "         ('TCTTAGTAGAGGACTC-1', 'ATTTTGCATATT', 'UBE2J2', 1254900): 1,\n",
       "         ('TGACAGTCATCAGCTA-1', 'CGCACTATGTAA', 'UBE2J2', 1254900): 1,\n",
       "         ('TGCAGATTCGCGGACT-1', 'ATTGCCTATATA', 'UBE2J2', 1254900): 1,\n",
       "         ('ACGGTTAAGGTAGTCG-1', 'AAACCCGATATA', 'UBE2J2', 1254901): 1,\n",
       "         ('TACATTCTCGTACCTC-1', 'ACACCTCCCTCG', 'UBE2J2', 1254902): 1,\n",
       "         ('TTCACCGCAATAGTGA-1', 'AAGTCCGTTTAG', 'UBE2J2', 1254904): 1,\n",
       "         ('GCATTAGGTAGGGTAC-1', 'ATCCTGCTGCCA', 'UBE2J2', 1254950): 1,\n",
       "         ('GCCGATGTCCTCTCTT-1', 'TTCCGGCCATCT', 'UBE2J2', 1255030): 1,\n",
       "         ('GACCCTTGTCCTCAGG-1', 'CCCTCAAACGTT', 'UBE2J2', 1255038): 1,\n",
       "         ('GCATTAGGTGTAGCAG-1', 'GGATGATCAGTT', 'UBE2J2', 1255075): 1,\n",
       "         ('AAGCCATCAGTCACGC-1', 'CCGTTTGAGTCT', 'UBE2J2', 1255173): 1,\n",
       "         ('CATTCATGTTTGGAAA-1', 'TCCTTGATTCGT', 'UBE2J2', 1255173): 1,\n",
       "         ('AACACACGTACGTGTT-1', 'CTCCACTTGGCA', 'ACAP3', 1292375): 1,\n",
       "         ('GCACATAAGCGGCTCT-1', 'CTTGTTACTTGG', 'ACAP3', 1292385): 1,\n",
       "         ('TCCGATCCATCCTATT-1', 'CTCCGCTTCCCA', 'ACAP3', 1292387): 1,\n",
       "         ('ATATCCTGTACGTGTT-1', 'TAAAACTGGGCG', 'ACAP3', 1292390): 1,\n",
       "         ('ATCGGATAGAGCTTTC-1', 'GGGTAATCCCGA', 'ACAP3', 1292390): 1,\n",
       "         ('GCATGATTCCCTTTGG-1', 'CGGTCCCTTGGG', 'ACAP3', 1292400): 1,\n",
       "         ('GTGTTAGCACACTTAG-1', 'GTAGACTAATTA', 'ACAP3', 1292636): 1,\n",
       "         ('ACCTACCAGCCGCTTG-1', 'AGAGGTTAACGG', 'ACAP3', 1292869): 1,\n",
       "         ('AGAAGCGGTCTAGGTT-1', 'GTTTATTGCTTC', 'ACAP3', 1292869): 1,\n",
       "         ('AGGTTGTAGCGTGTCC-1', 'CAAATCGGGGGT', 'ACAP3', 1292869): 1,\n",
       "         ('GTGTCCTAGGTTATAG-1', 'GATATGTCATTT', 'ACAP3', 1292869): 1,\n",
       "         ('GTTACCCTCCTACCAC-1', 'TTCCTTTGCCTT', 'ACAP3', 1292869): 1,\n",
       "         ('TCAGCCTCAGTTTCGA-1', 'CGGCAGCGCATT', 'ACAP3', 1292869): 2,\n",
       "         ('TCTCAGCAGCACCTGC-1', 'GCAGCATAAGAC', 'ACAP3', 1292869): 1,\n",
       "         ('TCCATCGGTAGCACAG-1', 'AGCTTGGTTGGG', 'ACAP3', 1292870): 2,\n",
       "         ('AATAGAGCAAGACGAC-1', 'AACTTACAAACT', 'ACAP3', 1292872): 1,\n",
       "         ('GCCTGTTTCAACACGT-1', 'TCGCTTAATGAA', 'ACAP3', 1301469): 1,\n",
       "         ('CATGGTACATTGACAC-1', 'CAACTTTGTCAG', 'ACAP3', 1301512): 1,\n",
       "         ('CATGAGTGTAAGCAAT-1', 'GGGGCTCTGATG', 'ACAP3', 1301588): 1,\n",
       "         ('AATCGACGTAGTCGTT-1', 'TATTATAATCGT', 'PUSL1', 1311342): 1,\n",
       "         ('CTTCGGTCAATCGTCA-1', 'GACCAATCTTTA', 'PUSL1', 1311361): 1,\n",
       "         ('GTCAAGTAGCCTAGGA-1', 'GAATGAGTTCTA', 'PUSL1', 1311404): 1,\n",
       "         ('TCATCATCAACCACGC-1', 'TTTGAGCTCCAG', 'INTS11', 1311584): 1,\n",
       "         ('AACGGGAAGGGTGGGA-1', 'ACCTTCGTTTGT', 'INTS11', 1311596): 1,\n",
       "         ('ACAGGGATCCTGGTCT-1', 'AAACTTAGTTAT', 'INTS11', 1311596): 1,\n",
       "         ('ATGAGTCAGAAGATCT-1', 'GTACCTATTAAA', 'INTS11', 1311596): 1,\n",
       "         ('CCACACTTCGTGGCGT-1', 'ATATCTCATCTT', 'INTS11', 1311596): 1,\n",
       "         ('GTCAAGTTCTTGATTC-1', 'ACTTCATAAGGC', 'INTS11', 1311596): 1,\n",
       "         ('GTTACGAGTAGGTTTC-1', 'ACGATCCTCGTT', 'INTS11', 1311596): 1,\n",
       "         ('TAATCTCCACACACTA-1', 'TACAGTTTAACC', 'INTS11', 1311596): 1,\n",
       "         ('TAATCTCTCCTGGGAC-1', 'GATCTAGCATCT', 'INTS11', 1311596): 1,\n",
       "         ('TCCTCCCTCTGCCTCA-1', 'TCTACTTTTTAT', 'INTS11', 1311596): 5,\n",
       "         ('TCTCTGGGTCAGGCAA-1', 'CTTGCTCTTAAC', 'INTS11', 1311598): 1,\n",
       "         ('AAGTTCGCACCATATG-1', 'TCTTCCGGAATT', 'INTS11', 1311599): 1,\n",
       "         ('ATCATTCAGCAAGTCG-1', 'TTGTCAGGTAGA', 'INTS11', 1311599): 1,\n",
       "         ('CAATCGACAACTACGT-1', 'CTCTGGTATAAT', 'INTS11', 1311599): 1,\n",
       "         ('CACAACATCGGACAAG-1', 'CCAACACCTCCT', 'INTS11', 1311599): 1,\n",
       "         ('CACTGAATCCTCGATC-1', 'GGCGGCTTGGAG', 'INTS11', 1311599): 1,\n",
       "         ('CTGCCTAAGACCTTTG-1', 'CATCTGACTAGT', 'INTS11', 1311599): 1,\n",
       "         ('GACATCACACGGATCC-1', 'GCGAACCCTTTT', 'INTS11', 1311599): 1,\n",
       "         ('GTCGCGAAGCACTCTA-1', 'TAATATTTTACG', 'INTS11', 1311599): 1,\n",
       "         ('TATATCCAGCCGATCC-1', 'TAGAAAAACTGG', 'INTS11', 1311599): 1,\n",
       "         ('TGGATCATCATGCCCT-1', 'CCCTTAAGTTCT', 'INTS11', 1311599): 2,\n",
       "         ('AGATCGTTCTAACACG-1', 'CCATAGGTCTAT', 'INTS11', 1311601): 1,\n",
       "         ('AGATGAATCCGTGGGT-1', 'TCGTACGCAACG', 'INTS11', 1311601): 1,\n",
       "         ('AGCTCAAGTGACCGAA-1', 'GCAGTCTAGTTA', 'INTS11', 1311601): 1,\n",
       "         ('CAGCCAGCATGGTACT-1', 'TTTAGCGCGTTA', 'INTS11', 1311601): 1,\n",
       "         ('CTTACCGTCTGCTTAT-1', 'CCGCCGGCTAAT', 'INTS11', 1311601): 1,\n",
       "         ('GAATCGTAGGTACAAT-1', 'AGGTGAGAAGAA', 'INTS11', 1311601): 1,\n",
       "         ('GTGCACGAGTAATCCC-1', 'AGCTATATCTAC', 'INTS11', 1311601): 1,\n",
       "         ('TAATTCCGTAGGTACG-1', 'TGGTAACAGTGT', 'INTS11', 1311601): 1,\n",
       "         ('TATCTGTAGCTTCTAG-1', 'ACCCCCGGTGGC', 'INTS11', 1311601): 1,\n",
       "         ('GTTACCCCAAACCACT-1', 'CCTCACTTAGCA', 'INTS11', 1311656): 1,\n",
       "         ('GCACGGTCAGTGTGCC-1', 'AGTGTCTTGCGA', 'INTS11', 1311703): 1,\n",
       "         ('AGAAGTATCTGCTAGA-1', 'TCTTTATTAAGC', 'INTS11', 1311753): 1,\n",
       "         ('TATCCTACAGGAAGTC-1', 'GATACGTGATGT', 'INTS11', 1311754): 1,\n",
       "         ('AGGTCATAGGTAAAGG-1', 'TTCGCTTCTGCT', 'INTS11', 1311761): 1,\n",
       "         ('AATAGAGGTCACCGAC-1', 'TTCTCGCGTAGC', 'INTS11', 1311885): 1,\n",
       "         ('CCGTGAGCACTACTTT-1', 'TCTCCAGGACTT', 'INTS11', 1316820): 1,\n",
       "         ('AAAGTCCCAACCACAT-1', 'ATCCGGTTCTCG', 'DVL1', 1335277): 1,\n",
       "         ('AATCACGGTAGATGTA-1', 'TATTGCCCCTAT', 'DVL1', 1335277): 1,\n",
       "         ('ACTGTGACACAAATGA-1', 'CACATATCCTAC', 'DVL1', 1335277): 1,\n",
       "         ('GCACGTGTCTAAGCCA-1', 'CTTTGCTAAAAC', 'DVL1', 1335277): 1,\n",
       "         ('TCTCTGGGTCGCTCGA-1', 'GACCACCTCTAC', 'DVL1', 1335277): 1,\n",
       "         ('TGTCAGAGTTCTCCCA-1', 'TGTAATAATTGT', 'DVL1', 1335277): 2,\n",
       "         ('CTTGATTGTCGCGTCA-1', 'CATTAACCTAAC', 'DVL1', 1335279): 2,\n",
       "         ('GTTACGATCTCGCTTG-1', 'CATAAAATTTAG', 'DVL1', 1335279): 1,\n",
       "         ('AAGCGAGTCGTAACTG-1', 'GTATGGGGTATT', 'DVL1', 1335282): 3,\n",
       "         ('CATTGTTTCCCGTGTT-1', 'ATTTCCTTCAGC', 'DVL1', 1335282): 1,\n",
       "         ('CATCGGGGTGGGACAT-1', 'GAGAAGCTGGTG', 'DVL1', 1335340): 1,\n",
       "         ('AGGAAATCAAATAAGC-1', 'GCTCAGCTCACC', 'AURKAIP1', 1373729): 1,\n",
       "         ('GCCAGCAGTACCGGCT-1', 'AGTATTATGCTT', 'AURKAIP1', 1373729): 1,\n",
       "         ('TCCTCCCAGGGCAGAG-1', 'CACAGCAATTTT', 'AURKAIP1', 1373729): 1,\n",
       "         ('AAGTCGTAGTATAACG-1', 'ACACCCTGGCTA', 'AURKAIP1', 1373730): 1,\n",
       "         ('AGTGCCGGTCTAACGT-1', 'TATTGTATTCCC', 'AURKAIP1', 1373730): 1,\n",
       "         ('CTATAGGTCCGGTAAT-1', 'TCAGGACGATTT', 'AURKAIP1', 1373730): 1,\n",
       "         ('CTCTCGAAGTCTGGAG-1', 'AGCTCTCTTTTT', 'AURKAIP1', 1373730): 1,\n",
       "         ('TACGTCCGTCATAACC-1', 'TCTACTGGATTG', 'AURKAIP1', 1373730): 1,\n",
       "         ('TGATGGTCACAAGCTT-1', 'TATAATAGGTTA', 'AURKAIP1', 1373730): 1,\n",
       "         ('AGGATCTCAAGGTACG-1', 'ATTCCGTCAGGA', 'AURKAIP1', 1373732): 1,\n",
       "         ('GTACAACAGCCTGCCA-1', 'TAAAGTTAAGAT', 'AURKAIP1', 1373732): 1,\n",
       "         ('GTTACAGAGAAGCCAC-1', 'ATGATCTGATGT', 'AURKAIP1', 1373732): 3,\n",
       "         ('TTCTAGTTCGGCATAT-1', 'ATACACTCCCAC', 'AURKAIP1', 1373732): 1,\n",
       "         ('AAGAACAAGTCATGGG-1', 'CCTTTCAGTCAT', 'AURKAIP1', 1373733): 2,\n",
       "         ('GAACTGTGTGCCTTCT-1', 'CCGCCGGCCCTT', 'AURKAIP1', 1373733): 1,\n",
       "         ('TATTCCATCACCTTAT-1', 'AACTATTCGCGG', 'AURKAIP1', 1373733): 1,\n",
       "         ('AGTCAACTCCGAGCTG-1', 'GCTGCCGATTAC', 'AURKAIP1', 1373734): 1,\n",
       "         ('ATAGAGAAGAGCAACC-1', 'ATCATAGCGCAT', 'AURKAIP1', 1373734): 1,\n",
       "         ('CACAACAAGCCACCGT-1', 'ACTGCGTAATCG', 'AURKAIP1', 1373734): 1,\n",
       "         ('TTATTGCAGTTCGCAT-1', 'TCTGGGTGTTCT', 'AURKAIP1', 1373734): 2,\n",
       "         ('ACCAAACTCTAGTACG-1', 'TGAATCCCATCC', 'AURKAIP1', 1373735): 1,\n",
       "         ('AGATCGTCAATTGCCA-1', 'ATTCCGTGTTCA', 'AURKAIP1', 1373735): 1,\n",
       "         ('CACAACAGTCGCATGC-1', 'TCTAGCTCTCGG', 'AURKAIP1', 1373735): 1,\n",
       "         ('CACAACATCTAGAACC-1', 'TGCAATATTTTC', 'AURKAIP1', 1373735): 1,\n",
       "         ('CACACAAAGGGACACT-1', 'GACCGATTCGAC', 'AURKAIP1', 1373735): 1,\n",
       "         ('CAGATTGAGATTAGTG-1', 'AGTCCAACGTAT', 'AURKAIP1', 1373735): 2,\n",
       "         ('CAGCGTGCATCCCGTT-1', 'ATTTAAGATGCA', 'AURKAIP1', 1373735): 1,\n",
       "         ('CCACACTGTTACCCAA-1', 'ATCATTAGTTCA', 'AURKAIP1', 1373735): 1,\n",
       "         ('CCCAACTTCAAGTCTG-1', 'CACCCTGGGTTA', 'AURKAIP1', 1373735): 1,\n",
       "         ('CTATCCGGTGCAACAG-1', 'ACGGGTGATTTG', 'AURKAIP1', 1373735): 1,\n",
       "         ('CTCATTATCACCTGGG-1', 'TTAGTTGATTTG', 'AURKAIP1', 1373735): 1,\n",
       "         ('GAGGCCTAGAAGGCTC-1', 'TCATTCCCATCT', 'AURKAIP1', 1373735): 1,\n",
       "         ('GCTTTCGAGGTGGCTA-1', 'ATTGATGGAGGC', 'AURKAIP1', 1373735): 1,\n",
       "         ('GGAACCCCAGCACAGA-1', 'TTCGCTAACATC', 'AURKAIP1', 1373735): 1,\n",
       "         ('GGTAATCTCACTGCTC-1', 'AGGTCAGCACGT', 'AURKAIP1', 1373735): 1,\n",
       "         ('GTAAGTCTCAAGAGGC-1', 'TTTATCGTCACT', 'AURKAIP1', 1373735): 1,\n",
       "         ('GTGGCGTAGAAATTCG-1', 'AGACTCTGTTCA', 'AURKAIP1', 1373735): 1,\n",
       "         ('GTGGCGTGTTGGCCTG-1', 'TGCGCGCTAGAC', 'AURKAIP1', 1373735): 1,\n",
       "         ('GTGTAACAGCCGAACA-1', 'GGTAAGCTAGTC', 'AURKAIP1', 1373735): 1,\n",
       "         ('GTTGTAGCAATAGTAG-1', 'AAAATGGTATTC', 'AURKAIP1', 1373735): 1,\n",
       "         ('TACACCCAGGTCGCCT-1', 'CTATCACACCCA', 'AURKAIP1', 1373735): 2,\n",
       "         ('TCAGCAACAAGTACCT-1', 'ATTGCAAGATAT', 'AURKAIP1', 1373735): 1,\n",
       "         ('TCCCAGTCAGCAGTCC-1', 'TTTCGTTTAGGC', 'AURKAIP1', 1373735): 1,\n",
       "         ('TCGCTCATCATTTCCA-1', 'GGCTCTAAGATT', 'AURKAIP1', 1373735): 1,\n",
       "         ('TCTATCAGTCATCCCT-1', 'GCTTTCCTTCAG', 'AURKAIP1', 1373735): 1,\n",
       "         ('TCTCTGGCACGCTGCA-1', 'TCAGTCACGTTA', 'AURKAIP1', 1373735): 2,\n",
       "         ('TCTTAGTAGCCACCGT-1', 'ATTATGAGCAGG', 'AURKAIP1', 1373735): 1,\n",
       "         ('TGATGGTTCGTCAGAT-1', 'TGGTTAACGTCG', 'AURKAIP1', 1373735): 1,\n",
       "         ('TGCAGTAGTACTGCCG-1', 'ATGAAGACTGTC', 'AURKAIP1', 1373735): 1,\n",
       "         ('TGCCGAGCATACAGCT-1', 'CTCGATTTCCTA', 'AURKAIP1', 1373735): 2,\n",
       "         ('TGTTCTACATTCACAG-1', 'AGTGCCACTATA', 'AURKAIP1', 1373735): 3,\n",
       "         ('TTTCCTCGTTTGATCG-1', 'CGCTATGTTCAG', 'AURKAIP1', 1373735): 1,\n",
       "         ('GCATGATTCAAACGTC-1', 'TCTAATCTGTTG', 'AURKAIP1', 1373736): 1,\n",
       "         ('TCGAACAAGAATTGTG-1', 'GAAAGAAAGGCA', 'AURKAIP1', 1373737): 2,\n",
       "         ('TGATCAGAGCGTTACT-1', 'GTGTATCTGTAC', 'AURKAIP1', 1373737): 1,\n",
       "         ('CTGAGCGGTTAGGGAC-1', 'TTCCGCTGCACT', 'AURKAIP1', 1373739): 1,\n",
       "         ('CACTAAGAGACATACA-1', 'TAGTACCAGCCA', 'AURKAIP1', 1373754): 1,\n",
       "         ('GATTGGTTCGAAATCC-1', 'TTTTCTCTATTT', 'AURKAIP1', 1373754): 1,\n",
       "         ('CAATACGAGCTCATAC-1', 'CAACCGCAGACA', 'AURKAIP1', 1373785): 1,\n",
       "         ('CCGTTCAAGTGAATAC-1', 'ACCAAGGCAGGT', 'AURKAIP1', 1373785): 1,\n",
       "         ('ATGGGAGCAAGGCCTC-1', 'ACATAATCCAAA', 'AURKAIP1', 1373803): 1,\n",
       "         ('GGAGAACGTGATGGCA-1', 'CTGTCCTCGTTA', 'AURKAIP1', 1373820): 1,\n",
       "         ('TCCCATGAGAATAGTC-1', 'TCCCTGTCTGAG', 'AURKAIP1', 1373822): 1,\n",
       "         ('TATTCCACAGACATCT-1', 'CCGCCAGACAAA', 'AURKAIP1', 1373841): 2,\n",
       "         ('CTACCCAAGCATGATA-1', 'TTGAAGGTGATA', 'AURKAIP1', 1373842): 1,\n",
       "         ('GAACACTCAATGGCAG-1', 'GAAGTAAGATTC', 'AURKAIP1', 1373858): 1,\n",
       "         ('GAGACTTTCCTGTTAT-1', 'CTGGTTACGTCG', 'AURKAIP1', 1373874): 1,\n",
       "         ('GTAGGTTAGAGCAACC-1', 'TCTTTACGTTCG', 'AURKAIP1', 1373874): 1,\n",
       "         ('ATTGTTCGTGGCTTAT-1', 'ACGAGGTTCTCT', 'AURKAIP1', 1373883): 1,\n",
       "         ('ACCGTTCTCAGACAAA-1', 'CCCACGGTTAAG', 'AURKAIP1', 1373895): 1,\n",
       "         ('GAGGGTAGTTGCCGCA-1', 'TTTTCATTTCGG', 'AURKAIP1', 1373895): 1,\n",
       "         ('GATCATGGTTCAACGT-1', 'AGATCCTTTTAC', 'AURKAIP1', 1373895): 1,\n",
       "         ('AAACCCAGTCGTGCCA-1', 'CTAGAGCCTAGT', 'AURKAIP1', 1373999): 1,\n",
       "         ('AAACCCATCGTGCATA-1', 'TTTATTTCATCG', 'AURKAIP1', 1373999): 1,\n",
       "         ('ACCATTTCACCAACAT-1', 'AGCCGTTTCTTG', 'AURKAIP1', 1373999): 1,\n",
       "         ('ACCCTCATCATTGAGC-1', 'ACCCACCTTAAG', 'AURKAIP1', 1373999): 1,\n",
       "         ('ACTTAGGGTACCATAC-1', 'TGACTACAAAGA', 'AURKAIP1', 1373999): 1,\n",
       "         ('AGAGAGCTCGGTCGGT-1', 'ATGCTTCTATAC', 'AURKAIP1', 1373999): 1,\n",
       "         ('AGCCAGCAGTGCTCAT-1', 'TACGTCTTTTCA', 'AURKAIP1', 1373999): 2,\n",
       "         ('ATCAGGTCATTGCCTC-1', 'TGAGGCCTGACC', 'AURKAIP1', 1373999): 1,\n",
       "         ('ATCCATTCAGGACTTT-1', 'TGTATCCCATTC', 'AURKAIP1', 1373999): 1,\n",
       "         ('ATCGTAGGTACCCGCA-1', 'CCTAATTCTGGT', 'AURKAIP1', 1373999): 1,\n",
       "         ('ATCTCTATCACGATAC-1', 'TAATAATAAGGT', 'AURKAIP1', 1373999): 3,\n",
       "         ('ATGTCTTCATCTTTCA-1', 'GGAATTTGTTTT', 'AURKAIP1', 1373999): 1,\n",
       "         ('ATTTCACCAAGTACCT-1', 'CAACATCCAGTT', 'AURKAIP1', 1373999): 1,\n",
       "         ('CAATGACGTTCGGTTA-1', 'CGGTTGTATTGG', 'AURKAIP1', 1373999): 1,\n",
       "         ('CACGTGGAGTATGTAG-1', 'TGCGCATAGAGC', 'AURKAIP1', 1373999): 1,\n",
       "         ('CACTGTCGTCTAATCG-1', 'TTAGGTCGTCAC', 'AURKAIP1', 1373999): 1,\n",
       "         ('CAGATACCAGCCGGTT-1', 'GAAGATGTTCCT', 'AURKAIP1', 1373999): 1,\n",
       "         ('CAGATTGAGATTAGTG-1', 'TACATTTGCGGG', 'AURKAIP1', 1373999): 1,\n",
       "         ('CAGCCAGAGAACCGCA-1', 'TCTCATAAGGAA', 'AURKAIP1', 1373999): 1,\n",
       "         ('CATTCCGTCGTTGTAG-1', 'TCGTTAAATAGG', 'AURKAIP1', 1373999): 1,\n",
       "         ('CCTTCAGCAGAGTTCT-1', 'ATCAACTTCGAT', 'AURKAIP1', 1373999): 1,\n",
       "         ('CGGACACTCGTAGCCG-1', 'GCCCTCCATTGT', 'AURKAIP1', 1373999): 1,\n",
       "         ('CGTGTCTCACTGGCCA-1', 'CCGTGTACACAC', 'AURKAIP1', 1373999): 1,\n",
       "         ('CTCGAGGCAACACACT-1', 'GGACTTAGGGCT', 'AURKAIP1', 1373999): 1,\n",
       "         ('CTTCCTTCAGAACGCA-1', 'AGTCGTCGAAGC', 'AURKAIP1', 1373999): 2,\n",
       "         ('GAAGGACTCGTAGTGT-1', 'TGATTGGCCCAC', 'AURKAIP1', 1373999): 1,\n",
       "         ('GACATCACACGGATCC-1', 'GCAATCTCTTTG', 'AURKAIP1', 1373999): 1,\n",
       "         ('GAGAGGTAGCGTATAA-1', 'TTTTCCTCGTTA', 'AURKAIP1', 1373999): 1,\n",
       "         ('GAGGGTAAGCAGGCAT-1', 'CGACATTGTGTG', 'AURKAIP1', 1373999): 1,\n",
       "         ('GAGGGTAAGCAGGCAT-1', 'TCTTCTCGAACG', 'AURKAIP1', 1373999): 1,\n",
       "         ('GATCACATCCGCTTAC-1', 'TACGCGAATCGA', 'AURKAIP1', 1373999): 2,\n",
       "         ('GATGATCCATTGCCGG-1', 'ACATTTTTATTT', 'AURKAIP1', 1373999): 1,\n",
       "         ('GCCCAGAGTCGCGTCA-1', 'CGGCTACCTCAT', 'AURKAIP1', 1373999): 1,\n",
       "         ('GGGTAGATCGTACCTC-1', 'TGAGCATTCTTT', 'AURKAIP1', 1373999): 1,\n",
       "         ('GTACAGTGTTCCCACT-1', 'CGTTTATGCGTG', 'AURKAIP1', 1373999): 1,\n",
       "         ('GTAGGTTTCACCTCAC-1', 'CGTGGGTTGCCA', 'AURKAIP1', 1373999): 1,\n",
       "         ('GTGTCCTAGGTTATAG-1', 'CGCAAAGACTTG', 'AURKAIP1', 1373999): 1,\n",
       "         ('GTGTGGCCACCGAATT-1', 'GCGCTCCAACTC', 'AURKAIP1', 1373999): 1,\n",
       "         ('GTGTGGCTCAACTGGT-1', 'TCCTTGTTACGT', 'AURKAIP1', 1373999): 1,\n",
       "         ('GTTCGCTGTTGCCGAC-1', 'GAGGTTCTATCT', 'AURKAIP1', 1373999): 1,\n",
       "         ('TAAGCGTGTGGACCAA-1', 'GCTGCTATAACA', 'AURKAIP1', 1373999): 1,\n",
       "         ('TAATCTCTCCGTATGA-1', 'TTTGGTTATAAT', 'AURKAIP1', 1373999): 1,\n",
       "         ('TATCTTGCACGACAGA-1', 'GCAAAAAGTCGC', 'AURKAIP1', 1373999): 2,\n",
       "         ('TCACTCGGTAGCTGAG-1', 'ATATGCTAGTTG', 'AURKAIP1', 1373999): 1,\n",
       "         ('TCCCATGTCATTGCCC-1', 'TGTACTATTAGT', 'AURKAIP1', 1373999): 1,\n",
       "         ('TCTACCGCACGATTCA-1', 'GATTATCAAGCC', 'AURKAIP1', 1373999): 1,\n",
       "         ('TCTTAGTAGCCACCGT-1', 'CTCAATCTCACA', 'AURKAIP1', 1373999): 1,\n",
       "         ('TCTTAGTGTTCCCAAA-1', 'TTTAAACCAAAT', 'AURKAIP1', 1373999): 1,\n",
       "         ('TGGATGTAGAGACAAG-1', 'GCACTCGGTGAC', 'AURKAIP1', 1373999): 1,\n",
       "         ('TGTGCGGCATAGAGGC-1', 'ATAGAATTAAGA', 'AURKAIP1', 1373999): 1,\n",
       "         ('TGTGTGACAGGATTCT-1', 'AGCGGGTTAGTC', 'AURKAIP1', 1373999): 1,\n",
       "         ('TGTTCTAGTACATACC-1', 'CCGTGACACTAA', 'AURKAIP1', 1373999): 1,\n",
       "         ('TTTAGTCGTATTTCGG-1', 'ATCGCTATGCAT', 'AURKAIP1', 1373999): 2,\n",
       "         ('TTTCCTCGTTGCGTAT-1', 'GTAAACTAAACG', 'AURKAIP1', 1373999): 1,\n",
       "         ('TTTGGAGCAGCGGTTC-1', 'TTTCACAGGTAG', 'AURKAIP1', 1373999): 1,\n",
       "         ('TGGTAGTAGAGATCGC-1', 'AAGTCGGGCCAT', 'AURKAIP1', 1374000): 1,\n",
       "         ('AGGCCACAGCGACTGA-1', 'ATATTATTAGTC', 'AURKAIP1', 1374001): 1,\n",
       "         ('ACTGATGTCGCAGAGA-1', 'CTATTGAATGTA', 'AURKAIP1', 1374005): 1,\n",
       "         ('TCCGATCAGACCATTC-1', 'TCATGATCATGT', 'AURKAIP1', 1374005): 1,\n",
       "         ('ACAGCCGAGAGTCTTC-1', 'CTATATCTTGCT', 'AURKAIP1', 1374012): 1,\n",
       "         ('GATCACAGTCAGGAGT-1', 'TAGGTTCTAAGA', 'AURKAIP1', 1374018): 1,\n",
       "         ('ACCATTTCACCAACAT-1', 'AGCCGTTTCTTG', 'AURKAIP1', 1374028): 1,\n",
       "         ('ACTTCGCAGGTGGTTG-1', 'TAAGTCGAGCAA', 'AURKAIP1', 1374028): 1,\n",
       "         ('CCGATCTAGGATATGT-1', 'GCCGTGGGGGTC', 'AURKAIP1', 1374028): 1,\n",
       "         ('CCGATGGAGGACAAGA-1', 'CCGGCGATTATC', 'AURKAIP1', 1374028): 1,\n",
       "         ('CTTCTCTAGCGCCGTT-1', 'CCATCTCCACCC', 'AURKAIP1', 1374028): 1,\n",
       "         ('GATCACAAGTATGAGT-1', 'GGATGTCGCGGA', 'AURKAIP1', 1374028): 1,\n",
       "         ('GCAGGCTGTTTGGCTA-1', 'GGAAAAGTCGCT', 'AURKAIP1', 1374028): 1,\n",
       "         ('GCCATTCTCATTACTC-1', 'TACAAGGAACTT', 'AURKAIP1', 1374028): 1,\n",
       "         ('GGATGTTTCCCAGCGA-1', 'CTTCGGATGTAC', 'AURKAIP1', 1374028): 1,\n",
       "         ('GTGGCGTAGAAATTCG-1', 'CGATCGGGCCTG', 'AURKAIP1', 1374028): 1,\n",
       "         ('TGTACAGCACCCTATC-1', 'CTATATTCTTAG', 'AURKAIP1', 1374029): 1,\n",
       "         ('TCGAACAAGAATTGTG-1', 'GAAAGAAAGGCA', 'AURKAIP1', 1374033): 1,\n",
       "         ('TGAGCATAGTCACTAC-1', 'TCTTTCTTTGCA', 'AURKAIP1', 1374034): 1,\n",
       "         ('AGATGAACATACAGGG-1', 'GGGCATTACCGC', 'AURKAIP1', 1374037): 2,\n",
       "         ('CACGTGGAGTATGTAG-1', 'GAATCTTGAGTT', 'AURKAIP1', 1374043): 1,\n",
       "         ('ACGTTCCAGGCTCACC-1', 'TAGAGTCAGTGA', 'AURKAIP1', 1374061): 1,\n",
       "         ('AAAGGATAGAGGCCAT-1', 'AGTAACTTACGG', 'AURKAIP1', 1374071): 1,\n",
       "         ('GTGCTGGTCAAAGGAT-1', 'CCCCAGTGCTTT', 'AURKAIP1', 1374085): 1,\n",
       "         ('CTGCTCAAGTTGCTGT-1', 'TCTTGTGTGGAT', 'AURKAIP1', 1374090): 1,\n",
       "         ('GAGTGAGTCCGTTTCG-1', 'AGCATATTATAA', 'AURKAIP1', 1374099): 1,\n",
       "         ('TGTGCGGCATAGAGGC-1', 'ATAGAATTAAGA', 'AURKAIP1', 1374102): 1,\n",
       "         ('ATCCATTAGGGCGAAG-1', 'GCTTTACAAGCC', 'AURKAIP1', 1374109): 1,\n",
       "         ('AGGGTGAGTTGTAGCT-1', 'CCAGCCCGTTAC', 'AURKAIP1', 1374110): 1,\n",
       "         ('GACGCTGCACCCGTAG-1', 'GCTGTATAGTTT', 'AURKAIP1', 1374133): 1,\n",
       "         ('TCTATCACAGAGACTG-1', 'GCAGCCTCCGGA', 'AURKAIP1', 1374135): 1,\n",
       "         ('GGCAGTCAGTGATCGG-1', 'GTGCGTTTTGTT', 'AURKAIP1', 1374142): 1,\n",
       "         ('CAATGACGTTCGGTTA-1', 'CTGACATTTCTG', 'CCNL2', 1385710): 1,\n",
       "         ('CGGAACCTCCGCACTT-1', 'CATTCGGGATAC', 'CCNL2', 1385710): 1,\n",
       "         ('TGCCGAGAGAGCACTG-1', 'CCCTGCTTCAGT', 'CCNL2', 1385710): 1,\n",
       "         ('TCACGCTGTACGATGG-1', 'CAGGAGATGACT', 'CCNL2', 1385875): 2,\n",
       "         ('ACTTATCCATATGCGT-1', 'GTAGAACCCTAA', 'CCNL2', 1385919): 1,\n",
       "         ('TTGCCTGTCCATTGGA-1', 'TACTTGCATTTC', 'CCNL2', 1385919): 1,\n",
       "         ('CGTGCTTTCGCTTGCT-1', 'TGATTCAGCGGA', 'CCNL2', 1386486): 1,\n",
       "         ('AGCCAATCAATCGATC-1', 'AAACTTGACCGT', 'CCNL2', 1386494): 1,\n",
       "         ('AGTCATGAGCATATGA-1', 'CCAGTGTTGAGG', 'CCNL2', 1386496): 1,\n",
       "         ('AACAACCGTGGACCAA-1', 'CTTATCTGGTGA', 'CCNL2', 1386501): 1,\n",
       "         ('AGGATAATCCGTAGTA-1', 'GCAAATTATCGA', 'CCNL2', 1386501): 1,\n",
       "         ('CAGTGCGCAAGAGATT-1', 'CCTCGCATGGGT', 'CCNL2', 1386501): 1,\n",
       "         ('CTGATCCCAGACTCTA-1', 'CCCTTTACCTCA', 'CCNL2', 1386501): 1,\n",
       "         ('GATGATCGTATACAGA-1', 'GTAGTATTTGAC', 'CCNL2', 1386501): 1,\n",
       "         ('GTTCATTCAGTTCACA-1', 'GGGATATTTCCA', 'CCNL2', 1386501): 1,\n",
       "         ('TCAGGGCTCGAACTCA-1', 'CCAATCCTGTTT', 'CCNL2', 1386501): 1,\n",
       "         ('TCGACCTCAGCTCGGT-1', 'AGTCTTATCTAA', 'CCNL2', 1386501): 1,\n",
       "         ('TGCATGACATAATCGC-1', 'TGTGCCTACAGG', 'CCNL2', 1386501): 1,\n",
       "         ('CTCTCAGAGATGTTGA-1', 'CTGGCCTGTTAC', 'CCNL2', 1386566): 1,\n",
       "         ('CCTATCGAGTCTCGTA-1', 'TGCCTTATGTGA', 'CCNL2', 1386613): 1,\n",
       "         ('ACGTACAAGCACTAAA-1', 'GACTATATTCGA', 'CCNL2', 1386667): 1,\n",
       "         ('CTCCACAAGTCTGCGC-1', 'ACCTCTTGTACA', 'CCNL2', 1386700): 1,\n",
       "         ('GGGAGATCAGGGACTA-1', 'GTACGCGACAGA', 'CCNL2', 1386700): 1,\n",
       "         ('TCTACCGAGCACACAG-1', 'AGCTAGTATGGG', 'CCNL2', 1386700): 1,\n",
       "         ('AAAGAACGTGATCGTT-1', 'TTGGCAAAGGTG', 'CCNL2', 1386704): 1,\n",
       "         ('ACACAGTAGTAGACAT-1', 'GCCTCCGGGGAC', 'CCNL2', 1386704): 1,\n",
       "         ('AGACAAACATATAGCC-1', 'CTAATTCATTTC', 'CCNL2', 1386704): 1,\n",
       "         ('ATTCGTTGTTTCTTAC-1', 'GTTGGTCCATAT', 'CCNL2', 1386704): 1,\n",
       "         ('GAACTGTTCTCTCGCA-1', 'TTTTTAACTGAA', 'CCNL2', 1386704): 1,\n",
       "         ('GGAATCTAGTGTAGTA-1', 'TTCTCCTTTAAT', 'CCNL2', 1386704): 1,\n",
       "         ('TAAGTCGCAAATCAGA-1', 'ATAACCTGTGTT', 'CCNL2', 1386704): 1,\n",
       "         ('TACCTGCTCTATGTGG-1', 'ATTATTGATGCT', 'CCNL2', 1386704): 1,\n",
       "         ('TCCATGCAGATAGCTA-1', 'CCCTATGGTCAT', 'CCNL2', 1386704): 1,\n",
       "         ('TCGGGCACACATTGTG-1', 'TGGAGCGCCAGA', 'CCNL2', 1386704): 1,\n",
       "         ('TGCAGGCAGGCGATAC-1', 'AAAGGTTACGGG', 'CCNL2', 1386704): 1,\n",
       "         ('TGGATCAAGTAGGATT-1', 'GCTCCCCCTCTT', 'CCNL2', 1386704): 1,\n",
       "         ('AAAGGATAGAGGCCAT-1', 'AATTTGATATCT', 'CCNL2', 1386710): 1,\n",
       "         ('ACCTGTCAGTGCTACT-1', 'CTCAGGTTTTCC', 'CCNL2', 1386710): 1,\n",
       "         ('AGACACTGTTGGCCTG-1', 'CGCTGAAGCTGA', 'CCNL2', 1386710): 1,\n",
       "         ('AGAGAGCGTATATGGA-1', 'TTGCCCCCGAGT', 'CCNL2', 1386710): 1,\n",
       "         ('AGCCAGCGTTCGGTAT-1', 'ACCCATTGTGCT', 'CCNL2', 1386710): 2,\n",
       "         ('ATGAGTCCAAATGCTC-1', 'TTCCGATGTACT', 'CCNL2', 1386710): 1,\n",
       "         ('CCAATTTGTGTCATCA-1', 'TACGTAAGCCTG', 'CCNL2', 1386710): 1,\n",
       "         ('GACCCTTGTCGTTTCC-1', 'GGTTATTTTCAT', 'CCNL2', 1386710): 1,\n",
       "         ('GCTACCTCACTTACAG-1', 'CTTTATACTGAC', 'CCNL2', 1386710): 1,\n",
       "         ('GGGTTTAGTCCGACGT-1', 'CGATTATACATG', 'CCNL2', 1386710): 1,\n",
       "         ('GTGTTCCCACCTGCAG-1', 'CTCCGTCAAGCT', 'CCNL2', 1386710): 1,\n",
       "         ('TATCTTGCAGAGGACT-1', 'ATGAAAATGTCG', 'CCNL2', 1386710): 1,\n",
       "         ('TTTACCATCACTAGCA-1', 'TATTATCACGAC', 'CCNL2', 1386710): 1,\n",
       "         ('CCCTGATTCCTTGAAG-1', 'GTGCATTAATAC', 'CCNL2', 1386728): 1,\n",
       "         ('CCCTTAGAGTGGCCTC-1', 'GCAATATATTTG', 'CCNL2', 1386745): 1,\n",
       "         ('ATTTCACGTCCATACA-1', 'TTGCCCTCTGGG', 'CCNL2', 1386752): 1,\n",
       "         ('ACCAAACCAAGGTCGA-1', 'TGTATATTTTTC', 'CCNL2', 1386818): 1,\n",
       "         ('GATGGAGAGGACAAGA-1', 'AGCCTGATACTT', 'CCNL2', 1386832): 1,\n",
       "         ('GGGTAGAAGCGTATGG-1', 'GTAATTGTCGCA', 'CCNL2', 1386833): 1,\n",
       "         ('TGCTTCGTCGCCTTTG-1', 'TTTTTAGACAAC', 'CCNL2', 1386878): 1,\n",
       "         ('TGCGATAAGCATGCAG-1', 'CTGTTTGTCTCT', 'CCNL2', 1386953): 1,\n",
       "         ('ATCGTCCAGAACCGCA-1', 'CTCTGACAATAA', 'CCNL2', 1387352): 1,\n",
       "         ('TTGGGATGTTCTTGCC-1', 'GGCTTTCATTCT', 'CCNL2', 1387449): 1,\n",
       "         ('TGCGATACAGGAATCG-1', 'ATGCGTCATATC', 'CCNL2', 1390330): 1,\n",
       "         ('TACCGAAAGCTTTGTG-1', 'GAACATATTGTG', 'CCNL2', 1390549): 1,\n",
       "         ('TCGCAGGCATACAGCT-1', 'CATCAATCTAAT', 'CCNL2', 1390765): 1,\n",
       "         ('CCCTAACCAGTGGCTC-1', 'TCGGTAATTGGG', 'CCNL2', 1390807): 1,\n",
       "         ('TGCGATACAGGAATCG-1', 'ATGCGTCATATC', 'CCNL2', 1390827): 1,\n",
       "         ('AGGTCATCACGTCTCT-1', 'CTAGAATTATGT', 'CCNL2', 1390845): 1,\n",
       "         ('CCCGAAGCAAATGGTA-1', 'TTCCGAAAGATC', 'CCNL2', 1390846): 1,\n",
       "         ('TCTTGCGAGACTCATC-1', 'GCCTCTGTCCCC', 'CCNL2', 1391042): 1,\n",
       "         ('ATTCCTACATGCGGTC-1', 'TGTGCTATCATT', 'CCNL2', 1391433): 1,\n",
       "         ('CCGGACACAAAGGCGT-1', 'CCGGTGCGGATT', 'CCNL2', 1391763): 1,\n",
       "         ('CTCCACACAGGTGTTT-1', 'CGTATAAGTTCG', 'CCNL2', 1391910): 1,\n",
       "         ('AAACGCTCATGCACTA-1', 'TAGTATTGCTTC', 'CCNL2', 1392286): 1,\n",
       "         ('ACTGTCCGTAGAATAC-1', 'AGCCCAAATGCG', 'CCNL2', 1392471): 1,\n",
       "         ('AAGACAAGTAGATTGA-1', 'CTGAATTGATGC', 'CCNL2', 1392677): 1,\n",
       "         ('AGTCATGTCCAATCTT-1', 'ATACAACCTTAT', 'CCNL2', 1392683): 1,\n",
       "         ('TCTATACCATAGAGGC-1', 'TTTGATGGCACT', 'CCNL2', 1395316): 1,\n",
       "         ('CATTGAGTCCTGTTAT-1', 'CACTCGCCTTTG', 'CCNL2', 1398314): 2,\n",
       "         ('GCTACCTGTAGGCAAC-1', 'ATTTTTTTTTGT', 'CCNL2', 1398336): 1,\n",
       "         ('TCATGAGCATTGCCTC-1', 'ATAGGTTCATAT', 'MRPL20', 1401907): 1,\n",
       "         ('AGTTCCCAGCACTCCG-1', 'AGCCACTGCTAC', 'MRPL20', 1401908): 1,\n",
       "         ('CAACGATGTTAAGACA-1', 'ATTCAAGCCTTT', 'MRPL20', 1401908): 1,\n",
       "         ('CACGGGTAGATGCTAA-1', 'CTATAGAAAACC', 'MRPL20', 1401908): 1,\n",
       "         ('CAGCACGGTGTCCAAT-1', 'ACATGCAGCAGT', 'MRPL20', 1401908): 1,\n",
       "         ('CATTGCCCACTTGAGT-1', 'CCCCGTTTGTCC', 'MRPL20', 1401908): 2,\n",
       "         ('CGGTCAGCACACCTAA-1', 'CTCCTTTGTATG', 'MRPL20', 1401908): 2,\n",
       "         ('CGTCCATTCAAGCCGC-1', 'ATGGCATTGCTA', 'MRPL20', 1401908): 1,\n",
       "         ('GAAGGGTCAAACTCTG-1', 'TGATAACTTATC', 'MRPL20', 1401908): 1,\n",
       "         ('GACACGCTCTCCTGAC-1', 'CTATGTTGACTG', 'MRPL20', 1401908): 1,\n",
       "         ('GAGCCTGCACCTCGTT-1', 'ATTTCAAAGAGC', 'MRPL20', 1401908): 1,\n",
       "         ('GAGGGTACAGAGGTTG-1', 'GAGCGGCTACTA', 'MRPL20', 1401908): 1,\n",
       "         ('GGAAGTGAGATGCTTC-1', 'CTTCTACGCTTA', 'MRPL20', 1401908): 1,\n",
       "         ('GGGTAGATCTTTACAC-1', 'ACATCTTACAGT', 'MRPL20', 1401908): 2,\n",
       "         ('GGTGTCGCATTCAGGT-1', 'GGACTCTAAAAG', 'MRPL20', 1401908): 1,\n",
       "         ('TAAGCCAAGGGACAGG-1', 'CATTCACCACAA', 'MRPL20', 1401908): 1,\n",
       "         ('TAAGTCGGTAGCGTAG-1', 'GGTAAATGTTTC', 'MRPL20', 1401908): 1,\n",
       "         ('TACATTCCAAATCAGA-1', 'TTAATCCCGCAG', 'MRPL20', 1401908): 1,\n",
       "         ('TAGACTGAGTTGGACG-1', 'TAAATGATCCCG', 'MRPL20', 1401908): 1,\n",
       "         ('TAGGGTTCAACGTTAC-1', 'TGATGCGCACAA', 'MRPL20', 1401908): 1,\n",
       "         ('TCAGCCTCAGTTTCGA-1', 'CTGTCGCGTACG', 'MRPL20', 1401908): 2,\n",
       "         ('TCGTCCACACGGCGTT-1', 'ATGACTCTGAAT', 'MRPL20', 1401908): 1,\n",
       "         ('TCTGGCTTCTCGTGAA-1', 'TCAAGATAATCA', 'MRPL20', 1401908): 1,\n",
       "         ('TGATTTCGTGACAACG-1', 'TATGACGTAGCT', 'MRPL20', 1401908): 1,\n",
       "         ('TGTGGCGCAAAGCAAT-1', 'CTTTAATACTAC', 'MRPL20', 1401908): 1,\n",
       "         ('GATGACTCAATCGAAA-1', 'TCGGACGAGGAC', 'MRPL20', 1401910): 1,\n",
       "         ('GTCCTCATCCATCTCG-1', 'ACACCGTTAGTG', 'MRPL20', 1401910): 1,\n",
       "         ('TTCATTGTCGACATCA-1', 'ATAAGACTATCG', 'MRPL20', 1401910): 1,\n",
       "         ('AACCATGAGATCGGTG-1', 'CGCACTTGTTAG', 'MRPL20', 1401912): 2,\n",
       "         ('AATGGCTAGATCCAAA-1', 'GGTATGCCTGCA', 'MRPL20', 1401912): 1,\n",
       "         ('ACCTGAAAGGAGAGTA-1', 'AATTGCCTATTC', 'MRPL20', 1401912): 1,\n",
       "         ('ACTTTGTGTAACGATA-1', 'CTCAGACTCAAT', 'MRPL20', 1401912): 1,\n",
       "         ('AGGGAGTAGAACTCCT-1', 'TCCCGGTATAAC', 'MRPL20', 1401912): 1,\n",
       "         ('AGGGTGATCCCGAAAT-1', 'CATCCGGTGGTT', 'MRPL20', 1401912): 1,\n",
       "         ('ATCCACCCACCATATG-1', 'TCCTCATCAGAG', 'MRPL20', 1401912): 1,\n",
       "         ('ATCCCTGAGAGACAAG-1', 'ACGCCCTTTTTT', 'MRPL20', 1401912): 2,\n",
       "         ('ATTCCCGCAAGCACAG-1', 'GGCGTTCGCGTT', 'MRPL20', 1401912): 1,\n",
       "         ('CAAGACTAGTGCAGCA-1', 'AATTTGTCATGG', 'MRPL20', 1401912): 1,\n",
       "         ('CCCGAAGTCTACTGAG-1', 'GCCCCCAAGCGA', 'MRPL20', 1401912): 1,\n",
       "         ('CTCCTTTAGTACAACA-1', 'TACTAGCCCTGT', 'MRPL20', 1401912): 1,\n",
       "         ('GAACTGTAGACTACGG-1', 'GGTCGATGTGCA', 'MRPL20', 1401912): 1,\n",
       "         ('GCCTGTTTCAACACGT-1', 'AGAGGGCACAAG', 'MRPL20', 1401912): 1,\n",
       "         ('GCTGCAGAGAGAGGGC-1', 'TATGTATTGGAT', 'MRPL20', 1401912): 2,\n",
       "         ('GGTGATTGTTGCAAGG-1', 'TGGTGAGACCGG', 'MRPL20', 1401912): 1,\n",
       "         ('GTAGATCGTGAGATAT-1', 'AATTCCCTGCCT', 'MRPL20', 1401912): 1,\n",
       "         ('GTCGCGAGTTTAGTCG-1', 'TCTGGTAGAACG', 'MRPL20', 1401912): 1,\n",
       "         ('GTGAGGATCACTTCTA-1', 'GGGCGGGGCTGC', 'MRPL20', 1401912): 1,\n",
       "         ('TACTTACTCCGTGACG-1', 'TGGACTTGCAAT', 'MRPL20', 1401912): 1,\n",
       "         ('TCTTAGTAGATACAGT-1', 'TCGCATGCCAGA', 'MRPL20', 1401912): 1,\n",
       "         ('TGCTCGTTCGACATTG-1', 'TGTTGACAACAT', 'MRPL20', 1401912): 1,\n",
       "         ('TGTCAGAGTTCTCCCA-1', 'AATGACCCCGAG', 'MRPL20', 1401912): 1,\n",
       "         ('TTGGGTAAGCCAGACA-1', 'CATGAAAACGGT', 'MRPL20', 1401912): 1,\n",
       "         ('AGACACTAGCGCAATG-1', 'GTCCAATATTCC', 'MRPL20', 1401913): 1,\n",
       "         ('CAAGACTCATGACTCA-1', 'TATTTAGGATTG', 'MRPL20', 1401913): 1,\n",
       "         ('ATTCCATAGCATCAAA-1', 'TTCTACATCGGT', 'MRPL20', 1401914): 1,\n",
       "         ('GTTACCCCAAACCACT-1', 'GTAACAAGGTGT', 'MRPL20', 1401914): 1,\n",
       "         ('AAGTTCGTCAGTCAGT-1', 'TTCGTAGTATGG', 'MRPL20', 1401947): 1,\n",
       "         ('ATTCACTAGGCGTTGA-1', 'TTGCAATCCAAT', 'MRPL20', 1401947): 1,\n",
       "         ('TGCTCCAAGAGCAACC-1', 'CGTAATTCCTAA', 'MRPL20', 1401947): 1,\n",
       "         ('TTTGACTGTGACTAAA-1', 'TGAGAATAGGTT', 'MRPL20', 1401947): 1,\n",
       "         ('TTACTGTCACCAATTG-1', 'TTCTCCTGCATC', 'MRPL20', 1401950): 2,\n",
       "         ('ACAGAAACACGGTGTC-1', 'ATCACTAGTTTT', 'MRPL20', 1401954): 1,\n",
       "         ('ACCCAAATCGCCGAGT-1', 'CTTTTCCTTATA', 'MRPL20', 1401954): 1,\n",
       "         ('ACGATCAAGCGTATAA-1', 'TTATGGAAAAGG', 'MRPL20', 1401954): 1,\n",
       "         ('ACGTTCCAGGCTCACC-1', 'CCGCTATTCCTT', 'MRPL20', 1401954): 1,\n",
       "         ('AGCGCCATCGGCCTTT-1', 'AAGTACGTCGCT', 'MRPL20', 1401954): 1,\n",
       "         ('AGGTTGTGTTAGGCCC-1', 'CTTAACACCGGT', 'MRPL20', 1401954): 1,\n",
       "         ('ATCCACCCACCATATG-1', 'TCCTCATCAGAG', 'MRPL20', 1401954): 1,\n",
       "         ('CGAGAAGGTTAGCTAC-1', 'TCTTATTTGGCC', 'MRPL20', 1401954): 1,\n",
       "         ('CGGAACCTCCGCACTT-1', 'GTTGTGCAACTA', 'MRPL20', 1401954): 1,\n",
       "         ('GAAGGGTTCATCCTGC-1', 'GTCAACCGAGTG', 'MRPL20', 1401954): 1,\n",
       "         ('GCAGCCAAGACATATG-1', 'ATTACCCTTCTG', 'MRPL20', 1401954): 1,\n",
       "         ('GTAGGTTTCACCTCAC-1', 'CAACATTCTCGA', 'MRPL20', 1401954): 1,\n",
       "         ('GTAGGTTTCACCTCAC-1', 'GCAAGAGAGAGA', 'MRPL20', 1401954): 2,\n",
       "         ('TCACGCTTCTTTGATC-1', 'ATGCTCACGTAT', 'MRPL20', 1401954): 2,\n",
       "         ('TGCAGGCAGCCGATAG-1', 'GTTCACGAAGTC', 'MRPL20', 1401954): 1,\n",
       "         ('TTCACGCCACAAGTGG-1', 'TCACAATGGACT', 'MRPL20', 1401999): 1,\n",
       "         ('GGGCTCATCGCCTTGT-1', 'TATTGTTTCTGC', 'MRPL20', 1402017): 1,\n",
       "         ('GGTCTGGTCCGAAATC-1', 'CAGGCACATTAG', 'MRPL20', 1402020): 1,\n",
       "         ('TAATTCCGTTGTACGT-1', 'CATTACTATTGT', 'MRPL20', 1402023): 1,\n",
       "         ('TGTTGAGCACCAGTTA-1', 'TTTGTAAACTAC', 'MRPL20', 1402023): 1,\n",
       "         ('TCGTGCTAGATGACCG-1', 'CCATTCCCGTGG', 'MRPL20', 1402036): 1,\n",
       "         ('AAAGGGCTCAGTCACA-1', 'CATCGGGGGCGT', 'MRPL20', 1402037): 1,\n",
       "         ('AACCTGAAGTGCAGGT-1', 'GAGGGTCTAACA', 'MRPL20', 1402037): 1,\n",
       "         ('CAAGGGAAGCCAGACA-1', 'TTGATATCGTTA', 'MRPL20', 1402038): 1,\n",
       "         ('AGCTCAAGTGACCGAA-1', 'TTACTAAGCTCA', 'MRPL20', 1402039): 2,\n",
       "         ('TGGATCAGTACCTGTA-1', 'TCTTGTCAGTGG', 'MRPL20', 1402041): 1,\n",
       "         ('AATTTCCGTCTACGTA-1', 'AGACGCCCTGGT', 'MRPL20', 1402042): 1,\n",
       "         ('CCACTTGAGTAGCCAG-1', 'GGATACGCAACG', 'MRPL20', 1402042): 1,\n",
       "         ('CCGGACAGTCTAGATC-1', 'TAACATAAGAGG', 'MRPL20', 1402043): 1,\n",
       "         ('ACTCTCGCAAGAATAC-1', 'TTCCTCCAGTGG', 'MRPL20', 1402046): 1,\n",
       "         ('CGCCAGACAATCACGT-1', 'TAAAACACCGCC', 'MRPL20', 1402055): 1,\n",
       "         ('CGAGAAGGTTAGCTAC-1', 'CGTCTGCGGCGT', 'MRPL20', 1402056): 1,\n",
       "         ('GTTGCTCTCCGGCAAC-1', 'CCACATTGGTAT', 'MRPL20', 1402058): 1,\n",
       "         ('CGGAATTCACATAGCT-1', 'GATTGATAGGCT', 'MRPL20', 1402066): 1,\n",
       "         ('CTGGCAGAGGGAGGGT-1', 'GTAGGTCTATCT', 'MRPL20', 1402068): 1,\n",
       "         ('CACAACATCGACATCA-1', 'AATAATAGCTTT', 'MRPL20', 1402073): 1,\n",
       "         ('AGTCTCCGTATGAAAC-1', 'AGGTGGCCCGTT', 'MRPL20', 1402085): 1,\n",
       "         ('CAACCTCGTCTTCTAT-1', 'CATTCTAGCTTA', 'MRPL20', 1402091): 1,\n",
       "         ('CACTGAAGTACAAGCG-1', 'ATTTAGTATCTG', 'MRPL20', 1402091): 1,\n",
       "         ('CAGATCAAGACCTCAT-1', 'AAGTTCCCTACA', 'MRPL20', 1402091): 1,\n",
       "         ('GGGCCATAGTGCAAAT-1', 'CCTTTCGTGAGT', 'MRPL20', 1402091): 1,\n",
       "         ('TCTGTCGGTTTCGGCG-1', 'CAATAGAAATGG', 'MRPL20', 1402091): 1,\n",
       "         ('TAGCACATCCGTAGGC-1', 'ATGACATTCCTG', 'MRPL20', 1402096): 1,\n",
       "         ('GCTACAATCCACTGGG-1', 'ACCGAGACTGGT', 'MRPL20', 1402099): 1,\n",
       "         ('TCATTCAAGCTCTGTA-1', 'TGCAACTTTATG', 'MRPL20', 1402099): 1,\n",
       "         ('ACCCTCAAGCAAGCCA-1', 'TCTGTTTCGACT', 'MRPL20', 1402105): 1,\n",
       "         ('TGATTTCAGGGTAATT-1', 'TTTAAAGTATAG', 'MRPL20', 1402105): 1,\n",
       "         ('ACGTTCCAGTCAGCGA-1', 'ACTTAGCCCATC', 'MRPL20', 1402106): 1,\n",
       "         ('TGTCAGAGTTCTCCCA-1', 'TTTTGCAATAAC', 'MRPL20', 1402109): 1,\n",
       "         ('TTCCTTCCATACCAGT-1', 'CACTCCTGGTGC', 'MRPL20', 1402110): 1,\n",
       "         ('CATGCAAAGACAGCTG-1', 'CATAAATCAAGT', 'MRPL20', 1402111): 1,\n",
       "         ('TCTACCGAGCACACAG-1', 'TAAATTTTCCGT', 'MRPL20', 1402111): 1,\n",
       "         ('CGCCAGAAGAGAAGGT-1', 'ATCGCAGATGCC', 'MRPL20', 1402113): 1,\n",
       "         ('CACTGAAGTACAAGCG-1', 'ATTTAGTATCTG', 'MRPL20', 1402123): 1,\n",
       "         ('ACTCCCACACCCAACG-1', 'CCAGCAACTTTG', 'MRPL20', 1402127): 1,\n",
       "         ('CCACGTTAGTAGAGTT-1', 'TGTCCATCAGAT', 'MRPL20', 1402128): 1,\n",
       "         ('GGACGTCCAACGATCT-1', 'CTATTATTTTGC', 'MRPL20', 1402138): 1,\n",
       "         ('AAGAACACAACGGCCT-1', 'ATAACTTTGGTT', 'MRPL20', 1402151): 1,\n",
       "         ('AGTTAGCAGCTACGTT-1', 'GAAACATTGCCT', 'MRPL20', 1402156): 1,\n",
       "         ('TCTAACTTCCCTCGAT-1', 'CCGTTGTTGGCA', 'MRPL20', 1402174): 1,\n",
       "         ('TCTACCGAGCACACAG-1', 'TTGTATCGGTGT', 'MRPL20', 1402184): 1,\n",
       "         ('GGCAGTCCAGCTGTGC-1', 'TGCACCCTAGCT', 'MRPL20', 1402190): 1,\n",
       "         ('TGGTTAGCAGGTGACA-1', 'CATCGTAAACGA', 'MRPL20', 1402195): 1,\n",
       "         ('GTTGTGATCAACCTTT-1', 'CATACGTCGTTC', 'MRPL20', 1402196): 1,\n",
       "         ('GTGACGCAGTCACTGT-1', 'TAGCAGATTAGG', 'MRPL20', 1402231): 1,\n",
       "         ('AGATCGTTCTAACACG-1', 'TTCCTGCTTGAC', 'MRPL20', 1405576): 1,\n",
       "         ('TTAGTCTGTTTGCAGT-1', 'CCACCACTGGTC', 'MRPL20', 1405809): 1,\n",
       "         ('CATCCACTCGAGATGG-1', 'GTGCTTGCCCTT', 'MRPL20', 1405878): 2,\n",
       "         ('CCTCTCCTCTGCATAG-1', 'GAAGTGGGCATG', 'MRPL20', 1406436): 1,\n",
       "         ('GTGCTGGTCTTCTTCC-1', 'GGTCTCTTATTT', 'MRPL20', 1407130): 1,\n",
       "         ('CATTGCCCAGCTTCGG-1', 'GCATGTAATTGC', 'MRPL20', 1407241): 1,\n",
       "         ('GAAATGACAAGCACCC-1', 'ATAGAGTCTTTT', 'ANKRD65', 1418419): 1,\n",
       "         ('GTCGAATAGTAAACTG-1', 'ACACAGCCGCTA', 'ANKRD65', 1418777): 1,\n",
       "         ('CGGAACCTCCAACACA-1', 'GATATTATGGCA', 'ATAD3B', 1496004): 2,\n",
       "         ('GTATTTCGTCGAAGCA-1', 'ACTTGTTTTACT', 'ATAD3A', 1534476): 1,\n",
       "         ('ACTATGGCACAAACGG-1', 'ATATGTCTACCA', 'SSU72', 1541672): 1,\n",
       "         ('AGACCCGCAGAGATGC-1', 'GTTCCGCTGGGC', 'SSU72', 1541672): 1,\n",
       "         ('AGGATCTTCATGCCGG-1', 'AGATACCTCAGA', 'SSU72', 1541672): 1,\n",
       "         ('AGTCACATCCATACTT-1', 'ACATCAATCGTT', 'SSU72', 1541672): 2,\n",
       "         ('ATACTTCGTTCTATCT-1', 'TTGCATCCCGTT', 'SSU72', 1541672): 1,\n",
       "         ('ATATCCTCAGTTCTAG-1', 'ATCATGCTGTTG', 'SSU72', 1541672): 1,\n",
       "         ('ATCCTATTCCCTGGTT-1', 'ACTTATTGATAT', 'SSU72', 1541672): 1,\n",
       "         ('ATCGCCTCACATAACC-1', 'AAAGACCGTCCT', 'SSU72', 1541672): 1,\n",
       "         ('ATGGAGGTCTTAGCTT-1', 'CTTCTACCGTTA', 'SSU72', 1541672): 1,\n",
       "         ('ATTATCCCACAAAGTA-1', 'ATTAAGTAACCG', 'SSU72', 1541672): 1,\n",
       "         ('ATTGGGTCAGAGGCTA-1', 'TCGGTTTATGTA', 'SSU72', 1541672): 1,\n",
       "         ('CAAGGGAGTAGTCACT-1', 'ATTCACGTTCGA', 'SSU72', 1541672): 2,\n",
       "         ('CACCAAAGTCAGTCTA-1', 'CAAGTTGTCTCT', 'SSU72', 1541672): 1,\n",
       "         ('CAGATCAAGACCTCAT-1', 'TGCCTACTTCTG', 'SSU72', 1541672): 2,\n",
       "         ('CAGATCAAGTCCTGTA-1', 'AACCACACCTTT', 'SSU72', 1541672): 3,\n",
       "         ('CAGTTAGCACGCCAGT-1', 'TTTCTCCACGTG', 'SSU72', 1541672): 1,\n",
       "         ('CATCAAGTCAAGAAAC-1', 'TTCAATTTTTTT', 'SSU72', 1541672): 1,\n",
       "         ('CATTCCGGTTTCACAG-1', 'CAGATAAATTTA', 'SSU72', 1541672): 1,\n",
       "         ('CCGGGTAAGGTTGGAC-1', 'ACTTTCATCTCG', 'SSU72', 1541672): 1,\n",
       "         ('CCTCATGGTACGGATG-1', 'ACGCTGCGAACT', 'SSU72', 1541672): 1,\n",
       "         ('CCTTCAGCAGAAGCTG-1', 'GTCTGCCTCGTT', 'SSU72', 1541672): 1,\n",
       "         ('CGACAGCAGTAAACAC-1', 'CGGTTCGGATGC', 'SSU72', 1541672): 1,\n",
       "         ('CGAGAAGGTTAGCTAC-1', 'ATCTATCCATGT', 'SSU72', 1541672): 1,\n",
       "         ('CGATCGGTCCGTACGG-1', 'CCTAGGGTCCAC', 'SSU72', 1541672): 1,\n",
       "         ('CGGGTCAAGAGAGGTA-1', 'TATTATTTACGT', 'SSU72', 1541672): 1,\n",
       "         ('CTCAATTCACATACTG-1', 'CTACAAGGATCA', 'SSU72', 1541672): 1,\n",
       "         ('CTCATCGTCAACTACG-1', 'TAACACTTTTTT', 'SSU72', 1541672): 1,\n",
       "         ('CTGAGGCAGGTGCTAG-1', 'TGCCCTCTCGCA', 'SSU72', 1541672): 4,\n",
       "         ('GAAGCGACAATCGTCA-1', 'CCTTCACCATGC', 'SSU72', 1541672): 1,\n",
       "         ('GACTGATAGTAATACG-1', 'AATACCTCTTAT', 'SSU72', 1541672): 1,\n",
       "         ('GCAGTTAAGAGTTGTA-1', 'TTCCCGAGTTCA', 'SSU72', 1541672): 1,\n",
       "         ('GTATTTCTCCCGTGTT-1', 'GACATTGAGCAC', 'SSU72', 1541672): 1,\n",
       "         ('GTCACTCCAAACCGGA-1', 'CACGACAATCAT', 'SSU72', 1541672): 1,\n",
       "         ('GTCTCACCAGTCGCTG-1', 'TTTTGATCATTG', 'SSU72', 1541672): 1,\n",
       "         ('GTGAGTTGTCTTGTCC-1', 'TCTGGTCGCTAT', 'SSU72', 1541672): 1,\n",
       "         ('GTTACCCCAAAGTATG-1', 'ATTATAGCGAAA', 'SSU72', 1541672): 1,\n",
       "         ('TACCGAACACAGAAGC-1', 'TCTCCATCCTTG', 'SSU72', 1541672): 1,\n",
       "         ('TATTGGGCAACCGACC-1', 'GCGGAGATTTTG', 'SSU72', 1541672): 1,\n",
       "         ('TCCTCCCCATTGCCTC-1', 'CTTTCACTCGGC', 'SSU72', 1541672): 1,\n",
       "         ('TCCTCCCTCTTGGTCC-1', 'TATATTTTTTAC', 'SSU72', 1541672): 1,\n",
       "         ('TCCTCTTTCTGAGAAA-1', 'CCACCGGGATTA', 'SSU72', 1541672): 1,\n",
       "         ('TCGACGGCATGGCTGC-1', 'GGTGAACTTTCC', 'SSU72', 1541672): 2,\n",
       "         ('TCGACGGGTAAGGCCA-1', 'AGATTAACTCTC', 'SSU72', 1541672): 1,\n",
       "         ('TCTCAGCGTACACGTT-1', 'CGATTGGTTAAA', 'SSU72', 1541672): 1,\n",
       "         ('TCTTAGTTCAGCACCG-1', 'ATCTCTCATCCG', 'SSU72', 1541672): 1,\n",
       "         ('TGAGCATCAAACTCGT-1', 'CTGCACACTGTG', 'SSU72', 1541672): 1,\n",
       "         ('TGATGGTAGCGACTAG-1', 'TCGTTCTCCCGC', 'SSU72', 1541672): 1,\n",
       "         ('TGTTCATCAGGAGACT-1', 'CTGTAGGACACA', 'SSU72', 1541672): 1,\n",
       "         ('TTCATTGTCTAGTGAC-1', 'AATCGTCGGTTC', 'SSU72', 1541672): 1,\n",
       "         ('TTGTTGTGTACCACGC-1', 'TCCGTCAGGCAG', 'SSU72', 1541672): 1,\n",
       "         ('TTTGATCCATAGGTTC-1', 'TAAGGAGTTTTA', 'SSU72', 1541672): 1,\n",
       "         ('ACGTAACAGACATACA-1', 'CCTCTCGTCCCC', 'SSU72', 1541673): 1,\n",
       "         ('CACTGTCCACGGTGCT-1', 'GTGTGATGGTGA', 'SSU72', 1541673): 1,\n",
       "         ('TACGGTAAGGGAGGTG-1', 'GAGTGTCTTCAA', 'SSU72', 1541673): 1,\n",
       "         ('CTCAGAACAATGTGGG-1', 'GATAGTGCTACT', 'SSU72', 1541674): 1,\n",
       "         ('GTCTGTCAGAACTCCT-1', 'CCTTACCTTGTT', 'SSU72', 1541674): 1,\n",
       "         ('CGCATGGTCATGAAAG-1', 'GTCATTTTGTAC', 'SSU72', 1541675): 1,\n",
       "         ('CCGTGAGCACGTACAT-1', 'CTATGTTATTGG', 'SSU72', 1541698): 1,\n",
       "         ('CATCGGGTCTTAATCC-1', 'TCTCCTCCTTCA', 'SSU72', 1541714): 1,\n",
       "         ('AGTGATCTCACGGGAA-1', 'ATTGCTTAACCC', 'SSU72', 1541756): 1,\n",
       "         ('TGATCTTTCGATTTCT-1', 'CTCATACGCCCG', 'SSU72', 1541756): 1,\n",
       "         ('CGGAGAACATCTTTCA-1', 'ACTGGGACCGTT', 'SSU72', 1541763): 1,\n",
       "         ('TCCGATCCACTTACAG-1', 'CGCCACCATGGT', 'SSU72', 1541767): 1,\n",
       "         ('ATAGGCTGTCGTTGCG-1', 'CACAGGGGGATG', 'SSU72', 1541781): 1,\n",
       "         ('TCCATCGGTAGCACAG-1', 'CCCCTTCGGGTT', 'SSU72', 1541781): 1,\n",
       "         ('TGCTTCGTCCCGAGAC-1', 'ACCGCATTGTTA', 'SSU72', 1541789): 1,\n",
       "         ('GGGTGTCAGCGATGGT-1', 'GTGCAAAGTGCT', 'SSU72', 1541797): 1,\n",
       "         ('CAGTTAGAGTATGATG-1', 'AGGAGGGTTAAC', 'SSU72', 1541800): 1,\n",
       "         ('GTAAGTCCAAATCGGG-1', 'CGCCACAATAGT', 'SSU72', 1541800): 1,\n",
       "         ('ATACCTTAGGATTTGA-1', 'TAGTAACGTGTA', 'SSU72', 1541802): 1,\n",
       "         ('GGTTGTACATCTCCCA-1', 'TCGTCCGGACGC', 'SSU72', 1541804): 1,\n",
       "         ('ATCAGGTAGTGCAGGT-1', 'GCTCAGTCGAGG', 'SSU72', 1541808): 1,\n",
       "         ('TGATTTCGTGACAACG-1', 'CTGAGTCTCTGT', 'SSU72', 1541820): 1,\n",
       "         ('CCTTCAGAGTGGTTGG-1', 'TGGGAAAATTTT', 'SSU72', 1541821): 1,\n",
       "         ('GTAAGTCCAAATCGGG-1', 'CGCCACAATAGT', 'SSU72', 1541824): 1,\n",
       "         ('AGGACGAAGTCGGCAA-1', 'CATAAGTCACGT', 'SSU72', 1541831): 1,\n",
       "         ('GTTAGACCATCGTGCG-1', 'CATTTTCCGCTT', 'SSU72', 1541838): 1,\n",
       "         ('ATTCATCGTTGCTAGT-1', 'GCAAATCCACCG', 'SSU72', 1541841): 1,\n",
       "         ('TACGTCCAGATCCGAG-1', 'TAGCTGCCCATC', 'SSU72', 1541842): 1,\n",
       "         ('AGGGTCCTCGCTACGG-1', 'TATTGTCAAACG', 'SSU72', 1541844): 1,\n",
       "         ('AGCGATTGTCGTATGT-1', 'TACCCTCCGGAT', 'SSU72', 1541847): 1,\n",
       "         ('TACCGGGAGGGTTAAT-1', 'CTTCGGGGCAAT', 'SSU72', 1541853): 1,\n",
       "         ('TTACAGGTCTTAGCCC-1', 'TTTATTATTCTG', 'SSU72', 1541853): 1,\n",
       "         ('CAAGCTACAAGAATGT-1', 'ATTGCCATACAC', 'SSU72', 1541854): 1,\n",
       "         ('TCCCAGTGTTACACAC-1', 'CATCCTGGTAAG', 'SSU72', 1541862): 1,\n",
       "         ('ACGTCCTAGAAACTGT-1', 'ATATTTCCTTGT', 'SSU72', 1541883): 1,\n",
       "         ('AAAGGTACACTAGGTT-1', 'CGCAAGAGAAGA', 'SSU72', 1541884): 1,\n",
       "         ('TGACCCTAGCTGCGAA-1', 'GTTTAAAGTAAC', 'SSU72', 1541887): 1,\n",
       "         ('TAACCAGTCAACTACG-1', 'ACGCCAACATAC', 'SSU72', 1541889): 1,\n",
       "         ('TACGGGCCAGACACCC-1', 'GAAGTAACTACG', 'SSU72', 1541902): 1,\n",
       "         ('GTGTTCCCAATCCTTT-1', 'ATCTTCAGAGGC', 'SSU72', 1541914): 1,\n",
       "         ('ACATGCAAGGTAACTA-1', 'ATGATCGGAACA', 'SSU72', 1541917): 1,\n",
       "         ('CTGGTCTTCCGGGACT-1', 'CAAGCCACATGG', 'SSU72', 1541945): 1,\n",
       "         ('AGCGATTGTCGTATGT-1', 'ATTTAAGGCTGC', 'SSU72', 1541952): 1,\n",
       "         ('ACCATTTCAAGTATCC-1', 'CTTTTCTGCCGT', 'SSU72', 1541956): 1,\n",
       "         ('TCGACCTAGCGGCTCT-1', 'ATTGACTTGATA', 'SSU72', 1541982): 1,\n",
       "         ('ACGTACAAGCGACATG-1', 'AGGTTTACGTAT', 'SSU72', 1545457): 1,\n",
       "         ('GGTCTGGGTAGCGCCT-1', 'CCCGCACCGACC', 'SSU72', 1560856): 1,\n",
       "         ('TCAAGTGCAGGTCAAG-1', 'ACTAGGAACCGG', 'SSU72', 1562265): 1,\n",
       "         ('AAGAACACAACGGCCT-1', 'CTTTATCGTCGA', 'SSU72', 1562336): 2,\n",
       "         ('GCCAGTGTCCGAGATT-1', 'GTAGAACCCCTT', 'SSU72', 1562344): 2,\n",
       "         ('ATTCTTGTCTTGTTAC-1', 'CGCCGGTCTGAA', 'SSU72', 1562349): 1,\n",
       "         ('CACTAAGCAGCGTAGA-1', 'CTGCGACCACAC', 'SSU72', 1562349): 1,\n",
       "         ('CTGAGGCAGCACTCGC-1', 'GAACAGGTAACA', 'SSU72', 1562349): 1,\n",
       "         ('TGAGCGCAGGTGCCTC-1', 'GCGCTATATGAC', 'SSU72', 1562349): 1,\n",
       "         ('TTACGCCCATCGAAGG-1', 'CAGTTCAGTACT', 'SSU72', 1562349): 1,\n",
       "         ('TCCATGCTCGTAGTCA-1', 'CCATCCCTAAAC', 'SSU72', 1562509): 1,\n",
       "         ('GGGTGAACATAAGATG-1', 'TGCAGTCTCCGA', 'SSU72', 1562520): 1,\n",
       "         ('GTAGATCAGTCTCTGA-1', 'CCATGTGATCCT', 'SSU72', 1562531): 1,\n",
       "         ('ATGACCAGTGCGCTCA-1', 'TTGTTTTCAATC', 'SSU72', 1562538): 1,\n",
       "         ('TGTGAGTCAGGACGAT-1', 'ATATTTCTCGCG', 'SSU72', 1562546): 1,\n",
       "         ('TCTATCATCCCTCTTT-1', 'ACCGTAGCAGTT', 'SSU72', 1563573): 1,\n",
       "         ('AGGGTGATCCCGAAAT-1', 'AATTGCTCTTCT', 'SSU72', 1564113): 1,\n",
       "         ('CACTGAATCCTCGATC-1', 'AGCACAACGATG', 'SSU72', 1564727): 1,\n",
       "         ('AGTCACATCCTCTCGA-1', 'TAAGATAGCCCG', 'SSU72', 1574477): 1,\n",
       "         ('AGTCTCCGTTAACCTG-1', 'CCAACGGGTACT', 'SSU72', 1574513): 1,\n",
       "         ('ACTGATGTCCCACAGG-1', 'TAGCCACTTTGA', 'SSU72', 1574541): 1,\n",
       "         ('TGATTCTCATTGTGCA-1', 'AATTTAAGTCTG', 'AL645728.1', 1575269): 1,\n",
       "         ('AATAGAGAGATGCTGG-1', 'AGATAAGTCTGG', 'AL645728.1', 1575713): 1,\n",
       "         ('CGCATGGTCATGGGAG-1', 'TAGTGCCTTACA', 'AL645728.1', 1575713): 1,\n",
       "         ('GTGACGCGTCTCTCCA-1', 'CTGCAACATCGC', 'FNDC10', 1598011): 1,\n",
       "         ('ACTATCTGTCACTTCC-1', 'GCCCAGCACACT', 'AL691432.2', 1613757): 1,\n",
       "         ('CTACGGGTCCAGTGCG-1', 'CAGTATCACTGT', 'AL691432.2', 1613760): 1,\n",
       "         ('TCTTCCTGTGCTCTCT-1', 'GTCCCCGCAGTT', 'AL691432.2', 1613763): 1,\n",
       "         ('TCGAAGTAGCAAGGAA-1', 'CTAAGTTTGTTT', 'AL691432.2', 1613780): 1,\n",
       "         ('AGGAGGTCACAAGCTT-1', 'TAGCATGCAATA', 'AL691432.2', 1613992): 2,\n",
       "         ('AAGTACCTCGGTGTAT-1', 'TTTAACCCTCCA', 'AL691432.2', 1614586): 1,\n",
       "         ('TAGGGTTAGTCGCCCA-1', 'CCGTCGGCTGTA', 'AL691432.2', 1615229): 1,\n",
       "         ('TGGGAGAAGAGGTATT-1', 'TACTGCACCGCG', 'MIB2', 1616969): 1,\n",
       "         ('TCAGCAATCTCTGCCA-1', 'AAACGTAGTATC', 'MIB2', 1617129): 1,\n",
       "         ('CGCCATTCACAAATCC-1', 'CGCCCTGGCTCC', 'MIB2', 1619117): 1,\n",
       "         ('CTCATCGTCTCAATCT-1', 'TGATGGCCTCAT', 'MIB2', 1625798): 1,\n",
       "         ('CAGGTATCACTGTGAT-1', 'CGTATACGTGCA', 'MIB2', 1630396): 1,\n",
       "         ('GGGATCCCAGCCTTCT-1', 'CTTACTCCCCCA', 'MIB2', 1630416): 1,\n",
       "         ('TGCTCCACACGCTATA-1', 'GCAAACACATCA', 'MMP23B', 1634257): 1,\n",
       "         ('GGCAGTCAGGAGAATG-1', 'ATACAACTATAT', 'CDK11B', 1635240): 1,\n",
       "         ('GGAGAACAGAGAGGGC-1', 'TGCGGTCGATCA', 'CDK11B', 1635377): 1,\n",
       "         ('CGAGGCTAGTCAGAGC-1', 'TGAATTCCTGTT', 'CDK11B', 1635441): 1,\n",
       "         ('AACTTCTTCCTCGCAT-1', 'CCAAATCAAGGT', 'CDK11B', 1635586): 1,\n",
       "         ('ACGTAGTAGATCCCAT-1', 'TGTCAATAACTT', 'CDK11B', 1635586): 2,\n",
       "         ('AGACAGGAGGGAGGTG-1', 'TATTCAAAACGT', 'CDK11B', 1635586): 1,\n",
       "         ('ATTCATCTCAATCCGA-1', 'ATCTTCCCACCA', 'CDK11B', 1635586): 1,\n",
       "         ('CCCTGATGTATAATGG-1', 'CCTGCCAATTTT', 'CDK11B', 1635586): 1,\n",
       "         ('CGAATTGCACTATCCC-1', 'TGTGCTTTGGTG', 'CDK11B', 1635586): 1,\n",
       "         ('CGAGTGCTCCGTATGA-1', 'TTTTATTCTCTG', 'CDK11B', 1635586): 1,\n",
       "         ('CGGAACCCATGACTAC-1', 'GCTACATGCAGG', 'CDK11B', 1635586): 2,\n",
       "         ('GAAGAATGTAGTCTGT-1', 'CTTGTTGCCCTT', 'CDK11B', 1635586): 1,\n",
       "         ('GACAGCCAGCGTTACT-1', 'CCTACCCAGTGT', 'CDK11B', 1635586): 1,\n",
       "         ('GCCAACGTCCGTGCGA-1', 'TCGATTACTAAA', 'CDK11B', 1635586): 1,\n",
       "         ('GCCAGCACACAGAGCA-1', 'CGCCATTTCGCC', 'CDK11B', 1635586): 1,\n",
       "         ('GCTGAATGTGGCTTAT-1', 'AAATGGAGCGTG', 'CDK11B', 1635586): 1,\n",
       "         ('GGGACCTTCCATTCGC-1', 'TGCTTTACCGCG', 'CDK11B', 1635586): 1,\n",
       "         ('GTGCAGCGTTTATGCG-1', 'CTCTAGGGTTGA', 'CDK11B', 1635586): 1,\n",
       "         ('TCATATCCACACCTTC-1', 'TAAACTAGTCAT', 'CDK11B', 1635586): 1,\n",
       "         ('TCATTACGTTAAGAAC-1', 'CCATAGACGCAC', 'CDK11B', 1635586): 1,\n",
       "         ('TGAGCGCCACAGCCTG-1', 'TGTCGTCGTCAC', 'CDK11B', 1635586): 1,\n",
       "         ('TGGATGTAGAGACAAG-1', 'TTGTCGAACGCT', 'CDK11B', 1635586): 1,\n",
       "         ('TTGCGTCTCAGCGCAC-1', 'CGACCAGTATCA', 'CDK11B', 1635586): 1,\n",
       "         ('TTGTTCACAGAGGGTT-1', 'ACTTGTTTTCTT', 'CDK11B', 1635586): 1,\n",
       "         ('ATTACTCCACGTGTGC-1', 'GGCCCGATCCAT', 'CDK11B', 1635591): 1,\n",
       "         ('CCTCACACAACCCTAA-1', 'CCATGTCCAAGG', 'CDK11B', 1635591): 1,\n",
       "         ('GGGAGTACAGATCCAT-1', 'TACTTCGGTGTC', 'CDK11B', 1635591): 1,\n",
       "         ('TGTGCGGGTCTCACAA-1', 'CCTACCTTCCGG', 'CDK11B', 1635606): 1,\n",
       "         ('GGGTTATGTTGGACTT-1', 'GAGTCGCGGGAT', 'CDK11B', 1635676): 1,\n",
       "         ('CGCCAGAAGAGAAGGT-1', 'CTTTCAGTGAGA', 'CDK11B', 1635774): 1,\n",
       "         ('AGTGCCGGTCTAACGT-1', 'TCTTATTTAGCT', 'CDK11B', 1635779): 1,\n",
       "         ('TTAATCCTCAGACTGT-1', 'TGCCAGAGCTTT', 'CDK11B', 1641661): 1,\n",
       "         ('TGAGCGCAGGTGCCTC-1', 'AACCATTAAAGA', 'CDK11B', 1641732): 1,\n",
       "         ('TGAGACTTCCATAAGC-1', 'CGTATTCACGCC', 'CDK11B', 1641905): 1,\n",
       "         ('ACTTATCTCTCGTGGG-1', 'TAACTCAGGCCT', 'CDK11B', 1642384): 2,\n",
       "         ('CTCCTTTTCTAGACAC-1', 'TATCTCATATCT', 'CDK11B', 1642385): 1,\n",
       "         ('CTGCCATAGCCGTTGC-1', 'ACAGCTACTTCT', 'CDK11B', 1642386): 1,\n",
       "         ('GACTCAATCTTGTGCC-1', 'TTCAGTAGCCGT', 'CDK11B', 1645163): 1,\n",
       "         ('AGAAGTACAGTAGAAT-1', 'GAACTGGTTTCC', 'CDK11B', 1645180): 1,\n",
       "         ('TCCCACAGTGCTATTG-1', 'TTTAACTCGTTC', 'CDK11B', 1645181): 1,\n",
       "         ('ACAAAGACAAGAGCTG-1', 'GCCACTTCTTTT', 'CDK11B', 1645191): 1,\n",
       "         ('GGAGATGCAGTATGAA-1', 'CTTAGAGGAATA', 'CDK11B', 1645239): 1,\n",
       "         ('ACAAAGACAAGAGCTG-1', 'GCCACTTCTTTT', 'CDK11B', 1649502): 1,\n",
       "         ('TAAGTCGGTCCAACGC-1', 'GTTCGGTGATCA', 'CDK11B', 1649523): 1,\n",
       "         ('AAAGTGACAGAGTAAT-1', 'CGGCTTCCGTCA', 'CDK11B', 1649607): 1,\n",
       "         ('GCCAGGTCATTGCTTT-1', 'ACCTCCGAGTGC', 'CDK11B', 1652467): 1,\n",
       "         ('ACAACCAGTATACAGA-1', 'CACGGGGACTCT', 'CDK11B', 1652469): 1,\n",
       "         ('TACATTCGTCTGATAC-1', 'AAGGATCTTGCT', 'CDK11B', 1652490): 2,\n",
       "         ('AATCGACGTGCCGGTT-1', 'GCTTTGATTTAG', 'CDK11B', 1655368): 1,\n",
       "         ('AGCGATTGTCCTGTTC-1', 'TCGTTGGCATAT', 'CDK11B', 1655368): 1,\n",
       "         ('AGCTTCCAGCGTGTTT-1', 'GGTAACTACTCT', 'CDK11B', 1655368): 2,\n",
       "         ('CAACCAATCCATCACC-1', 'GCGGTCCCGATA', 'CDK11B', 1655368): 1,\n",
       "         ('GGTCACGCATCCGGCA-1', 'AATTATGTAACG', 'CDK11B', 1655368): 1,\n",
       "         ('TTGGGATTCTAGCCTC-1', 'ACGCCTCGCCCT', 'CDK11B', 1655368): 1,\n",
       "         ('ACCATTTTCAGGAAAT-1', 'CATCTCGACATA', 'CDK11B', 1655370): 1,\n",
       "         ('AAGAACACAACGGCCT-1', 'CTACATCTATAA', 'CDK11B', 1655380): 1,\n",
       "         ('TAACACGTCCTAAGTG-1', 'AATTCCATTGTT', 'CDK11B', 1655390): 1,\n",
       "         ('GTATTGGGTCACCGCA-1', 'TAGTCGTATTTC', 'CDK11B', 1655457): 1,\n",
       "         ('AGGACTTGTGCCCGTA-1', 'TTTACTATGGTC', 'CDK11B', 1655467): 1,\n",
       "         ('CATCCACCACGGCTAC-1', 'ATGTTAGAGCAT', 'CDK11B', 1657255): 1,\n",
       "         ('ATAGACCTCACTGAAC-1', 'TAGATCCTGCGG', 'CDK11B', 1657291): 1,\n",
       "         ('CAGATCAGTATGGTAA-1', 'CCTTAATAATGC', 'CDK11B', 1657291): 1,\n",
       "         ('GATTCGAGTTCTCGCT-1', 'ATCCTTGTTAAA', 'CDK11B', 1657291): 1,\n",
       "         ('TCAGTGAAGGCACTCC-1', 'CGCTTTTTACTT', 'CDK11B', 1657291): 2,\n",
       "         ('GATTCGAGTTCTCGCT-1', 'ATCCTTGTTAAT', 'CDK11B', 1657297): 1,\n",
       "         ('GTTGCTCTCCACTAGA-1', 'CTTAGCGAGCCA', 'CDK11B', 1657297): 1,\n",
       "         ('TAAGTCGCAAATCAGA-1', 'ACACCCGATAAG', 'CDK11B', 1657297): 1,\n",
       "         ('CATCCGTAGTAGTCCT-1', 'CTATGCTCTAGT', 'CDK11B', 1657374): 1,\n",
       "         ('TGCAGTACAGCAGACA-1', 'ATACGGGCAACA', 'CDK11B', 1657374): 1,\n",
       "         ('TCTTGCGCAACGGCCT-1', 'CACTCTTCTTGT', 'CDK11B', 1657375): 1,\n",
       "         ('TTACGTTGTCTTGAAC-1', 'GCGAGGTTTATT', 'CDK11B', 1657375): 1,\n",
       "         ('AGTGACTGTCGCAACC-1', 'CCTATCTGTGTT', 'SLC35E2B', 1659534): 1,\n",
       "         ('ACGTTCCGTATCGTAC-1', 'CGAATAAAGTGA', 'SLC35E2B', 1661477): 1,\n",
       "         ('AGGGTTTGTGGTACAG-1', 'AACTGATATGCA', 'SLC35E2B', 1661477): 1,\n",
       "         ('CACGTTCTCTTCCCGA-1', 'TGTTTATGTGCG', 'SLC35E2B', 1661477): 1,\n",
       "         ('CCCTCTCCATCCTAAG-1', 'CATCCTTCTATG', 'SLC35E2B', 1661477): 3,\n",
       "         ('CGTCCATCAAACGGCA-1', 'AACGATGTAAAA', 'SLC35E2B', 1661477): 1,\n",
       "         ('CTTAGGAGTCAGGTGA-1', 'ACCGTTTTTTGT', 'SLC35E2B', 1661477): 1,\n",
       "         ('CTTCTAAAGTTAACGA-1', 'GCTTTAAGCATT', 'SLC35E2B', 1661477): 1,\n",
       "         ('GATCCCTCAGTTGCGC-1', 'GTGTTCGTAGGC', 'SLC35E2B', 1661477): 1,\n",
       "         ('GCGTGCACAATCGCGC-1', 'CTTACACAAGGT', 'SLC35E2B', 1661477): 1,\n",
       "         ('GTCAAACAGCGTATGG-1', 'TCGGGTCCCTGG', 'SLC35E2B', 1661477): 1,\n",
       "         ('TCGGTCTTCTGTGTGA-1', 'TACGTTCGCCGC', 'SLC35E2B', 1661477): 1,\n",
       "         ('TGAGCGCGTCAATGGG-1', 'TCCTGTCGATTT', 'SLC35E2B', 1661477): 1,\n",
       "         ('TTTGATCAGGAAAGTG-1', 'GACTGCCTAGGT', 'SLC35E2B', 1661477): 1,\n",
       "         ('CACTTCGCAACCCTCT-1', 'CTGAAATTTCTG', 'SLC35E2B', 1661479): 1,\n",
       "         ('CCTAAGATCCTCTTTC-1', 'TTTTCCGTCTTC', 'SLC35E2B', 1661480): 1,\n",
       "         ('TTACGTTAGTAGGAAG-1', 'TGTAAACAAGTC', 'SLC35E2B', 1661564): 1,\n",
       "         ('TGTGCGGGTATGTCAC-1', 'TTGTCACCGGTC', 'SLC35E2B', 1661662): 1,\n",
       "         ('TTTAGTCAGAGTCTGG-1', 'CTTGCTCGTTGC', 'SLC35E2B', 1661662): 1,\n",
       "         ('GGGCCATGTAATCAGA-1', 'TTTAACTGGCTG', 'SLC35E2B', 1661722): 1,\n",
       "         ('CTATAGGAGTCCTACA-1', 'ATAAACCACTCG', 'SLC35E2B', 1662040): 1,\n",
       "         ('GGATCTAAGCTCGAAG-1', 'GCACGGTCTTAC', 'SLC35E2B', 1662181): 1,\n",
       "         ('ATGAAAGAGATAGTGT-1', 'CGACTGAGCGTC', 'FO704657.1', 1662412): 1,\n",
       "         ('AGCCAGCAGATAACAC-1', 'ACGCCATACTTC', 'SLC35E2B', 1662720): 1,\n",
       "         ('TAAGTCGGTTGCGGCT-1', 'TGAATTGGACTT', 'SLC35E2B', 1662896): 1,\n",
       "         ('ACACCAATCCTTCTTC-1', 'GGCCCTTACCTG', 'SLC35E2B', 1663922): 1,\n",
       "         ('ATTGGGTAGACTAGAT-1', 'CCAGAAGGTTTG', 'SLC35E2B', 1670142): 1,\n",
       "         ('GTAAGTCTCTCCGTGT-1', 'TAATATTCGAAG', 'SLC35E2B', 1670895): 1,\n",
       "         ('TTGTTTGTCATCGCAA-1', 'GCCATATCTTCT', 'SLC35E2B', 1671521): 1,\n",
       "         ('AACTTCTTCCTCGCAT-1', 'CCAAATCAAGGT', 'CDK11A', 1702729): 1,\n",
       "         ('ACGTAGTAGATCCCAT-1', 'TGTCAATAACTT', 'CDK11A', 1702729): 2,\n",
       "         ('AGACAGGAGGGAGGTG-1', 'TATTCAAAACGT', 'CDK11A', 1702729): 1,\n",
       "         ('ATTCATCTCAATCCGA-1', 'ATCTTCCCACCA', 'CDK11A', 1702729): 1,\n",
       "         ('CCCTGATGTATAATGG-1', 'CCTGCCAATTTT', 'CDK11A', 1702729): 1,\n",
       "         ('CGAATTGCACTATCCC-1', 'TGTGCTTTGGTG', 'CDK11A', 1702729): 1,\n",
       "         ('CGAGTGCTCCGTATGA-1', 'TTTTATTCTCTG', 'CDK11A', 1702729): 1,\n",
       "         ('CGGAACCCATGACTAC-1', 'GCTACATGCAGG', 'CDK11A', 1702729): 2,\n",
       "         ('GAAGAATGTAGTCTGT-1', 'CTTGTTGCCCTT', 'CDK11A', 1702729): 1,\n",
       "         ('GACAGCCAGCGTTACT-1', 'CCTACCCAGTGT', 'CDK11A', 1702729): 1,\n",
       "         ('GCCAACGTCCGTGCGA-1', 'TCGATTACTAAA', 'CDK11A', 1702729): 1,\n",
       "         ('GCCAGCACACAGAGCA-1', 'CGCCATTTCGCC', 'CDK11A', 1702729): 1,\n",
       "         ('GCTGAATGTGGCTTAT-1', 'AAATGGAGCGTG', 'CDK11A', 1702729): 1,\n",
       "         ('GGGACCTTCCATTCGC-1', 'TGCTTTACCGCG', 'CDK11A', 1702729): 1,\n",
       "         ...})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match -- 0\n",
    "Insertion -- 1\n",
    "Deletion -- 2\n",
    "Splice -- 3\n",
    "Softclip -- 4\n",
    "Hardclip (not good, rerun the alignment) -- 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(798512, (0,)),\n",
       " (143947, (4, 0)),\n",
       " (46502, (0, 4)),\n",
       " (3855, (4, 0, 4)),\n",
       " (3518, (0, 1, 0)),\n",
       " (1662, (0, 2, 0)),\n",
       " (1380, (0, 3, 0)),\n",
       " (133, (4, 0, 1, 0)),\n",
       " (123, (0, 1, 0, 4)),\n",
       " (109, (4, 0, 3, 0)),\n",
       " (101, (0, 3, 0, 4)),\n",
       " (62, (0, 2, 0, 4)),\n",
       " (46, (4, 0, 2, 0)),\n",
       " (11, (4, 0, 3, 0, 4)),\n",
       " (9, (0, 3, 0, 3, 0)),\n",
       " (8, (0, 3, 0, 1, 0)),\n",
       " (6, (4, 0, 1, 0, 4)),\n",
       " (4, (0, 1, 0, 1, 0)),\n",
       " (3, (4, 0, 2, 0, 4)),\n",
       " (3, (0, 1, 0, 2, 0)),\n",
       " (2, (0, 2, 0, 1, 0)),\n",
       " (1, (4, 0, 1, 0, 2, 0)),\n",
       " (1, (0, 2, 0, 2, 0)),\n",
       " (1, (0, 1, 0, 3, 0)),\n",
       " (1, (0, 1, 0, 1, 0, 4))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(j, i) for i, j in c.items()], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[(798512, (0,)),\n",
    " (143947, (4, 0)),\n",
    " (46502, (0, 4)),\n",
    " (3855, (4, 0, 4)),\n",
    " (3518, (0, 1, 0)),\n",
    " (1662, (0, 2, 0)),\n",
    " (1380, (0, 3, 0)),\n",
    " (133, (4, 0, 1, 0)),\n",
    " (123, (0, 1, 0, 4)),\n",
    " (109, (4, 0, 3, 0)),\n",
    " (101, (0, 3, 0, 4)),\n",
    " (62, (0, 2, 0, 4)),\n",
    " (46, (4, 0, 2, 0)),\n",
    " (11, (4, 0, 3, 0, 4)),\n",
    " (9, (0, 3, 0, 3, 0)),\n",
    " (8, (0, 3, 0, 1, 0)),\n",
    " (6, (4, 0, 1, 0, 4)),\n",
    " (4, (0, 1, 0, 1, 0)),\n",
    " (3, (4, 0, 2, 0, 4)),\n",
    " (3, (0, 1, 0, 2, 0)),\n",
    " (2, (0, 2, 0, 1, 0)),\n",
    " (1, (4, 0, 1, 0, 2, 0)),\n",
    " (1, (0, 2, 0, 2, 0)),\n",
    " (1, (0, 1, 0, 3, 0)),\n",
    " (1, (0, 1, 0, 1, 0, 4))]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
